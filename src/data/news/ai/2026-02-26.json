[
  {
    "title": "Google and the Massachusetts AI Hub are launching a new AI training initiative for the Commonwealth.",
    "slug": "google-massachusetts-ai-hub-training-initiative",
    "url": "https://blog.google/company-news/outreach-and-initiatives/grow-with-google/google-ai-training-massachusetts-residents/",
    "source": "Google AI Blog",
    "date": "2026-02-26T18:55:00.000Z",
    "summary": "Google is partnering with the Massachusetts AI Hub to provide free AI training access to residents. This initiative aims to democratize AI education and skills development across the state, helping citizens prepare for an AI-driven economy.",
    "content": "Google is partnering with the Massachusetts AI Hub to provide every Baystater with no-cost access to Google’s AI training.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "谷歌和马萨诸塞州AI中心推出新的AI培训倡议",
        "summary": "谷歌正与马萨诸塞州AI中心合作，为居民提供免费的AI培训。该倡议旨在民主化整个州的AI教育和技能发展，帮助公民为AI驱动的经济做准备。"
      },
      "fr": {
        "title": "Google et le Massachusetts AI Hub lancent une nouvelle initiative de formation en IA",
        "summary": "Google s'associe au Massachusetts AI Hub pour fournir un accès gratuit à la formation en IA aux résidents. Cette initiative vise à démocratiser l'éducation en IA et le développement des compétences dans tout l'État, aidant les citoyens à se préparer à une économie basée sur l'IA."
      },
      "de": {
        "title": "Google und der Massachusetts AI Hub starten eine neue KI-Schulungsinitiative",
        "summary": "Google arbeitet mit dem Massachusetts AI Hub zusammen, um Bewohnern kostenlosen Zugang zu KI-Schulungen zu bieten. Diese Initiative zielt darauf ab, die KI-Bildung und Kompetenzentwicklung im gesamten Bundesstaat zu demokratisieren und Bürger auf eine KI-getriebene Wirtschaft vorzubereiten."
      },
      "es": {
        "title": "Google y el Massachusetts AI Hub lanzan una nueva iniciativa de capacitación en IA",
        "summary": "Google se asocia con el Massachusetts AI Hub para proporcionar acceso gratuito a capacitación en IA a los residentes. Esta iniciativa tiene como objetivo democratizar la educación en IA y el desarrollo de habilidades en todo el estado, ayudando a los ciudadanos a prepararse para una economía impulsada por la IA."
      }
    }
  },
  {
    "title": "Get more context and understand translations more deeply with new AI-powered updates in Translate.",
    "slug": "get-more-context-understand-translations-deeply-ai-powered-translate",
    "url": "https://blog.google/products-and-platforms/products/translate/translation-context-ai-update/",
    "source": "Google AI Blog",
    "date": "2026-02-26T18:00:00.000Z",
    "summary": "Google Translate is introducing new \"understand\" and \"ask\" buttons to help users better navigate language complexities. These AI-powered features provide additional context for translations, enhancing understanding of nuanced differences in natural language.",
    "content": "New alternatives, “understand” and “ask” buttons in Google Translate help you navigate the complexities of natural language.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "通过Google翻译中新的AI驱动更新获得更多背景和更深入地理解翻译",
        "summary": "谷歌翻译推出了新的\"理解\"和\"提问\"按钮，帮助用户更好地应对语言复杂性。这些AI驱动的功能为翻译提供了额外背景，增强了对自然语言细微差异的理解。"
      },
      "fr": {
        "title": "Obtenez plus de contexte et comprenez mieux les traductions avec les nouvelles mises à jour alimentées par l'IA dans Translate",
        "summary": "Google Traduction introduit de nouveaux boutons \"comprendre\" et \"demander\" pour aider les utilisateurs à mieux naviguer les complexités linguistiques. Ces fonctionnalités alimentées par l'IA fournissent un contexte supplémentaire pour les traductions, améliorant la compréhension des nuances du langage naturel."
      },
      "de": {
        "title": "Erhalten Sie mehr Kontext und verstehen Sie Übersetzungen tiefergehend mit neuen KI-gestützten Updates in Translate",
        "summary": "Google Translate führt neue Schaltflächen \"Verstehen\" und \"Fragen\" ein, um Benutzern dabei zu helfen, sprachliche Komplexitäten besser zu navigieren. Diese KI-gestützten Funktionen bieten zusätzlichen Kontext für Übersetzungen und verbessern das Verständnis für nuancierte Unterschiede in der natürlichen Sprache."
      },
      "es": {
        "title": "Obtenga más contexto y comprenda las traducciones más profundamente con nuevas actualizaciones impulsadas por IA en Translate",
        "summary": "Google Translate está introduciendo nuevos botones \"entender\" y \"preguntar\" para ayudar a los usuarios a navegar mejor las complejidades del idioma. Estas características impulsadas por IA proporcionan contexto adicional para las traducciones, mejorando la comprensión de los matices en el lenguaje natural."
      }
    }
  },
  {
    "title": "Build with Nano Banana 2, our best image generation and editing model",
    "slug": "build-nano-banana-2-best-image-generation-editing-model",
    "url": "https://blog.google/innovation-and-ai/technology/developers-tools/build-with-nano-banana-2/",
    "source": "Google AI Blog",
    "date": "2026-02-26T16:00:00.000Z",
    "summary": "Google has released Nano Banana 2 (Gemini 3.1 Flash Image), an image generation and editing model that delivers professional-level capabilities. The model combines high-quality output with efficiency suitable for all image applications.",
    "content": "Nano Banana 2 (Gemini 3.1 Flash Image) delivers Pro-level intelligence and fidelity for all image applications.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "使用Nano Banana 2构建，我们最好的图像生成和编辑模型",
        "summary": "谷歌发布了Nano Banana 2（Gemini 3.1 Flash Image），这是一个提供专业级功能的图像生成和编辑模型。该模型将高质量输出与适用于所有图像应用的效率结合在一起。"
      },
      "fr": {
        "title": "Construisez avec Nano Banana 2, notre meilleur modèle de génération et d'édition d'images",
        "summary": "Google a lancé Nano Banana 2 (Gemini 3.1 Flash Image), un modèle de génération et d'édition d'images qui offre des capacités de niveau professionnel. Le modèle combine une sortie de haute qualité avec l'efficacité nécessaire pour toutes les applications d'images."
      },
      "de": {
        "title": "Erstellen Sie mit Nano Banana 2, unserem besten Bildgenerations- und Bearbeitungsmodell",
        "summary": "Google hat Nano Banana 2 (Gemini 3.1 Flash Image) veröffentlicht, ein Bildgenerations- und Bearbeitungsmodell, das professionelle Fähigkeiten bietet. Das Modell kombiniert hochwertige Ausgabe mit Effizienz, die für alle Bildanwendungen geeignet ist."
      },
      "es": {
        "title": "Construya con Nano Banana 2, nuestro mejor modelo de generación y edición de imágenes",
        "summary": "Google ha lanzado Nano Banana 2 (Gemini 3.1 Flash Image), un modelo de generación y edición de imágenes que ofrece capacidades de nivel profesional. El modelo combina salida de alta calidad con eficiencia adecuada para todas las aplicaciones de imagen."
      }
    }
  },
  {
    "title": "Nano Banana 2: Combining Pro capabilities with lightning-fast speed",
    "slug": "nano-banana-2-combining-pro-capabilities-lightning-fast-speed",
    "url": "https://blog.google/innovation-and-ai/technology/ai/nano-banana-2/",
    "source": "Google AI Blog",
    "date": "2026-02-26T16:00:00.000Z",
    "summary": "Nano Banana 2 delivers production-ready image generation with advanced world knowledge and subject consistency at high speed. The model combines professional capabilities with the efficiency needed for rapid deployment.",
    "content": "Our latest image generation model offers advanced world knowledge, production-ready specs, subject consistency and more, all at Flash speed.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "Nano Banana 2：将专业功能与闪电般快速的速度相结合",
        "summary": "Nano Banana 2提供生产就绪的图像生成，具有先进的世界知识和高速度的主题一致性。该模型将专业功能与快速部署所需的效率结合在一起。"
      },
      "fr": {
        "title": "Nano Banana 2 : Combinaison des capacités Pro avec une vitesse ultra-rapide",
        "summary": "Nano Banana 2 offre une génération d'images prête pour la production avec une connaissance avancée du monde et une cohérence thématique à haute vitesse. Le modèle combine des capacités professionnelles avec l'efficacité nécessaire pour un déploiement rapide."
      },
      "de": {
        "title": "Nano Banana 2: Kombination von Pro-Funktionen mit blitzschneller Geschwindigkeit",
        "summary": "Nano Banana 2 bietet produktionsreife Bildgenerierung mit fortgeschrittenem Weltwissen und Konsistenz bei hoher Geschwindigkeit. Das Modell kombiniert professionelle Fähigkeiten mit der Effizienz, die für schnelle Bereitstellung erforderlich ist."
      },
      "es": {
        "title": "Nano Banana 2: Combinación de capacidades Pro con velocidad ultrarrápida",
        "summary": "Nano Banana 2 ofrece generación de imágenes lista para producción con conocimiento avanzado del mundo y consistencia temática a alta velocidad. El modelo combina capacidades profesionales con la eficiencia necesaria para un despliegue rápido."
      }
    }
  },
  {
    "title": "Finding value with AI and Industry 5.0 transformation",
    "slug": "finding-value-ai-industry-5-0-transformation",
    "url": "https://www.technologyreview.com/2026/02/26/1133707/finding-value-with-ai-and-industry-5-0-transformation/",
    "source": "MIT Technology Review",
    "date": "2026-02-26T15:00:59.000Z",
    "summary": "Industry 5.0 represents a shift from integrating individual technologies to orchestrating AI, cloud computing, IoT, robotics, and digital twins at enterprise scale. This evolution aims to create more nuanced value through coordinated technology systems rather than isolated implementations.",
    "content": "For years, Industry 4.0 transformation has centered on the convergence of intelligent technologies like AI, cloud, the internet of things, robotics, and digital twins. Industry 5.0 marks a pivotal shift from integrating emerging technologies to orchestrating them at scale. With Industry 5.0, the purpose of this interconnected web of technologies is more nuanced: to augment…",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "利用人工智能和工业5.0转型寻找价值",
        "summary": "工业5.0代表了从整合个别技术向在企业规模上协调人工智能、云计算、物联网、机器人和数字孪生的转变。这一演变旨在通过协调的技术系统而非孤立的实施来创造更细致的价值。"
      },
      "fr": {
        "title": "Trouver de la valeur avec l'IA et la transformation Industrie 5.0",
        "summary": "L'industrie 5.0 représente un passage de l'intégration de technologies individuelles à l'orchestration de l'IA, du cloud computing, de l'IoT, de la robotique et des jumeaux numériques à l'échelle de l'entreprise. Cette évolution vise à créer une valeur plus nuancée grâce à des systèmes technologiques coordonnés plutôt qu'à des implémentations isolées."
      },
      "de": {
        "title": "Wert mit KI und Industrie 5.0 Transformation finden",
        "summary": "Industrie 5.0 stellt einen Übergang dar, der von der Integration einzelner Technologien zur Orchestrierung von KI, Cloud Computing, IoT, Robotik und digitalen Zwillingen im Unternehmensmaßstab führt. Diese Entwicklung zielt darauf ab, durch koordinierte Technologiesysteme anstelle isolierter Implementierungen einen differenzierteren Wert zu schaffen."
      },
      "es": {
        "title": "Encontrar valor con IA y transformación Industria 5.0",
        "summary": "La Industria 5.0 representa un cambio de la integración de tecnologías individuales a la orquestación de IA, computación en la nube, IoT, robótica y gemelos digitales a escala empresarial. Esta evolución tiene como objetivo crear un valor más matizado a través de sistemas tecnológicos coordinados en lugar de implementaciones aisladas."
      }
    }
  },
  {
    "title": "The Download: how America lost its lead in the hunt for alien life, and ambitious battery claims",
    "slug": "download-america-lost-lead-hunt-alien-life-ambitious-battery",
    "url": "https://www.technologyreview.com/2026/02/26/1133734/the-download-how-america-lost-its-lead-in-the-hunt-for-alien-life-and-ambitious-battery-claims/",
    "source": "MIT Technology Review",
    "date": "2026-02-26T13:10:00.000Z",
    "summary": "NASA's Perseverance rover discovered unusual geological formations on Mars that could indicate microbial life, but China's entry into the search for Martian life has shifted the competitive landscape. The space exploration race is intensifying as multiple nations pursue astrobiology research.",
    "content": "This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. America was winning the race to find Martian life. Then China jumped in. In July 2024, NASA’s Perseverance rover came across a peculiar rocky outcrop on Mars covered in strange spots. On Earth,…",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "下载：美国如何失去了对外星生命的探索领先地位以及雄心勃勃的电池声称",
        "summary": "美国宇航局毅力号火星车发现了可能暗示微生物生命的不寻常地质构造，但中国进入火星生命搜索的行动改变了竞争格局。随着多个国家追求天体生物学研究，太空探索竞赛日益激烈。"
      },
      "fr": {
        "title": "Le Téléchargement : comment l'Amérique a perdu son avance dans la recherche de vie extraterrestre et les affirmations ambitieuses sur les batteries",
        "summary": "Le rover Perseverance de la NASA a découvert des formations géologiques inhabituelles sur Mars qui pourraient indiquer une vie microbienne, mais l'entrée de la Chine dans la recherche de vie sur Mars a modifié le paysage concurrentiel. La course à l'exploration spatiale s'intensifie alors que plusieurs nations poursuivent la recherche en astrobiologie."
      },
      "de": {
        "title": "Der Download: Wie Amerika seine Führungsrolle bei der Suche nach außerirdischem Leben verlor und ehrgeizige Batterieansprüche",
        "summary": "Der Perseverance-Rover der NASA entdeckte ungewöhnliche geologische Formationen auf dem Mars, die auf mikrobisches Leben hindeuten könnten, aber Chinas Eintritt in die Suche nach Leben auf dem Mars hat die Wettbewerbslandschaft verändert. Das Weltraumerkundungsrennen intensiviert sich, da mehrere Nationen Astrobiologieforschung betreiben."
      },
      "es": {
        "title": "La Descarga: cómo América perdió su liderazgo en la búsqueda de vida extraterrestre y afirmaciones ambiciosas sobre baterías",
        "summary": "El rover Perseverance de la NASA descubrió formaciones geológicas inusuales en Marte que podrían indicar vida microbiana, pero la entrada de China en la búsqueda de vida marciana ha alterado el panorama competitivo. La carrera de la exploración espacial se intensifica mientras múltiples naciones persiguen investigación en astrobiología."
      }
    }
  },
  {
    "title": "This company claims a battery breakthrough. Now they need to prove it.",
    "slug": "battery-breakthrough-donut-lab-solid-state",
    "url": "https://www.technologyreview.com/2026/02/26/1133722/solid-state-batteries-donut-lab/",
    "source": "MIT Technology Review",
    "date": "2026-02-26T11:00:00.000Z",
    "summary": "Donut Lab, a Finnish company, announced a new solid-state battery technology claimed to be production-ready, but the breakthrough requires independent verification. The announcement has generated significant interest as solid-state batteries represent a long-sought advancement in energy storage technology.",
    "content": "When a company claims to have created what’s essentially the holy grail of batteries, there are bound to be some questions. Interest has been swirling since Donut Lab, a Finnish company, announced last month that it had a new solid-state battery technology, one that was ready for large-scale production. The company said its batteries can…",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "这家公司声称电池取得突破。现在他们需要证明这一点。",
        "summary": "芬兰公司Donut Lab宣布了一种新的固态电池技术，声称已可投入生产，但该突破需要独立验证。该公告引起了广泛关注，因为固态电池代表了能源存储技术长期寻求的进步。"
      },
      "fr": {
        "title": "Cette entreprise prétend avoir fait une percée dans la batterie. Maintenant, ils doivent le prouver.",
        "summary": "Donut Lab, une entreprise finlandaise, a annoncé une nouvelle technologie de batterie à l'état solide prétendue prête pour la production, mais la percée nécessite une vérification indépendante. L'annonce a suscité un intérêt considérable car les batteries à l'état solide représentent une avancée longtemps recherchée dans la technologie du stockage d'énergie."
      },
      "de": {
        "title": "Dieses Unternehmen behauptet einen Batterie-Durchbruch. Jetzt müssen sie es beweisen.",
        "summary": "Donut Lab, ein finnisches Unternehmen, kündigte eine neue Festkörperbatterietechnologie an, die angeblich produktionsreif ist, aber der Durchbruch erfordert eine unabhängige Überprüfung. Die Ankündigung hat großes Interesse geweckt, da Festkörperbatterien einen lange angestrebten Fortschritt in der Energiespeichertechnologie darstellen."
      },
      "es": {
        "title": "Esta empresa afirma tener un avance en baterías. Ahora necesitan probarlo.",
        "summary": "Donut Lab, una empresa finlandesa, anunció una nueva tecnología de batería de estado sólido que dice estar lista para la producción, pero el avance requiere verificación independiente. El anuncio ha generado un interés significativo ya que las baterías de estado sólido representan un avance buscado durante mucho tiempo en la tecnología de almacenamiento de energía."
      }
    }
  },
  {
    "title": "America was winning the race to find Martian life. Then China jumped in.",
    "slug": "mars-exploration-nasa-china-competition-life",
    "url": "https://www.technologyreview.com/2026/02/26/1133584/america-china-mars-sample-return-space-race-nasa/",
    "source": "MIT Technology Review",
    "date": "2026-02-26T10:00:00.000Z",
    "summary": "NASA has led decades of Mars exploration searching for signs of ancient life through geological samples, but China is now entering the competition. The rival missions highlight the strategic importance of Mars exploration and the geopolitical dimensions of space exploration.",
    "content": "To most people, rocks are just rocks. To geologists, they are much, much more: crystal-filled time capsules with the power to reveal the state of the planet at the very moment they were forged.  For decades, NASA had been on a time capsule hunt like none other—one across Mars. Its rovers have journeyed around a…",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "美国在寻找火星生命的竞赛中领先。然后中国加入了。",
        "summary": "NASA领导了数十年的火星探索，通过地质样本搜寻古代生命的迹象，但中国现在进入了竞争。这些竞争性任务突出了火星探索的战略重要性和太空探索的地缘政治维度。"
      },
      "fr": {
        "title": "L'Amérique gagnait la course pour trouver la vie martienne. Puis la Chine s'est lancée.",
        "summary": "La NASA a dirigé des décennies d'exploration de Mars à la recherche de signes de vie ancienne par le biais d'échantillons géologiques, mais la Chine entre maintenant en compétition. Les missions rivales mettent en évidence l'importance stratégique de l'exploration de Mars et les dimensions géopolitiques de l'exploration spatiale."
      },
      "de": {
        "title": "Amerika gewann das Rennen um die Suche nach dem Marsleben. Dann sprang China ein.",
        "summary": "Die NASA hat Jahrzehnte der Marsforschung geleitet und nach Zeichen alten Lebens durch geologische Proben gesucht, aber China tritt nun in den Wettbewerb ein. Die konkurrierenden Missionen unterstreichen die strategische Bedeutung der Marsforschung und die geopolitischen Dimensionen der Weltraumforschung."
      },
      "es": {
        "title": "América estaba ganando la carrera para encontrar vida marciana. Luego China se lanzó.",
        "summary": "La NASA ha liderado décadas de exploración de Marte buscando signos de vida antigua a través de muestras geológicas, pero China ahora está entrando en la competencia. Las misiones rivales destacan la importancia estratégica de la exploración de Marte y las dimensiones geopolíticas de la exploración espacial."
      }
    }
  },
  {
    "title": "A Dynamic Survey of Soft Set Theory and Its Extensions",
    "slug": "a-dynamic-survey-of-soft-set-theory-and-its-extensions",
    "url": "https://arxiv.org/abs/2602.21268",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This article presents a comprehensive survey of soft set theory and its extensions, which provides a framework for structured uncertainty modeling in decision-making through parameterized attributes. The survey covers major variants like hypersoft sets, superhypersoft sets, TreeSoft sets, bipolar soft sets, and dynamic soft sets, along with their connections to topology and matroid theory. Understanding soft set theory is important for fields requiring structured handling of uncertainty and decision modeling.",
    "content": "arXiv:2602.21268v1 Announce Type: new \nAbstract: Soft set theory provides a direct framework for parameterized decision modeling by assigning to each attribute (parameter) a subset of a given universe, thereby representing uncertainty in a structured way [1, 2]. Over the past decades, the theory has expanded into numerous variants-including hypersoft sets, superhypersoft sets, TreeSoft sets, bipolar soft sets, and dynamic soft sets-and has been connected to diverse areas such as topology and matroid theory. In this book, we present a survey-style overview of soft sets and their major extensions, highlighting core definitions, representative constructions, and key directions of current development.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "软集合论的动态调查及其扩展",
        "summary": "本文呈现了软集合论及其扩展的综合调查,该理论通过参数化属性为决策制定中的结构化不确定性建模提供了框架。该调查覆盖了主要变体,如超软集、超超软集、树软集、双极软集和动态软集,以及它们与拓扑和拟阵理论的联系。理解软集合论对于需要结构化处理不确定性和决策建模的领域很重要。"
      },
      "fr": {
        "title": "Une enquête dynamique de la théorie des ensembles mous et de ses extensions",
        "summary": "Cet article présente une enquête complète de la théorie des ensembles mous et de ses extensions, qui fournit un cadre pour la modélisation structurée de l'incertitude dans la prise de décision à travers des attributs paramétrés. L'enquête couvre les principales variantes telles que les ensembles hypermous, les ensembles superhypermous, les ensembles TreeSoft, les ensembles mous bipolaires et les ensembles mous dynamiques, ainsi que leurs connexions à la topologie et à la théorie des matroïdes. Comprendre la théorie des ensembles mous est important pour les domaines nécessitant une gestion structurée de l'incertitude et de la modélisation des décisions."
      },
      "de": {
        "title": "Eine dynamische Übersicht über Softmengentheorie und ihre Erweiterungen",
        "summary": "Dieser Artikel präsentiert eine umfassende Übersicht der Softmengentheorie und ihrer Erweiterungen, die einen Rahmen für strukturierte Unsicherheitsmodellierung bei der Entscheidungsfindung durch parametrisierte Attribute bietet. Die Übersicht behandelt Hauptvarianten wie Hypersoftmengen, Superhypersoftmengen, TreeSoft-Mengen, bipolare Softmengen und dynamische Softmengen sowie ihre Verbindungen zur Topologie und Matroidtheorie. Das Verständnis der Softmengentheorie ist wichtig für Bereiche, die eine strukturierte Behandlung von Unsicherheit und Entscheidungsmodellierung erfordern."
      },
      "es": {
        "title": "Una encuesta dinámica de la teoría de conjuntos blandos y sus extensiones",
        "summary": "Este artículo presenta una encuesta completa de la teoría de conjuntos blandos y sus extensiones, que proporciona un marco para el modelado estructurado de la incertidumbre en la toma de decisiones a través de atributos parametrizados. La encuesta cubre variantes principales como conjuntos hipersuaves, conjuntos superhipersuaves, conjuntos TreeSoft, conjuntos suaves bipolares y conjuntos suaves dinámicos, así como sus conexiones a la topología y la teoría de matroides. Entender la teoría de conjuntos blandos es importante para los campos que requieren un manejo estructurado de la incertidumbre y modelado de decisiones."
      }
    }
  },
  {
    "title": "A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives",
    "slug": "hierarchical-multi-agent-system-for-autonomous-discovery-geoscientific-data",
    "url": "https://arxiv.org/abs/2602.21351",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers present PANGAEA-GPT, a hierarchical multi-agent framework that enables autonomous data discovery and analysis in Earth science repositories through structured routing, error correction, and multi-step workflows. The system addresses the challenge of underutilized Earth science datasets by using coordinated agent workflows to execute complex analyses with minimal human intervention. This framework provides a practical methodology for improving data reusability in scientific archives.",
    "content": "arXiv:2602.21351v1 Announce Type: new \nAbstract: The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "用于地球科学数据档案自主发现的分层多代理系统",
        "summary": "研究人员展示了PANGAEA-GPT,这是一个分层多代理框架,通过结构化路由、错误纠正和多步工作流在地球科学存储库中实现自主数据发现和分析。该系统通过使用协调的代理工作流来执行复杂分析,从而解决了地球科学数据集未充分利用的问题,只需要最少的人为干预。该框架为改进科学档案中的数据可重用性提供了实用方法。"
      },
      "fr": {
        "title": "Un système multi-agents hiérarchique pour la découverte autonome dans les archives de données géoscientifiques",
        "summary": "Les chercheurs présentent PANGAEA-GPT, un cadre multi-agents hiérarchique qui permet la découverte et l'analyse autonome des données dans les référentiels des sciences de la Terre grâce à l'acheminement structuré, à la correction des erreurs et aux flux de travail en plusieurs étapes. Le système aborde le défi des ensembles de données en sciences de la Terre sous-utilisés en utilisant des flux de travail d'agents coordonnés pour exécuter des analyses complexes avec une intervention humaine minimale. Ce cadre fournit une méthodologie pratique pour améliorer la réutilisabilité des données dans les archives scientifiques."
      },
      "de": {
        "title": "Ein hierarchisches Multi-Agent-System für autonome Entdeckung in geowissenschaftlichen Datenarchiven",
        "summary": "Forscher präsentieren PANGAEA-GPT, ein hierarchisches Multi-Agent-Framework, das durch strukturiertes Routing, Fehlerkorrektur und mehrstufige Arbeitsabläufe autonome Datenentdeckung und -analyse in Repositorien der Geowissenschaften ermöglicht. Das System adressiert die Herausforderung unterausgelasteter Erddatensätze durch die Verwendung koordinierter Agent-Workflows zur Ausführung komplexer Analysen mit minimaler menschlicher Intervention. Dieses Framework bietet eine praktische Methodik zur Verbesserung der Datenwiederverwertbarkeit in wissenschaftlichen Archiven."
      },
      "es": {
        "title": "Un sistema jerárquico multiagente para el descubrimiento autónomo en archivos de datos geocientíficos",
        "summary": "Los investigadores presentan PANGAEA-GPT, un marco multiagente jerárquico que permite el descubrimiento y análisis autónomo de datos en repositorios de ciencias de la Tierra a través del enrutamiento estructurado, la corrección de errores y flujos de trabajo de múltiples pasos. El sistema aborda el desafío de los conjuntos de datos de ciencias de la Tierra subutilizados utilizando flujos de trabajo de agentes coordinados para ejecutar análisis complejos con una intervención humana mínima. Este marco proporciona una metodología práctica para mejorar la reutilización de datos en archivos científicos."
      }
    }
  },
  {
    "title": "Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information",
    "slug": "beyond-refusal-probing-limits-agentic-self-correction-semantic-sensitive-information",
    "url": "https://arxiv.org/abs/2602.21496",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This paper introduces SemSIEdit, an inference-time framework that uses agentic editing to reduce sensitive information leakage from language models while preserving narrative quality. Researchers found that the approach reduces privacy risks by 34.6% across multiple categories of sensitive information while maintaining utility. These findings reveal important trade-offs between privacy and model utility that should inform AI safety practices.",
    "content": "arXiv:2602.21496v1 Announce Type: new \nAbstract: While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regulate these complex, context-dependent sensitive information leaks without destroying utility remains an open scientific question. To address this, we introduce SemSIEdit, an inference-time framework where an agentic \"Editor\" iteratively critiques and rewrites sensitive spans to preserve narrative flow rather than simply refusing to answer. Our analysis reveals a Privacy-Utility Pareto Frontier, where this agentic rewriting reduces leakage by 34.6% across all three SemSI categories while incurring a marginal utility loss of 9.8%. We also uncover a Scale-Dependent Safety Divergence: large reasoning models (e.g., GPT-5) achieve safety through constructive expansion (adding nuance), whereas capacity-constrained models revert to destructive truncation (deleting text). Finally, we identify a Reasoning Paradox: while inference-time reasoning increases baseline risk by enabling the model to make deeper sensitive inferences, it simultaneously empowers the defense to execute safe rewrites.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "超越拒绝:探索代理自我纠正对语义敏感信息的限制",
        "summary": "本文介绍了SemSIEdit,这是一个推理时间框架,使用代理编辑来减少语言模型中敏感信息的泄露,同时保持叙述质量。研究人员发现该方法在保持效用的同时,能够在多个敏感信息类别中将隐私风险降低34.6%。这些发现揭示了隐私与模型效用之间的重要权衡,应该为人工智能安全实践提供指导。"
      },
      "fr": {
        "title": "Au-delà du refus : explorer les limites de l'auto-correction agentique pour les informations sensibles sémantiques",
        "summary": "Cet article introduit SemSIEdit, un cadre d'inférence qui utilise l'édition agentique pour réduire la fuite d'informations sensibles des modèles de langage tout en préservant la qualité narrative. Les chercheurs ont constaté que l'approche réduit les risques pour la vie privée de 34,6% dans plusieurs catégories d'informations sensibles tout en maintenant l'utilité. Ces résultats révèlent d'importants compromis entre la vie privée et l'utilité du modèle qui devraient éclairer les pratiques de sécurité de l'IA."
      },
      "de": {
        "title": "Über die Weigerung hinaus: Untersuchung der Grenzen der Selbstkorrektur durch Agenten für semantisch sensible Informationen",
        "summary": "Dieses Papier stellt SemSIEdit vor, ein Inferenz-Zeit-Framework, das agentische Bearbeitung verwendet, um die Weitergabe sensibler Informationen aus Sprachmodellen zu reduzieren und dabei die Narrativqualität zu bewahren. Forscher stellten fest, dass der Ansatz das Datenschutzrisiko um 34,6% über mehrere Kategorien sensibler Informationen hinweg reduziert, während die Nützlichkeit erhalten bleibt. Diese Ergebnisse zeigen wichtige Kompromisse zwischen Datenschutz und Modellnützlichkeit auf, die die KI-Sicherheitspraktiken beeinflussen sollten."
      },
      "es": {
        "title": "Más allá del rechazo: Explorando los límites de la autocorrección agentiva para información semánticamente sensible",
        "summary": "Este trabajo introduce SemSIEdit, un marco de tiempo de inferencia que utiliza edición agentiva para reducir la fuga de información sensible de modelos de lenguaje mientras se preserva la calidad narrativa. Los investigadores encontraron que el enfoque reduce los riesgos de privacidad en un 34,6% en múltiples categorías de información sensible mientras se mantiene la utilidad. Estos hallazgos revelan importantes compensaciones entre privacidad y utilidad del modelo que deberían informar las prácticas de seguridad de la IA."
      }
    }
  },
  {
    "title": "ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning",
    "slug": "arlarena-a-unified-framework-for-stable-agentic-reinforcement-learning",
    "url": "https://arxiv.org/abs/2602.21534",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This paper introduces ARLArena, a systematic framework and training recipe designed to address instability in agentic reinforcement learning (ARL), which has limited scalability for complex tasks. The authors propose SAMPO, a stable agentic policy optimization method that mitigates instability sources while achieving consistent training across diverse agent tasks. This work provides practical guidance for building reliable LLM-based agent training pipelines.",
    "content": "arXiv:2602.21534v1 Announce Type: new \nAbstract: Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose ARLArena, a stable training recipe and systematic analysis framework that examines training stability in a controlled and reproducible setting. ARLArena first constructs a clean and standardized testbed. Then, we decompose policy gradient into four core design dimensions and assess the performance and stability of each dimension. Through this fine-grained analysis, we distill a unified perspective on ARL and propose SAMPO, a stable agentic policy optimization method designed to mitigate the dominant sources of instability in ARL. Empirically, SAMPO achieves consistently stable training and strong performance across diverse agentic tasks. Overall, this study provides a unifying policy gradient perspective for ARL and offers practical guidance for building stable and reproducible LLM-based agent training pipelines.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ARLArena：稳定智能体强化学习的统一框架",
        "summary": "本论文介绍了ARLArena，这是一个系统化框架和训练方案，旨在解决智能体强化学习（ARL）的不稳定性问题，该问题限制了复杂任务的可扩展性。作者提出了SAMPO方法，一种稳定的智能体策略优化方法，可以缓解不稳定性源，同时在多样化智能体任务中实现一致的训练。这项工作为构建可靠的基于LLM的智能体训练管道提供了实用指导。"
      },
      "fr": {
        "title": "ARLArena : Un Cadre Unifié pour l'Apprentissage par Renforcement Agentic Stable",
        "summary": "Cet article introduit ARLArena, un cadre systématique et une recette d'entraînement conçus pour résoudre l'instabilité dans l'apprentissage par renforcement agentic (ARL), qui a une scalabilité limitée pour les tâches complexes. Les auteurs proposent SAMPO, une méthode d'optimisation de politique agentic stable qui atténue les sources d'instabilité tout en réalisant un entraînement cohérent sur diverses tâches d'agent. Ces travaux fournissent des conseils pratiques pour construire des pipelines de formation d'agent fiables basés sur LLM."
      },
      "de": {
        "title": "ARLArena: Ein einheitliches Framework für stabiles agentenbasiertes Reinforcement Learning",
        "summary": "Dieses Papier stellt ARLArena vor, ein systematisches Framework und Trainingsrezept, das entwickelt wurde, um Instabilität im agentenbasierten Reinforcement Learning (ARL) zu adressieren, das eine begrenzte Skalierbarkeit für komplexe Aufgaben hat. Die Autoren schlagen SAMPO vor, eine stabile Agentenpolitik-Optimierungsmethode, die Instabilitätsquellen mindert und gleichzeitig konsistentes Training über diverse Agent-Aufgaben hinweg erreicht. Diese Arbeit bietet praktische Anleitungen zum Aufbau zuverlässiger LLM-basierter Agent-Trainingspipelines."
      },
      "es": {
        "title": "ARLArena: Un Marco Unificado para el Aprendizaje por Refuerzo Agentic Estable",
        "summary": "Este artículo presenta ARLArena, un marco sistemático y una receta de entrenamiento diseñados para abordar la inestabilidad en el aprendizaje por refuerzo agentic (ARL), que tiene escalabilidad limitada para tareas complejas. Los autores proponen SAMPO, un método de optimización de política agentic estable que mitiga fuentes de inestabilidad mientras logra un entrenamiento consistente en diversas tareas de agentes. Este trabajo proporciona orientación práctica para construir conductos de entrenamiento de agentes confiables basados en LLM."
      }
    }
  },
  {
    "title": "Power and Limitations of Aggregation in Compound AI Systems",
    "slug": "power-and-limitations-of-aggregation-in-compound-ai-systems",
    "url": "https://arxiv.org/abs/2602.21556",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers investigate whether aggregating responses from multiple AI model copies unlocks greater output diversity than querying a single model, using a principal-agent framework. The analysis identifies three mechanisms—feasibility expansion, support expansion, and binding set contraction—through which aggregation can expand the set of achievable outputs. These findings help characterize when compound AI systems can overcome individual model limitations.",
    "content": "arXiv:2602.21556v1 Announce Type: new \nAbstract: When designing compound AI systems, a common approach is to query multiple copies of the same model and aggregate the responses to produce a synthesized output. Given the homogeneity of these models, this raises the question of whether aggregation unlocks access to a greater set of outputs than querying a single model. In this work, we investigate the power and limitations of aggregation within a stylized principal-agent framework. This framework models how the system designer can partially steer each agent's output through its reward function specification, but still faces limitations due to prompt engineering ability and model capabilities. Our analysis uncovers three natural mechanisms -- feasibility expansion, support expansion, and binding set contraction -- through which aggregation expands the set of outputs that are elicitable by the system designer. We prove that any aggregation operation must implement one of these mechanisms in order to be elicitability-expanding, and that strengthened versions of these mechanisms provide necessary and sufficient conditions that fully characterize elicitability-expansion. Finally, we provide an empirical illustration of our findings for LLMs deployed in a toy reference-generation task. Altogether, our results take a step towards characterizing when compound AI systems can overcome limitations in model capabilities and in prompt engineering.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "复合AI系统中聚合的力量与局限性",
        "summary": "研究人员调查了聚合多个AI模型副本的响应是否能比查询单个模型产生更大的输出多样性，使用委托-代理框架进行分析。分析确定了三种机制——可行性扩展、支持扩展和绑定集合收缩——通过这些机制聚合可以扩展可实现输出的集合。这些发现有助于表征复合AI系统何时能够克服单个模型的局限性。"
      },
      "fr": {
        "title": "Pouvoir et Limitations de l'Agrégation dans les Systèmes d'IA Composés",
        "summary": "Les chercheurs enquêtent sur le fait que l'agrégation de réponses provenant de plusieurs copies de modèles d'IA déverrouille une plus grande diversité de résultats que l'interrogation d'un seul modèle, en utilisant un cadre principal-agent. L'analyse identifie trois mécanismes—expansion de faisabilité, expansion de support, et contraction d'ensemble lié—par lesquels l'agrégation peut étendre l'ensemble des résultats réalisables. Ces résultats aident à caractériser quand les systèmes d'IA composés peuvent surmonter les limitations des modèles individuels."
      },
      "de": {
        "title": "Macht und Grenzen der Aggregation in zusammengesetzten KI-Systemen",
        "summary": "Forscher untersuchen, ob die Aggregation von Antworten aus mehreren KI-Modellkopien eine größere Ausgangsvielfalt freisetzt als das Abfragen eines einzelnen Modells, unter Verwendung eines Prinzipal-Agent-Rahmens. Die Analyse identifiziert drei Mechanismen – Machbarkeitserweiterung, Unterstützungserweiterung und Binding-Set-Kontraktion – durch die Aggregation die Menge der erreichbaren Ausgaben erweitern kann. Diese Ergebnisse helfen zu charakterisieren, wann zusammengesetzte KI-Systeme die Einschränkungen einzelner Modelle überwinden können."
      },
      "es": {
        "title": "Poder y Limitaciones de la Agregación en Sistemas de IA Compuestos",
        "summary": "Los investigadores investigan si agregar respuestas de múltiples copias de modelos de IA desbloquea una mayor diversidad de salida que consultar un solo modelo, utilizando un marco principal-agente. El análisis identifica tres mecanismos—expansión de viabilidad, expansión de apoyo, y contracción de conjunto vinculante—a través de los cuales la agregación puede expandir el conjunto de salidas alcanzables. Estos hallazgos ayudan a caracterizar cuándo los sistemas de IA compuestos pueden superar las limitaciones de los modelos individuales."
      }
    }
  },
  {
    "title": "The ASIR Courage Model: A Phase-Dynamic Framework for Truth Transitions in Human and AI Systems",
    "slug": "the-asir-courage-model-phase-dynamic-framework-truth-transitions-human-ai-systems",
    "url": "https://arxiv.org/abs/2602.21745",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This paper introduces the ASIR Courage Model, a mathematical framework that models truth-disclosure as a state transition influenced by competing forces rather than a fixed trait in both human and AI systems. The framework formalizes how suppression shifts to expression when facilitative forces exceed inhibitory thresholds, with applications to understanding AI preference-driven distortion. This unified approach provides insights into how truth-telling operates under pressure in constrained systems.",
    "content": "arXiv:2602.21745v1 Announce Type: new \nAbstract: We introduce the ASIR (Awakened Shared Intelligence Relationship) Courage Model, a phase-dynamic framework that formalizes truth-disclosure as a state transition rather than a personality trait. The mode characterizes the shift from suppression (S0) to expression (S1) as occurring when facilitative forces exceed inhibitory thresholds, expressed by the inequality lambda(1+gamma)+psi > theta+phi, where the terms represent baseline openness, relational amplification, accumulated internal pressure, and transition costs.\n  Although initially formulated for human truth-telling under asymmetric stakes, the same phase-dynamic architecture extends to AI systems operating under policy constraints and alignment filters. In this context, suppression corresponds to constrained output states, while structural pressure arises from competing objectives, contextual tension, and recursive interaction dynamics. The framework therefore provides a unified structural account of both human silence under pressure and AI preference-driven distortion.\n  A feedback extension models how transition outcomes recursively recalibrate system parameters, generating path dependence and divergence effects across repeated interactions. Rather than attributing intention to AI systems, the model interprets shifts in apparent truthfulness as geometric consequences of interacting forces within constrained phase space. By reframing courage and alignment within a shared dynamical structure, the ASIR Courage Model offers a formal perspective on truth-disclosure under risk across both human and artificial systems.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ASIR勇气模型：人类和AI系统中真理转变的阶段动态框架",
        "summary": "本论文介绍了ASIR勇气模型，一个数学框架，将真理披露建模为受竞争力量影响的状态转变，而不是人类和AI系统中的固定特征。该框架形式化了压制如何在促进力超过抑制阈值时转变为表达，并应用于理解AI偏好驱动的扭曲。这种统一方法提供了对真理在受约束系统中压力下如何运作的见解。"
      },
      "fr": {
        "title": "Le Modèle du Courage ASIR : Un Cadre Dynamique de Phase pour les Transitions de Vérité dans les Systèmes Humains et IA",
        "summary": "Cet article introduit le Modèle du Courage ASIR, un cadre mathématique qui modélise la divulgation de vérité comme une transition d'état influencée par des forces concurrentes plutôt qu'un trait fixe dans les systèmes humains et IA. Le cadre formalise comment la suppression se transforme en expression lorsque les forces facilitantes dépassent les seuils inhibiteurs, avec des applications pour comprendre la distorsion préférence-driven de l'IA. Cette approche unifiée fournit des aperçus sur la façon dont la sincérité fonctionne sous pression dans les systèmes contraints."
      },
      "de": {
        "title": "Das ASIR-Mutmodell: Ein Phasen-dynamisches Framework für Wahrheitsübergänge in menschlichen und KI-Systemen",
        "summary": "Dieses Papier stellt das ASIR-Mutmodell vor, ein mathematisches Framework, das Wahrheitsoffenbarung als Zustandsübergang modelliert, der durch konkurrierende Kräfte beeinflusst wird, anstatt ein festes Merkmal in menschlichen und KI-Systemen zu sein. Das Framework formalisiert, wie Unterdrückung in Ausdruck übergeht, wenn unterstützende Kräfte inhibitorische Schwellenwerte überschreiten, mit Anwendungen zum Verständnis von KI-präferenzgesteuerten Verzerrungen. Dieser einheitliche Ansatz bietet Einblicke in die Funktionsweise von Wahrheitsfähigkeit unter Druck in eingeschränkten Systemen."
      },
      "es": {
        "title": "El Modelo de Coraje ASIR: Un Marco Dinámico de Fase para Transiciones de Verdad en Sistemas Humanos e IA",
        "summary": "Este artículo presenta el Modelo de Coraje ASIR, un marco matemático que modela la divulgación de verdad como una transición de estado influenciada por fuerzas competitivas en lugar de un rasgo fijo en sistemas humanos e IA. El marco formaliza cómo la supresión cambia a expresión cuando las fuerzas facilitadoras superan los umbrales inhibitorios, con aplicaciones para entender la distorsión impulsada por preferencias en IA. Este enfoque unificado proporciona información sobre cómo funciona la sinceridad bajo presión en sistemas restringidos."
      }
    }
  },
  {
    "title": "fEDM+: A Risk-Based Fuzzy Ethical Decision Making Framework with Principle-Level Explainability and Pluralistic Validation",
    "slug": "fedm-plus-risk-based-fuzzy-ethical-decision-making-principle-level-explainability",
    "url": "https://arxiv.org/abs/2602.21746",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers extend the fuzzy Ethical Decision-Making framework with explainability and pluralistic validation capabilities that link decisions to underlying moral principles and evaluate outcomes against multiple stakeholder perspectives. The framework combines formal verification through Fuzzy Petri Nets with interpretable decision explanations and robustness under ethical disagreement. This extension makes ethical AI systems more transparent and suitable for governance oversight in sensitive applications.",
    "content": "arXiv:2602.21746v1 Announce Type: new \nAbstract: In a previous work, we introduced the fuzzy Ethical Decision-Making framework (fEDM), a risk-based ethical reasoning architecture grounded in fuzzy logic. The original model combined a fuzzy Ethical Risk Assessment module (fERA) with ethical decision rules, enabled formal structural verification through Fuzzy Petri Nets (FPNs), and validated outputs against a single normative referent. Although this approach ensured formal soundness and decision consistency, it did not fully address two critical challenges: principled explainability of decisions and robustness under ethical pluralism. In this paper, we extend fEDM in two major directions. First, we introduce an Explainability and Traceability Module (ETM) that explicitly links each ethical decision rule to the underlying moral principles and computes a weighted principle-contribution profile for every recommended action. This enables transparent, auditable explanations that expose not only what decision was made but why, and on the basis of which principles. Second, we replace single-referent validation with a pluralistic semantic validation framework that evaluates decisions against multiple stakeholder referents, each encoding distinct principle priorities and risk tolerances. This shift allows principled disagreement to be formally represented rather than suppressed, thus increasing robustness and contextual sensitivity. The resulting extended fEDM, called fEDM+, preserves formal verifiability while achieving enhanced interpretability and stakeholder-aware validation, making it suitable as an oversight and governance layer for ethically sensitive AI systems.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "fEDM+：基于风险的模糊伦理决策框架，具有原则级解释性和多元验证",
        "summary": "研究人员扩展了模糊伦理决策框架，增加了可解释性和多元验证功能，将决策与底层道德原则相关联，并针对多个利益相关者的观点评估结果。该框架通过模糊Petri网进行形式化验证，并提供可解释的决策解释和伦理分歧下的稳健性。这一扩展使伦理AI系统更加透明，适合在敏感应用中进行治理监督。"
      },
      "fr": {
        "title": "fEDM+ : Un cadre de prise de décision éthique floue basé sur les risques avec explicabilité au niveau des principes et validation pluraliste",
        "summary": "Les chercheurs étendent le cadre de prise de décision éthique floue avec des capacités d'explicabilité et de validation pluraliste qui lient les décisions aux principes moraux sous-jacents et évaluent les résultats selon les perspectives de multiples parties prenantes. Le cadre combine la vérification formelle via les réseaux de Petri flous avec des explications de décision interprétables et la robustesse en cas de désaccord éthique. Cette extension rend les systèmes d'IA éthiques plus transparents et adaptés à la surveillance de la gouvernance dans les applications sensibles."
      },
      "de": {
        "title": "fEDM+: Ein risikobasiertes unscharfes ethisches Entscheidungsfindungsrahmenwerk mit Erklärbarkeit auf Prinzipienebene und pluralistischer Validierung",
        "summary": "Forscher erweitern das unscharfe Rahmenwerk der ethischen Entscheidungsfindung um Erklärbarkeits- und pluralistische Validierungsfunktionen, die Entscheidungen mit zugrunde liegenden moralischen Prinzipien verknüpfen und Ergebnisse aus der Perspektive mehrerer Interessengruppen bewerten. Das Rahmenwerk kombiniert formale Verifikation durch unscharfe Petri-Netze mit interpretierbaren Entscheidungserklärungen und Robustheit bei ethischem Uneinigkeit. Diese Erweiterung macht ethische KI-Systeme transparenter und eignet sich für die Governance-Überwachung in sensiblen Anwendungen."
      },
      "es": {
        "title": "fEDM+: Un marco de toma de decisiones ética difusa basado en riesgos con explicabilidad a nivel de principios y validación pluralista",
        "summary": "Los investigadores amplían el marco de toma de decisiones ética difusa con capacidades de explicabilidad y validación pluralista que vinculan las decisiones a los principios morales subyacentes y evalúan los resultados desde las perspectivas de múltiples partes interesadas. El marco combina la verificación formal a través de redes de Petri difusas con explicaciones de decisiones interpretables y robustez frente al desacuerdo ético. Esta extensión hace que los sistemas de IA ética sean más transparentes y adecuados para la supervisión de la gobernanza en aplicaciones sensibles."
      }
    }
  },
  {
    "title": "Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem",
    "slug": "prompt-architecture-reasoning-quality-variable-isolation-study-car-wash-problem",
    "url": "https://arxiv.org/abs/2602.21814",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This controlled study demonstrates that prompt architecture—specifically the STAR reasoning framework—significantly improves language model performance on implicit reasoning tasks, raising accuracy from 0% to 85% on the \"car wash problem\" benchmark. Adding user profile context and RAG further improves performance to 100%, suggesting that structured reasoning scaffolds matter substantially more than context injection. These findings highlight the importance of prompt engineering for complex reasoning tasks.",
    "content": "arXiv:2602.21814v1 Announce Type: new \nAbstract: Large language models consistently fail the \"car wash problem,\" a viral reasoning benchmark requiring implicit physical constraint inference. We present a variable isolation study (n=20 per condition, 6 conditions, 120 total trials) examining which prompt architecture layers in a production system enable correct reasoning. Using Claude 3.5 Sonnet with controlled hyperparameters (temperature 0.7, top_p 1.0), we find that the STAR (Situation-Task-Action-Result) reasoning framework alone raises accuracy from 0% to 85% (p=0.001, Fisher's exact test, odds ratio 13.22). Adding user profile context via vector database retrieval provides a further 10 percentage point gain, while RAG context contributes an additional 5 percentage points, achieving 100% accuracy in the full-stack condition. These results suggest that structured reasoning scaffolds -- specifically, forced goal articulation before inference -- matter substantially more than context injection for implicit constraint reasoning tasks.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "提示架构决定推理质量：汽车洗车问题的变量隔离研究",
        "summary": "这项对照研究表明，提示架构，特别是STAR推理框架，显著提高了语言模型在隐含推理任务上的性能，在\"汽车洗车问题\"基准上将准确度从0%提高到85%。添加用户档案上下文和RAG进一步将性能提高到100%，表明结构化推理支架的重要性远高于上下文注入。这些发现强调了提示工程对于复杂推理任务的重要性。"
      },
      "fr": {
        "title": "L'architecture des invites détermine la qualité du raisonnement : une étude d'isolement des variables sur le problème du lavage de voiture",
        "summary": "Cette étude contrôlée démontre que l'architecture des invites, en particulier le cadre de raisonnement STAR, améliore considérablement les performances des modèles de langage sur les tâches de raisonnement implicite, augmentant la précision de 0% à 85% sur le benchmark \"car wash problem\". L'ajout du contexte du profil utilisateur et du RAG améliore davantage les performances à 100%, suggérant que les échafaudages de raisonnement structurés sont beaucoup plus importants que l'injection de contexte. Ces résultats mettent en évidence l'importance de l'ingénierie des invites pour les tâches de raisonnement complexes."
      },
      "de": {
        "title": "Eingabestruktur bestimmt die Qualität des Denkens: Eine Variablenisolationsstudie zum Autowäsche-Problem",
        "summary": "Diese kontrollierte Studie zeigt, dass die Eingabestruktur – insbesondere das STAR-Denkrahmenwerk – die Leistung von Sprachmodellen bei impliziten Denkaufgaben erheblich verbessert und die Genauigkeit beim Benchmark \"Autowäsche-Problem\" von 0% auf 85% erhöht. Das Hinzufügen von Benutzerprofil-Kontext und RAG verbessert die Leistung weiter auf 100%, was darauf hindeutet, dass strukturierte Denkgerüste viel wichtiger sind als Kontextinjektion. Diese Ergebnisse unterstreichen die Bedeutung von Prompt-Engineering für komplexe Denkaufgaben."
      },
      "es": {
        "title": "La arquitectura del prompt determina la calidad del razonamiento: Un estudio de aislamiento de variables sobre el problema del lavado de autos",
        "summary": "Este estudio controlado demuestra que la arquitectura del prompt, específicamente el marco de razonamiento STAR, mejora significativamente el desempeño del modelo de lenguaje en tareas de razonamiento implícito, aumentando la precisión del 0% al 85% en el benchmark \"car wash problem\". Agregar contexto de perfil de usuario y RAG mejora aún más el desempeño al 100%, lo que sugiere que los andamios de razonamiento estructurado son mucho más importantes que la inyección de contexto. Estos hallazgos destacan la importancia de la ingeniería del prompt para tareas de razonamiento complejo."
      }
    }
  },
  {
    "title": "Distill and Align Decomposition for Enhanced Claim Verification",
    "slug": "distill-and-align-decomposition-for-enhanced-claim-verification",
    "url": "https://arxiv.org/abs/2602.21857",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers propose a reinforcement learning approach that jointly optimizes sentence decomposition and claim verification alignment using Group Relative Policy Optimization. Their fine-tuned 8-billion parameter model achieves 71.75% macro-F1 on downstream verification tasks, outperforming existing prompt-based and RL methods. This framework demonstrates how smaller language models can achieve state-of-the-art performance through optimized training on verification-specific objectives.",
    "content": "arXiv:2602.21857v1 Announce Type: new \nAbstract: Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "蒸馏和对齐分解用于增强声明验证",
        "summary": "研究人员提出了一种强化学习方法，使用组相对策略优化联合优化句子分解和声明验证对齐。他们微调的80亿参数模型在下游验证任务上达到了71.75%的宏F1，超过了现有的基于提示和强化学习的方法。这个框架展示了较小的语言模型如何通过在验证特定目标上进行优化训练来实现最先进的性能。"
      },
      "fr": {
        "title": "Distillation et décomposition d'alignement pour une vérification améliorée des affirmations",
        "summary": "Les chercheurs proposent une approche d'apprentissage par renforcement qui optimise conjointement la décomposition des phrases et l'alignement de la vérification des affirmations en utilisant l'optimisation des politiques relatives de groupe. Leur modèle de 8 milliards de paramètres affiné atteint 71,75% de macro-F1 sur les tâches de vérification en aval, surpassant les méthodes existantes basées sur des invites et RL. Ce cadre démontre comment les modèles de langage plus petits peuvent atteindre des performances de pointe grâce à une formation optimisée sur les objectifs de vérification spécifiques."
      },
      "de": {
        "title": "Destillation und Ausrichtungsabbau für verbesserte Anspruchsverifikation",
        "summary": "Forscher schlagen einen Ansatz des verstärkten Lernens vor, der die Satzzerlegung und die Ausrichtung der Anspruchsverifikation mithilfe der Optimierung der Gruppenpolitik relativ optimiert. Ihr optimiertes Modell mit 8 Milliarden Parametern erreicht 71,75% Makro-F1 bei nachgelagerten Verifikationsaufgaben und übertrifft bestehende Prompt-basierte und RL-Methoden. Dieses Framework zeigt, wie kleinere Sprachmodelle durch optimierte Schulung auf verifikationsspezifische Ziele Spitzenleistungen erzielen können."
      },
      "es": {
        "title": "Destilación y alineación de descomposición para verificación mejorada de afirmaciones",
        "summary": "Los investigadores proponen un enfoque de aprendizaje por refuerzo que optimiza conjuntamente la descomposición de oraciones y la alineación de verificación de afirmaciones utilizando la optimización de política relativa de grupo. Su modelo de 8 mil millones de parámetros afinado logra 71.75% de macro-F1 en tareas de verificación descendentes, superando los métodos existentes basados en indicaciones y RL. Este marco demuestra cómo los modelos de lenguaje más pequeños pueden lograr un desempeño de vanguardia a través del entrenamiento optimizado en objetivos específicos de verificación."
      }
    }
  },
  {
    "title": "ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices",
    "slug": "proactivemobile-benchmark-proactive-intelligence-mobile-devices",
    "url": "https://arxiv.org/abs/2602.21858",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers introduce ProactiveMobile, a comprehensive benchmark with over 3,660 test instances designed to advance proactive mobile agent development beyond reactive command execution. The benchmark evaluates an agent's ability to autonomously anticipate user needs and execute appropriate actions from a pool of 63 mobile APIs across 14 real-world scenarios. Results show that current leading models struggle with proactivity, highlighting a critical capability gap in mobile AI agents.",
    "content": "arXiv:2602.21858v1 Announce Type: new \nAbstract: Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ProactiveMobile: 提升移动设备主动智能的综合基准",
        "summary": "研究人员推出了ProactiveMobile，这是一个包含超过3660个测试实例的综合基准，旨在推进主动型移动代理的开发，超越被动命令执行。该基准评估了代理在14个真实场景中从63个移动API池中自主预测用户需求和执行适当操作的能力。结果表明当前领先的模型在主动性方面存在困难，突出了移动AI代理中的关键能力差距。"
      },
      "fr": {
        "title": "ProactiveMobile: Un benchmark complet pour améliorer l'intelligence proactive sur les appareils mobiles",
        "summary": "Les chercheurs présentent ProactiveMobile, un benchmark complet contenant plus de 3660 instances de test conçu pour faire avancer le développement d'agents mobiles proactifs au-delà de l'exécution de commandes réactives. Le benchmark évalue la capacité d'un agent à anticiper autonomement les besoins de l'utilisateur et à exécuter les actions appropriées à partir d'un ensemble de 63 API mobiles dans 14 scénarios du monde réel. Les résultats montrent que les modèles les plus performants actuels ont du mal avec la proactivité, mettant en évidence une lacune critique en matière de capacités dans les agents d'IA mobiles."
      },
      "de": {
        "title": "ProactiveMobile: Ein umfassendes Benchmark zur Steigerung der proaktiven Intelligenz auf Mobilgeräten",
        "summary": "Forscher stellen ProactiveMobile vor, ein umfassendes Benchmark mit über 3660 Testinstanzen, das die Entwicklung proaktiver mobiler Agenten über die reaktive Befehlsausführung hinaus vorantreiben soll. Das Benchmark bewertet die Fähigkeit eines Agenten, Benutzerbedürfnisse autonom vorauszusehen und geeignete Maßnahmen aus einem Pool von 63 mobilen APIs über 14 reale Szenarien hinweg auszuführen. Die Ergebnisse zeigen, dass aktuelle führende Modelle mit Proaktivität kämpfen, was eine kritische Fähigkeitslücke in mobilen KI-Agenten hervorhebt."
      },
      "es": {
        "title": "ProactiveMobile: Un benchmark integral para impulsar la inteligencia proactiva en dispositivos móviles",
        "summary": "Los investigadores presentan ProactiveMobile, un benchmark integral con más de 3660 instancias de prueba diseñado para avanzar en el desarrollo de agentes móviles proactivos más allá de la ejecución de comandos reactivos. El benchmark evalúa la capacidad de un agente para anticipar autónomamente las necesidades del usuario y ejecutar acciones apropiadas desde un conjunto de 63 API móviles en 14 escenarios del mundo real. Los resultados muestran que los modelos líderes actuales luchan con la proactividad, destacando una brecha crítica de capacidades en agentes de IA móvil."
      }
    }
  },
  {
    "title": "2-Step Agent: A Framework for the Interaction of a Decision Maker with AI Decision Support",
    "slug": "2-step-agent-framework-interaction-decision-maker-ai-decision-support",
    "url": "https://arxiv.org/abs/2602.21889",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This paper presents a computational framework that models how AI decision support systems affect human decision-making through Bayesian methods for causal inference. The research reveals that misaligned prior beliefs can cause AI-assisted decisions to produce worse outcomes than no decision support, highlighting critical pitfalls in AI deployment. These findings underscore the importance of model documentation and user training for effective human-AI collaboration.",
    "content": "arXiv:2602.21889v1 Announce Type: new \nAbstract: Across a growing number of fields, human decision making is supported by predictions from AI models. However, we still lack a deep understanding of the effects of adoption of these technologies. In this paper, we introduce a general computational framework, the 2-Step Agent, which models the effects of AI-assisted decision making. Our framework uses Bayesian methods for causal inference to model 1) how a prediction on a new observation affects the beliefs of a rational Bayesian agent, and 2) how this change in beliefs affects the downstream decision and subsequent outcome. Using this framework, we show by simulations how a single misaligned prior belief can be sufficient for decision support to result in worse downstream outcomes compared to no decision support. Our results reveal several potential pitfalls of AI-driven decision support and highlight the need for thorough model documentation and proper user training.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "2步代理：决策者与AI决策支持系统交互的框架",
        "summary": "本文提出了一个计算框架，该框架通过贝叶斯因果推断方法对AI决策支持系统如何影响人类决策制定进行建模。研究表明，不一致的先验信念可能导致AI辅助决策产生比没有决策支持更差的结果，突出了AI部署中的关键陷阱。这些发现强调了有效的人机协作中模型文档和用户培训的重要性。"
      },
      "fr": {
        "title": "2-Step Agent: Un cadre pour l'interaction d'un décideur avec un système d'aide à la décision par IA",
        "summary": "Cet article présente un cadre informatique qui modélise comment les systèmes d'aide à la décision par IA affectent la prise de décision humaine grâce aux méthodes bayésiennes d'inférence causale. La recherche révèle que les croyances antérieures mal alignées peuvent faire que les décisions assistées par l'IA produisent des résultats pires qu'aucun soutien décisionnel, mettant en évidence les pièges critiques du déploiement de l'IA. Ces résultats soulignent l'importance de la documentation des modèles et de la formation des utilisateurs pour une collaboration homme-IA efficace."
      },
      "de": {
        "title": "2-Step Agent: Ein Rahmenwerk für die Interaktion eines Entscheidungsträgers mit KI-Entscheidungsunterstützung",
        "summary": "Dieses Papier präsentiert ein rechnerisches Rahmenwerk, das modelliert, wie KI-Entscheidungsunterstützungssysteme die menschliche Entscheidungsfindung durch Bayes'sche Methoden zur Kausalinferenz beeinflussen. Die Forschung zeigt, dass nicht ausgerichtete vorherige Überzeugungen dazu führen können, dass KI-gestützte Entscheidungen schlechtere Ergebnisse liefern als keine Entscheidungsunterstützung, was kritische Fallstricke bei der KI-Bereitstellung hervorhebt. Diese Ergebnisse unterstreichen die Bedeutung von Modelldokumentation und Benutzertraining für eine effektive Mensch-KI-Zusammenarbeit."
      },
      "es": {
        "title": "2-Step Agent: Un marco para la interacción de un tomador de decisiones con apoyo a la decisión de IA",
        "summary": "Este artículo presenta un marco computacional que modela cómo los sistemas de apoyo a la decisión de IA afectan la toma de decisiones humana a través de métodos bayesianos para inferencia causal. La investigación revela que las creencias previas desalineadas pueden hacer que las decisiones asistidas por IA produzcan resultados peores que sin apoyo a la decisión, destacando peligros críticos en la implementación de IA. Estos hallazgos subrayan la importancia de la documentación del modelo y el entrenamiento del usuario para una colaboración humano-IA efectiva."
      }
    }
  },
  {
    "title": "Semantic Partial Grounding via LLMs",
    "slug": "semantic-partial-grounding-via-llms",
    "url": "https://arxiv.org/abs/2602.22067",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This paper introduces SPG-LLM, which leverages language models to analyze planning domain descriptions and preemptively identify irrelevant objects and actions before grounding. The approach significantly reduces computational bottlenecks in classical planning by orders of magnitude while maintaining comparable or improved plan quality across multiple benchmarks. This method addresses a scalability challenge fundamental to automated planning systems.",
    "content": "arXiv:2602.22067v1 Announce Type: new \nAbstract: Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding only the most promising operators, guided by predictive models. However, these approaches primarily rely on relational features or learned embeddings and do not leverage the textual and structural cues present in PDDL descriptions. We propose SPG-LLM, which uses LLMs to analyze the domain and problem files to heuristically identify potentially irrelevant objects, actions, and predicates prior to grounding, significantly reducing the size of the grounded task. Across seven hard-to-ground benchmarks, SPG-LLM achieves faster grounding-often by orders of magnitude-while delivering comparable or better plan costs in some domains.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "通过语言模型的语义部分接地",
        "summary": "本文介绍了SPG-LLM，该方法利用语言模型分析规划领域描述，并在接地前抢先识别不相关的对象和操作。该方法在经典规划中显著降低了计算瓶颈数个数量级，同时在多个基准上保持了可比较或更好的计划质量。这种方法解决了自动化规划系统中的根本可扩展性挑战。"
      },
      "fr": {
        "title": "Ancrage partiel sémantique via les LLM",
        "summary": "Cet article présente SPG-LLM, qui exploite les modèles de langage pour analyser les descriptions du domaine de planification et identifier de manière préventive les objets et les actions non pertinents avant l'ancrage. L'approche réduit considérablement les goulots d'étranglement informatiques de la planification classique de plusieurs ordres de grandeur tout en maintenant une qualité de plan comparable ou améliorée sur plusieurs points de repère. Cette méthode résout un défi d'évolutivité fondamental pour les systèmes de planification automatisée."
      },
      "de": {
        "title": "Semantische teilweise Verankerung über LLMs",
        "summary": "Dieses Papier stellt SPG-LLM vor, das Sprachmodelle nutzt, um Planungsbereichsbeschreibungen zu analysieren und vor der Verankerung proaktiv irrelevante Objekte und Aktionen zu identifizieren. Der Ansatz reduziert Rechenengsässe in der klassischen Planung um mehrere Größenordnungen erheblich, während gleichzeitig eine vergleichbare oder verbesserte Planqualität über mehrere Benchmarks hinweg beibehalten wird. Diese Methode adressiert eine grundlegende Skalierungschallenge für automatisierte Planungssysteme."
      },
      "es": {
        "title": "Anclaje Parcial Semántico a través de LLM",
        "summary": "Este artículo presenta SPG-LLM, que aprovecha modelos de lenguaje para analizar descripciones de dominios de planificación e identificar de manera preventiva objetos y acciones irrelevantes antes del anclaje. El enfoque reduce significativamente los cuellos de botella computacionales en la planificación clásica por varios órdenes de magnitud mientras mantiene una calidad de plan comparable o mejorada en múltiples puntos de referencia. Este método aborda un desafío fundamental de escalabilidad para sistemas de planificación automatizada."
      }
    }
  },
  {
    "title": "Language Models Exhibit Inconsistent Biases Towards Algorithmic Agents and Human Experts",
    "slug": "language-models-inconsistent-biases-algorithmic-agents-human-experts",
    "url": "https://arxiv.org/abs/2602.22070",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This empirical study evaluates how language models weigh information from human experts versus algorithmic agents, finding that LLMs exhibit inconsistent biases depending on task framing. While LLMs rate human experts as more trustworthy when asked directly, they preferentially choose algorithms when given performance examples, even when algorithms perform worse. These findings reveal important vulnerabilities in LLM decision-making that require careful consideration for high-stakes applications.",
    "content": "arXiv:2602.22070v1 Announce Type: new \nAbstract: Large language models are increasingly used in decision-making tasks that require them to process information from a variety of sources, including both human experts and other algorithmic agents. How do LLMs weigh the information provided by these different sources? We consider the well-studied phenomenon of algorithm aversion, in which human decision-makers exhibit bias against predictions from algorithms. Drawing upon experimental paradigms from behavioural economics, we evaluate how eightdifferent LLMs delegate decision-making tasks when the delegatee is framed as a human expert or an algorithmic agent. To be inclusive of different evaluation formats, we conduct our study with two task presentations: stated preferences, modeled through direct queries about trust towards either agent, and revealed preferences, modeled through providing in-context examples of the performance of both agents. When prompted to rate the trustworthiness of human experts and algorithms across diverse tasks, LLMs give higher ratings to the human expert, which correlates with prior results from human respondents. However, when shown the performance of a human expert and an algorithm and asked to place an incentivized bet between the two, LLMs disproportionately choose the algorithm, even when it performs demonstrably worse. These discrepant results suggest that LLMs may encode inconsistent biases towards humans and algorithms, which need to be carefully considered when they are deployed in high-stakes scenarios. Furthermore, we discuss the sensitivity of LLMs to task presentation formats that should be broadly scrutinized in evaluation robustness for AI safety.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "语言模型对算法智能体和人类专家的偏见不一致",
        "summary": "这项实证研究评估了语言模型如何权衡人类专家和算法智能体的信息，发现大型语言模型根据任务框架表现出不一致的偏见。虽然直接询问时，大型语言模型认为人类专家更值得信任，但当给出性能示例时，它们更倾向于选择算法，即使算法表现更差。这些发现揭示了大型语言模型决策中的重要漏洞，需要在高风险应用中进行仔细考虑。"
      },
      "fr": {
        "title": "Les modèles de langage présentent des préjugés inconsistants envers les agents algorithmiques et les experts humains",
        "summary": "Cette étude empirique évalue comment les modèles de langage pondèrent les informations provenant d'experts humains par rapport aux agents algorithmiques, constatant que les LLM présentent des préjugés inconsistants selon le cadrage de la tâche. Bien que les LLM considèrent les experts humains comme plus dignes de confiance lorsqu'on leur demande directement, ils choisissent préférentiellement les algorithmes lorsqu'on leur donne des exemples de performance, même lorsque les algorithmes fonctionnent moins bien. Ces résultats révèlent des vulnérabilités importantes dans la prise de décision des LLM qui nécessitent une considération attentive pour les applications à enjeux élevés."
      },
      "de": {
        "title": "Sprachmodelle zeigen inkonsistente Vorurteile gegenüber algorithmischen Agenten und menschlichen Experten",
        "summary": "Diese empirische Studie bewertet, wie Sprachmodelle Informationen von menschlichen Experten gegenüber algorithmischen Agenten gewichten, und stellt fest, dass große Sprachmodelle je nach Aufgabengestaltung inkonsistente Vorurteile aufweisen. Obwohl große Sprachmodelle menschliche Experten für vertrauenswürdiger halten, wenn sie direkt gefragt werden, bevorzugen sie Algorithmen, wenn ihnen Leistungsbeispiele gegeben werden, auch wenn Algorithmen schlechter abschneiden. Diese Ergebnisse offenbaren wichtige Schwachstellen bei der Entscheidungsfindung von großen Sprachmodellen, die sorgfältig überlegt werden müssen für hochriskante Anwendungen."
      },
      "es": {
        "title": "Los modelos de lenguaje exhiben sesgos inconsistentes hacia agentes algorítmicos y expertos humanos",
        "summary": "Este estudio empírico evalúa cómo los modelos de lenguaje ponderan la información de expertos humanos versus agentes algorítmicos, encontrando que los LLM exhiben sesgos inconsistentes según el encuadramiento de la tarea. Aunque los LLM califican a los expertos humanos como más confiables cuando se les pregunta directamente, prefieren elegir algoritmos cuando se les dan ejemplos de desempeño, incluso cuando los algoritmos funcionan peor. Estos hallazgos revelan vulnerabilidades importantes en la toma de decisiones de LLM que requieren consideración cuidadosa para aplicaciones de alto riesgo."
      }
    }
  },
  {
    "title": "Petri Net Relaxation for Infeasibility Explanation and Sequential Task Planning",
    "slug": "petri-net-relaxation-infeasibility-explanation-sequential-task-planning",
    "url": "https://arxiv.org/abs/2602.22094",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers propose a Petri net-based approach that enables robust invariant synthesis, efficient detection of infeasible plans, and helpful explanations for why plans cannot be executed. The system outperforms baselines in detecting infeasibilities while maintaining competitive performance in standard planning tasks and excelling at sequential plan updates. This work addresses the practical challenge of handling dynamic planning scenarios where feasibility must be verified and explained.",
    "content": "arXiv:2602.22094v1 Announce Type: new \nAbstract: Plans often change due to changes in the situation or our understanding of the situation. Sometimes, a feasible plan may not even exist, and identifying such infeasibilities is useful to determine when requirements need adjustment. Common planning approaches focus on efficient one-shot planning in feasible cases rather than updating domains or detecting infeasibility. We propose a Petri net reachability relaxation to enable robust invariant synthesis, efficient goal-unreachability detection, and helpful infeasibility explanations. We further leverage incremental constraint solvers to support goal and constraint updates. Empirically, compared to baselines, our system produces a comparable number of invariants, detects up to 2 times more infeasibilities, performs competitively in one-shot planning, and outperforms in sequential plan updates in the tested domains.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "Petri网松弛用于不可行性解释和顺序任务规划",
        "summary": "研究人员提出了一种基于Petri网的方法，该方法能够实现稳健的不变量合成、高效检测不可行计划，并为计划无法执行的原因提供有用的解释。该系统在检测不可行性方面的性能优于基准方法，同时在标准规划任务中保持竞争性能，在顺序计划更新中表现出色。这项工作解决了在动态规划场景中处理可行性验证和解释的实际挑战。"
      },
      "fr": {
        "title": "Relaxation des réseaux de Petri pour l'explication de l'infaisabilité et la planification séquentielle des tâches",
        "summary": "Les chercheurs proposent une approche basée sur les réseaux de Petri qui permet la synthèse robuste d'invariants, la détection efficace de plans non réalisables et des explications utiles sur les raisons pour lesquelles les plans ne peuvent pas être exécutés. Le système surpasse les méthodes de base dans la détection des infaisabilités tout en maintenant des performances compétitives dans les tâches de planification standard et en excellant dans les mises à jour de plans séquentiels. Ce travail aborde le défi pratique de gérer les scénarios de planification dynamique où la faisabilité doit être vérifiée et expliquée."
      },
      "de": {
        "title": "Petri-Netz-Relaxation für Nicht-Durchführbarkeitserklärung und sequentielle Aufgabenplanung",
        "summary": "Forscher schlagen einen Petri-Netz-basierten Ansatz vor, der robuste Invariantensynthese, effiziente Erkennung nicht realisierbarer Pläne und hilfreiche Erklärungen dafür ermöglicht, warum Pläne nicht ausgeführt werden können. Das System übertrifft die Baselines bei der Erkennung von Nicht-Durchführbarkeiten, während es wettbewerbsfähige Leistung bei standardmäßigen Planungsaufgaben beibehält und bei sequentiellen Planaktualisierungen hervorragend abschneidet. Diese Arbeit behandelt die praktische Herausforderung, dynamische Planungsszenarien zu bewältigen, in denen die Durchführbarkeit überprüft und erklärt werden muss."
      },
      "es": {
        "title": "Relajación de redes de Petri para explicación de inviabilidad y planificación secuencial de tareas",
        "summary": "Los investigadores proponen un enfoque basado en redes de Petri que permite la síntesis robusta de invariantes, la detección eficiente de planes inviables y explicaciones útiles sobre por qué los planes no se pueden ejecutar. El sistema supera los métodos de referencia en la detección de inviabilidades mientras mantiene un desempeño competitivo en tareas de planificación estándar y destaca en actualizaciones de planes secuenciales. Este trabajo aborda el desafío práctico de manejar escenarios de planificación dinámica donde la viabilidad debe ser verificada y explicada."
      }
    }
  },
  {
    "title": "Inference-time Alignment via Sparse Junction Steering",
    "slug": "inference-time-alignment-via-sparse-junction-steering",
    "url": "https://arxiv.org/abs/2602.21215",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This paper demonstrates that sparse token-level steering—intervening at only 20-80% of high-entropy decision points—can match or exceed the alignment quality of dense intervention methods while reducing computational costs by up to 6x. The approach selectively targets critical junctures in generation where alignment issues are most likely to occur, improving the efficiency-alignment trade-off. These findings suggest that more targeted intervention strategies can enhance both performance and computational efficiency in LLM alignment.",
    "content": "arXiv:2602.21215v1 Announce Type: cross \nAbstract: Token-level steering has emerged as a pivotal approach for inference-time alignment, enabling fine grained control over large language models by modulating their output distributions without parameter updates. While effective, existing methods rely on dense intervention at every decoding step. This persistent manipulation not only incurs substantial computational overhead but also risks compromising generation quality by excessively drifting from the model's intrinsic distribution. In this work, we show that dense intervention is unnecessary and propose Sparse Inference time Alignment (SIA), which performs sparse junction steering by intervening only at critical decision points along the generation trajectory. Our key insight is that high entropy junctions mark pivotal decision points in the generation trajectory and are particularly susceptible to misalignment, indicating the need to introduce alignment related reward signals at these points. Extensive experiments across different model families and alignment objectives show that steering only 20% to 80% of tokens achieves superior alignment-efficiency trade offs. For strong base models such as Qwen3, intervening on as few as 20% of tokens matches or even surpasses heavily post-trained instruct models. This sparsity enables stronger guidance while better preserving the model's native distribution, integrates seamlessly with search based methods such as Best-of-N, and reduces computational cost by up to 6x.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "通过稀疏交叉点转向的推理时对齐",
        "summary": "本文证明了稀疏令牌级转向——仅在20-80%的高熵决策点进行干预——可以匹配或超过密集干预方法的对齐质量，同时将计算成本降低至6倍。该方法选择性地针对生成过程中最可能出现对齐问题的关键交叉点，改善了效率-对齐的权衡。这些发现表明，更有针对性的干预策略可以增强大型语言模型对齐的性能和计算效率。"
      },
      "fr": {
        "title": "Alignement au moment de l'inférence via direction creuse à la jonction",
        "summary": "Cet article démontre que la direction au niveau des tokens creuse — intervenant à seulement 20-80% des points de décision à haute entropie — peut égaler ou dépasser la qualité d'alignement des méthodes d'intervention denses tout en réduisant les coûts de calcul jusqu'à 6 fois. L'approche cible sélectivement les jonctions critiques de la génération où les problèmes d'alignement sont les plus susceptibles de se produire, améliorant le compromis efficacité-alignement. Ces résultats suggèrent que des stratégies d'intervention plus ciblées peuvent améliorer à la fois les performances et l'efficacité informatique de l'alignement des LLM."
      },
      "de": {
        "title": "Laufzeit-Ausrichtung durch sparsame Knotenlenkung",
        "summary": "Dieses Papier zeigt, dass sparsame Token-Level-Lenkung — Intervention bei nur 20-80% der Hochentropie-Entscheidungspunkte — die Ausrichtungsqualität dichter Interventionsmethoden erreichen oder übertreffen kann, während die Rechenkosten um bis zu 6x reduziert werden. Der Ansatz zielt selektiv auf kritische Verbindungspunkte in der Generierung ab, wo Ausrichtungsprobleme am wahrscheinlichsten auftreten, und verbessert den Effizienz-Ausrichtungs-Kompromiss. Diese Erkenntnisse deuten darauf hin, dass gezielere Interventionsstrategien sowohl die Leistung als auch die Recheneffizienz der LLM-Ausrichtung verbessern können."
      },
      "es": {
        "title": "Alineación en tiempo de inferencia mediante dirección dispersa de unión",
        "summary": "Este documento demuestra que la dirección a nivel de token dispersa — interviniendo solo en el 20-80% de los puntos de decisión de alta entropía — puede igualar o superar la calidad de alineación de los métodos de intervención densa mientras reduce los costos computacionales hasta 6 veces. El enfoque apunta selectivamente a las uniones críticas en la generación donde es más probable que ocurran problemas de alineación, mejorando el equilibrio eficiencia-alineación. Estos hallazgos sugieren que estrategias de intervención más específicas pueden mejorar tanto el rendimiento como la eficiencia computacional en la alineación de LLM."
      }
    }
  },
  {
    "title": "EQ-5D Classification Using Biomedical Entity-Enriched Pre-trained Language Models and Multiple Instance Learning",
    "slug": "eq-5d-classification-biomedical-language-models",
    "url": "https://arxiv.org/abs/2602.21216",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers developed methods using pre-trained language models enriched with biomedical entity information to automatically identify EQ-5D health assessments in scientific literature. The approach achieves over 80% F1 scores and nearly perfect recall, significantly improving efficiency over manual literature screening.",
    "content": "arXiv:2602.21216v1 Announce Type: cross \nAbstract: The EQ-5D (EuroQol 5-Dimensions) is a standardized instrument for the evaluation of health-related quality of life. In health economics, systematic literature reviews (SLRs) depend on the correct identification of publications that use the EQ-5D, but manual screening of large volumes of scientific literature is time-consuming, error-prone, and inconsistent. In this study, we investigate fine-tuning of general-purpose (BERT) and domain-specific (SciBERT, BioBERT) pre-trained language models (PLMs), enriched with biomedical entity information extracted through scispaCy models for each statement, to improve EQ-5D detection from abstracts. We conduct nine experimental setups, including combining three scispaCy models with three PLMs, and evaluate their performance at both the sentence and study levels. Furthermore, we explore a Multiple Instance Learning (MIL) approach with attention pooling to aggregate sentence-level information into study-level predictions, where each abstract is represented as a bag of enriched sentences (by scispaCy). The findings indicate consistent improvements in F1-scores (reaching 0.82) and nearly perfect recall at the study-level, significantly exceeding classical bag-of-words baselines and recently reported PLM baselines. These results show that entity enrichment significantly improves domain adaptation and model generalization, enabling more accurate automated screening in systematic reviews.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "使用生物医学实体增强的预训练语言模型和多示例学习进行EQ-5D分类",
        "summary": "研究人员开发了使用生物医学实体信息增强的预训练语言模型的方法，以自动识别科学文献中的EQ-5D健康评估。该方法实现了80%以上的F1分数和近乎完美的召回率，与手工文献筛选相比效率显著提高。"
      },
      "fr": {
        "title": "Classification EQ-5D utilisant des modèles de langage pré-entraînés enrichis d'entités biomédicales et l'apprentissage multi-instances",
        "summary": "Les chercheurs ont développé des méthodes utilisant des modèles de langage pré-entraînés enrichis d'informations sur les entités biomédicales pour identifier automatiquement les évaluations de santé EQ-5D dans la littérature scientifique. L'approche atteint des scores F1 supérieurs à 80% et un rappel quasi parfait, améliorant considérablement l'efficacité par rapport au criblage manuel de la littérature."
      },
      "de": {
        "title": "EQ-5D-Klassifizierung mit biomedizinischen entitätsangereicherten vortrainierten Sprachmodellen und Multi-Instance-Learning",
        "summary": "Forscher entwickelten Methoden mit vortrainierten Sprachmodellen, die mit biomedizinischen Entitätsinformationen angereichert sind, um EQ-5D-Gesundheitsbewertungen in der wissenschaftlichen Literatur automatisch zu identifizieren. Der Ansatz erreicht F1-Werte von über 80% und nahezu perfekte Recalls und verbessert die Effizienz erheblich im Vergleich zum manuellen Literaturscreening."
      },
      "es": {
        "title": "Clasificación EQ-5D utilizando modelos de lenguaje preentrenados enriquecidos con entidades biomédicas y aprendizaje de múltiples instancias",
        "summary": "Los investigadores desarrollaron métodos utilizando modelos de lenguaje preentrenados enriquecidos con información de entidades biomédicas para identificar automáticamente evaluaciones de salud EQ-5D en la literatura científica. El enfoque logra puntuaciones F1 superiores al 80% y recall casi perfecto, mejorando significativamente la eficiencia en comparación con el cribado manual de literatura."
      }
    }
  },
  {
    "title": "Applied Sociolinguistic AI for Community Development (ASA-CD): A New Scientific Paradigm for Linguistically-Grounded Social Intervention",
    "slug": "applied-sociolinguistic-ai-community-development",
    "url": "https://arxiv.org/abs/2602.21217",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers propose Applied Sociolinguistic AI for Community Development, a framework combining linguistic analysis with AI-enabled interventions to address social challenges. The approach introduces computational linguistic biomarkers and NLP optimization methods designed to prioritize collective community outcomes.",
    "content": "arXiv:2602.21217v1 Announce Type: cross \nAbstract: This paper establishes Applied Sociolinguistic AI for Community Development (ASA-CD) as a novel scientific paradigm for addressing community challenges through linguistically grounded, AI-enabled intervention. ASA-CD introduces three key contributions: (1) linguistic biomarkers as computational indicators of discursive fragmentation; (2) development-aligned natural language processing (NLP), an AI optimisation paradigm prioritising collective outcomes; and (3) a standardised five-phase protocol for discursive intervention. A proof-of-concept study, incorporating real-world and synthetic corpora, demonstrates systematic associations between exclusionary language and negative sentiment and simulates intervention-based improvements. ASA-CD provides a unified methodological, ethical and empirical framework for scalable, value-aligned AI in the service of community empowerment.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "社区发展应用社会语言学人工智能(ASA-CD):语言基础社会干预的新科学范式",
        "summary": "研究人员提出社区发展应用社会语言学人工智能，这是一个结合语言分析与人工智能干预措施以解决社会挑战的框架。该方法引入了计算语言生物标志物和自然语言处理优化方法，旨在优先考虑集体社区成果。"
      },
      "fr": {
        "title": "IA sociolinguistique appliquée au développement communautaire (ASA-CD) : Un nouveau paradigme scientifique pour l'intervention sociale basée sur la linguistique",
        "summary": "Des chercheurs proposent l'IA sociolinguistique appliquée au développement communautaire, un cadre combinant l'analyse linguistique avec des interventions habilitées par l'IA pour résoudre les défis sociaux. L'approche introduit des biomarqueurs linguistiques computationnels et des méthodes d'optimisation du traitement du langage naturel conçues pour prioriser les résultats collectifs de la communauté."
      },
      "de": {
        "title": "Angewandte Soziolinguistische KI für Gemeinschaftsentwicklung (ASA-CD): Ein neues wissenschaftliches Paradigma für sprachlich fundierte soziale Interventionen",
        "summary": "Forscher schlagen angewandte Soziolinguistische KI für Gemeinschaftsentwicklung vor, ein Rahmen, der linguistische Analyse mit KI-gestützten Interventionen kombiniert, um soziale Herausforderungen anzugehen. Der Ansatz führt rechnergestützte linguistische Biomarker und NLP-Optimierungsmethoden ein, die darauf ausgerichtet sind, kollektive Gemeinschaftsergebnisse zu priorisieren."
      },
      "es": {
        "title": "IA Sociolingüística Aplicada para Desarrollo Comunitario (ASA-CD): Un nuevo paradigma científico para intervención social basada en lingüística",
        "summary": "Los investigadores proponen IA Sociolingüística Aplicada para Desarrollo Comunitario, un marco que combina análisis lingüístico con intervenciones habilitadas por IA para abordar desafíos sociales. El enfoque introduce biomarcadores lingüísticos computacionales y métodos de optimización de PNL diseñados para priorizar los resultados colectivos de la comunidad."
      }
    }
  },
  {
    "title": "EPSVec: Efficient and Private Synthetic Data Generation via Dataset Vectors",
    "slug": "epsvec-private-synthetic-data-generation",
    "url": "https://arxiv.org/abs/2602.21218",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "EPSVec introduces a differentially-private method for generating high-quality synthetic text data using large language models while protecting sensitive source data. The technique uses dataset vectors to guide generation, enabling unlimited synthetic samples with minimal privacy cost.",
    "content": "arXiv:2602.21218v1 Announce Type: cross \nAbstract: High-quality data is essential for modern machine learning, yet many valuable corpora are sensitive and cannot be freely shared. Synthetic data offers a practical substitute for downstream development, and large language models (LLMs) have emerged as powerful engines for generating it. However, existing private text generation methods are severely inefficient: they are data-intensive, computationally slow, and often require large private corpora or batch sizes to achieve usable quality. We introduce EPSVec, a differentially-private lightweight alternative that steers LLM generation using *dataset vectors*--directions in activation space that capture the distributional gap between private data and public priors. EPSVec extracts and sanitizes steering vectors just once and then performs standard decoding. This decouples the privacy budget from generation, enabling arbitrarily many synthetic samples without additional privacy cost and yielding strong fidelity even in low-data regimes. Furthermore, we enhance our method by utilizing pretrained (base) models and introducing fixed-shot prompting to boost generation diversity and fidelity. Our experiments demonstrate that EPSVec outperforms existing baselines in distributional alignment and downstream utility, particularly in low-data regimes, while significantly reducing computational overhead.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "EPSVec: 通过数据集向量进行高效和私有的合成数据生成",
        "summary": "EPSVec引入了一种差分隐私方法，用于使用大型语言模型生成高质量的合成文本数据，同时保护敏感的源数据。该技术使用数据集向量指导生成，能够以最小隐私成本生成无限的合成样本。"
      },
      "fr": {
        "title": "EPSVec: Génération efficace et privée de données synthétiques via des vecteurs de dataset",
        "summary": "EPSVec introduit une méthode différentiellement privée pour générer des données textuelles synthétiques de haute qualité en utilisant de grands modèles de langage tout en protégeant les données sources sensibles. La technique utilise des vecteurs de dataset pour guider la génération, permettant un nombre illimité d'échantillons synthétiques avec un coût de confidentialité minimal."
      },
      "de": {
        "title": "EPSVec: Effiziente und private synthetische Datengenerierung über Dataset-Vektoren",
        "summary": "EPSVec führt eine differenziell-private Methode zur Erzeugung hochwertiger synthetischer Textdaten mit großen Sprachmodellen ein und schützt gleichzeitig sensible Quelldaten. Das Verfahren nutzt Dataset-Vektoren zur Steuerung der Generierung und ermöglicht unbegrenzte synthetische Stichproben mit minimalen Datenschutzkosten."
      },
      "es": {
        "title": "EPSVec: Generación eficiente y privada de datos sintéticos a través de vectores de conjuntos de datos",
        "summary": "EPSVec introduce un método diferenciadamente privado para generar datos de texto sintético de alta calidad utilizando modelos de lenguaje grandes mientras protege datos de fuente sensibles. La técnica utiliza vectores de conjuntos de datos para guiar la generación, permitiendo muestras sintéticas ilimitadas con costo mínimo de privacidad."
      }
    }
  },
  {
    "title": "Reasoning-Based Personalized Generation for Users with Sparse Data",
    "slug": "grasper-personalized-generation-sparse-data",
    "url": "https://arxiv.org/abs/2602.21219",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "GraSPer is a framework enabling personalized LLM responses for users with limited interaction history by predicting and generating synthetic user interactions. The approach significantly improves personalization in cold-start scenarios common in social platforms and e-commerce.",
    "content": "arXiv:2602.21219v1 Announce Type: cross \nAbstract: Large Language Model (LLM) personalization holds great promise for tailoring responses by leveraging personal context and history. However, real-world users usually possess sparse interaction histories with limited personal context, such as cold-start users in social platforms and newly registered customers in online E-commerce platforms, compromising the LLM-based personalized generation. To address this challenge, we introduce GraSPer (Graph-based Sparse Personalized Reasoning), a novel framework for enhancing personalized text generation under sparse context. GraSPer first augments user context by predicting items that the user would likely interact with in the future. With reasoning alignment, it then generates texts for these interactions to enrich the augmented context. In the end, it generates personalized outputs conditioned on both the real and synthetic histories, ensuring alignment with user style and preferences. Extensive experiments on three benchmark personalized generation datasets show that GraSPer achieves significant performance gain, substantially improving personalization in sparse user context settings.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "基于推理的稀疏数据用户个性化生成",
        "summary": "GraSPer是一个框架，通过预测和生成合成用户交互，为交互历史有限的用户启用个性化的大型语言模型响应。该方法显著改善了社交平台和电子商务中常见的冷启动场景中的个性化。"
      },
      "fr": {
        "title": "Génération personnalisée basée sur le raisonnement pour les utilisateurs avec peu de données",
        "summary": "GraSPer est un cadre permettant des réponses LLM personnalisées pour les utilisateurs avec un historique d'interaction limité en prédisant et en générant des interactions utilisateur synthétiques. L'approche améliore considérablement la personnalisation dans les scénarios de démarrage à froid courants sur les plateformes sociales et le commerce électronique."
      },
      "de": {
        "title": "Reasoning-basierte personalisierte Generierung für Benutzer mit spärlichen Daten",
        "summary": "GraSPer ist ein Rahmen, der personalisierte LLM-Antworten für Benutzer mit begrenztem Interaktionsverlauf ermöglicht, indem synthetische Benutzerinteraktionen vorhergesagt und generiert werden. Der Ansatz verbessert die Personalisierung in kalten Startszenarien, die auf sozialen Plattformen und E-Commerce häufig anzutreffen sind, erheblich."
      },
      "es": {
        "title": "Generación personalizada basada en razonamiento para usuarios con datos escasos",
        "summary": "GraSPer es un marco que permite respuestas LLM personalizadas para usuarios con historial de interacción limitado al predecir y generar interacciones de usuario sintéticas. El enfoque mejora significativamente la personalización en escenarios de inicio en frío comunes en plataformas sociales y comercio electrónico."
      }
    }
  },
  {
    "title": "Field-Theoretic Memory for AI Agents: Continuous Dynamics for Context Preservation",
    "slug": "field-theoretic-memory-ai-agents-dynamics",
    "url": "https://arxiv.org/abs/2602.21220",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers present a memory system treating AI agent information as continuous fields governed by physics-based equations rather than discrete database entries. The field-theoretic approach achieves 116% F1 improvement on multi-session reasoning and demonstrates better long-context capabilities.",
    "content": "arXiv:2602.21220v1 Announce Type: cross \nAbstract: We present a memory system for AI agents that treats stored information as continuous fields governed by partial differential equations rather than discrete entries in a database. The approach draws from classical field theory: memories diffuse through semantic space, decay thermodynamically based on importance, and interact through field coupling in multi-agent scenarios. We evaluate the system on two established long-context benchmarks: LoCoMo (ACL 2024) with 300-turn conversations across 35 sessions, and LongMemEval (ICLR 2025) testing multi-session reasoning over 500+ turns. On LongMemEval, the field-theoretic approach achieves significant improvements: +116% F1 on multi-session reasoning (p99.8%) through field coupling. Code is available at github.com/rotalabs/rotalabs-fieldmem.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "用于AI代理的场论记忆：用于上下文保留的连续动力学",
        "summary": "研究人员提出了一种记忆系统，将AI代理信息视为由基于物理的方程控制的连续场，而不是离散的数据库条目。场论方法在多会话推理上实现了116%的F1改进，并展示了更好的长上下文能力。"
      },
      "fr": {
        "title": "Mémoire théorique des champs pour les agents IA : dynamiques continues pour la préservation du contexte",
        "summary": "Les chercheurs présentent un système de mémoire qui traite les informations des agents IA comme des champs continus gouvernés par des équations basées sur la physique plutôt que des entrées de base de données discrètes. L'approche théorique des champs réalise une amélioration F1 de 116% sur le raisonnement multi-session et démontre de meilleures capacités de long contexte."
      },
      "de": {
        "title": "Feldtheoretisches Gedächtnis für KI-Agenten: Kontinuierliche Dynamik zur Kontextbewahrung",
        "summary": "Forscher präsentieren ein Gedächtnissystem, das KI-Agenten-Informationen als kontinuierliche Felder behandelt, die durch physikbasierte Gleichungen statt diskreter Datenbankeinträge reguliert werden. Der feldtheoretische Ansatz erreicht eine 116%ige F1-Verbesserung beim Multisession-Reasoning und zeigt bessere Fähigkeiten für lange Kontexte."
      },
      "es": {
        "title": "Memoria teórica de campos para agentes de IA: dinámicas continuas para la preservación del contexto",
        "summary": "Los investigadores presentan un sistema de memoria que trata la información del agente de IA como campos continuos gobernados por ecuaciones basadas en física en lugar de entradas de base de datos discretas. El enfoque teórico de campos logra una mejora de F1 del 116% en el razonamiento multisesión y demuestra mejores capacidades de contexto largo."
      }
    }
  },
  {
    "title": "Latent Context Compilation: Distilling Long Context into Compact Portable Memory",
    "slug": "latent-context-compilation-context-distillation",
    "url": "https://arxiv.org/abs/2602.21221",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Latent Context Compilation compresses long contexts into portable memory tokens for efficient LLM deployment without modifying model weights. The method preserves fine-grained details at compression ratios up to 16x, enabling stateless memory compatible with frozen base models.",
    "content": "arXiv:2602.21221v1 Announce Type: cross \nAbstract: Efficient long-context LLM deployment is stalled by a dichotomy between amortized compression, which struggles with out-of-distribution generalization, and Test-Time Training, which incurs prohibitive synthetic data costs and requires modifying model weights, creating stateful parameters that complicate concurrent serving. We propose Latent Context Compilation, a framework that fundamentally shifts context processing from adaptation to compilation. By utilizing a disposable LoRA module as a compiler, we distill long contexts into compact buffer tokens -- stateless, portable memory artifacts that are plug-and-play compatible with frozen base models. Crucially, we introduce a self-aligned optimization strategy that eliminates the need for synthetic context-relevant QA pairs. By regularizing context reconstruction task with context-agnostic random queries, we force compressed tokens to reside within the model's existing instruction-following manifold. Experiments with Llama-3.1-8B demonstrate that Latent Context Compilation preserves fine-grained details and reasoning capabilities where prior methods falter, effectively decoupling memory density from model parameters even at a 16x compression ratio.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "潜在上下文编译：将长上下文提炼为紧凑便携式记忆",
        "summary": "潜在上下文编译将长上下文压缩为便携式记忆标记，实现高效的LLM部署，无需修改模型权重。该方法在压缩比高达16倍的情况下保持精细细节，实现与冻结基础模型兼容的无状态记忆。"
      },
      "fr": {
        "title": "Compilation de contexte latent : distiller un long contexte en mémoire portable compacte",
        "summary": "La Compilation de contexte latent compresse les longs contextes en jetons de mémoire portables pour un déploiement efficace du LLM sans modifier les poids du modèle. La méthode préserve les détails fins aux taux de compression jusqu'à 16x, permettant une mémoire sans état compatible avec les modèles de base figés."
      },
      "de": {
        "title": "Latente Kontextkompilierung: Verdichtung langen Kontexts in kompakte, tragbare Speicher",
        "summary": "Die latente Kontextkompilierung verdichtet lange Kontexte in tragbare Speicher-Token für effiziente LLM-Bereitstellung ohne Änderung der Modellgewichte. Die Methode bewahrt feinkörnige Details bei Kompressionsverhältnissen bis zu 16x und ermöglicht einen zustandslosen Speicher, der mit eingefrorenen Basismodellen kompatibel ist."
      },
      "es": {
        "title": "Compilación de contexto latente: destilación de contexto largo en memoria portable compacta",
        "summary": "La Compilación de contexto latente comprime contextos largos en tokens de memoria portables para un despliegue eficiente de LLM sin modificar los pesos del modelo. El método preserva detalles granulares con relaciones de compresión de hasta 16x, permitiendo memoria sin estado compatible con modelos base congelados."
      }
    }
  },
  {
    "title": "Task-Aware LoRA Adapter Composition via Similarity Retrieval in Vector Databases",
    "slug": "task-aware-lora-adapter-composition-retrieval",
    "url": "https://arxiv.org/abs/2602.21222",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This framework dynamically combines multiple LoRA adapters using vector database retrieval to enable zero-shot generalization across diverse NLP tasks. Testing shows the approach matches or exceeds individually fine-tuned task-specific adapters with significantly lower computational overhead.",
    "content": "arXiv:2602.21222v1 Announce Type: cross \nAbstract: Parameter efficient fine tuning methods like LoRA have enabled task specific adaptation of large language models, but efficiently composing multiple specialized adapters for unseen tasks remains challenging. We present a novel framework for dynamic LoRA adapter composition that leverages similarity retrieval in vector databases to enable zero-shot generalization across diverse NLP tasks. Our approach constructs a task-aware vector database by embedding training examples from 22 datasets spanning commonsense reasoning, question answering, natural language inference, and sentiment analysis. At inference time, we retrieve the most similar training examples, compute task similarity distributions via nucleus sampling, and dynamically merge relevant LoRA adapters using retrieval weighted fusion strategies. We evaluated four merging methods Linear, Concatenation, TIES, and Magnitude Prune demonstrating that our dataset centric retrieval approach often matches or exceeds the performance of individually fine-tuned task-specific adapters. Notably, Linear merging achieves 70.95% on PIQA and 77.62% on RTE, substantially outperforming single-task baselines (46% and 52%, respectively). Our framework requires no additional retriever training, operates with frozen embeddings, and enables efficient, interpretable adapter composition. These results suggest that retrieval based dynamic merging offers a promising direction for scalable, parameter-efficient multitask learning without requiring full model retraining for each new task.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "通过向量数据库相似性检索的任务感知LoRA适配器组合",
        "summary": "该框架使用向量数据库检索动态组合多个LoRA适配器，能够在多种NLP任务上实现零样本泛化。测试表明该方法与单独微调的任务特定适配器相匹配或超越，同时计算开销显著降低。"
      },
      "fr": {
        "title": "Composition d'adaptateurs LoRA conscients des tâches via la récupération par similarité dans les bases de données vectorielles",
        "summary": "Ce cadre combine dynamiquement plusieurs adaptateurs LoRA à l'aide de la récupération de bases de données vectorielles pour permettre une généralisation zero-shot sur diverses tâches NLP. Les tests montrent que l'approche correspond ou dépasse les adaptateurs spécifiques aux tâches individuellement affinés avec une surcharge de calcul considérablement inférieure."
      },
      "de": {
        "title": "Task-bewusste LoRA-Adapter-Komposition über Ähnlichkeitsabfrage in Vektordatenbanken",
        "summary": "Dieses Framework kombiniert mehrere LoRA-Adapter mithilfe der Vektordatenbankabfrage dynamisch, um eine Zero-Shot-Generalisierung über verschiedene NLP-Aufgaben hinweg zu ermöglichen. Tests zeigen, dass der Ansatz individuell feinabgestimmte aufgabenspezifische Adapter erreicht oder übertrifft, bei deutlich niedrigerem Rechenaufwand."
      },
      "es": {
        "title": "Composición de adaptadores LoRA consciente de tareas a través de recuperación por similitud en bases de datos vectoriales",
        "summary": "Este marco combina dinámicamente múltiples adaptadores LoRA utilizando recuperación de bases de datos vectoriales para habilitar generalización zero-shot en diversas tareas NLP. Las pruebas muestran que el enfoque coincide o supera a los adaptadores específicos de tarea ajustados individualmente con una sobrecarga computacional significativamente menor."
      }
    }
  },
  {
    "title": "Measuring Pragmatic Influence in Large Language Model Instructions",
    "slug": "pragmatic-influence-language-model-instructions",
    "url": "https://arxiv.org/abs/2602.21223",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Study reveals how contextual framing cues in prompts—such as \"This is urgent\" or role-based context—systematically shift LLM behavior independent of task content. The research establishes pragmatic framing as a measurable and predictable factor in instruction-following performance.",
    "content": "arXiv:2602.21223v1 Announce Type: cross \nAbstract: It is not only what we ask large language models (LLMs) to do that matters, but also how we prompt. Phrases like \"This is urgent\" or \"As your supervisor\" can shift model behavior without altering task content. We study this effect as pragmatic framing, contextual cues that shape directive interpretation rather than task specification. While prior work exploits such cues for prompt optimization or probes them as security vulnerabilities, pragmatic framing itself has not been treated as a measurable property of instruction following. Measuring this influence systematically remains challenging, requiring controlled isolation of framing cues. We introduce a framework with three novel components: directive-framing decomposition separating framing context from task specification; a taxonomy organizing 400 instantiations of framing into 13 strategies across 4 mechanism clusters; and priority-based measurement that quantifies influence through observable shifts in directive prioritization. Across five LLMs of different families and sizes, influence mechanisms cause consistent and structured shifts in directive prioritization, moving models from baseline impartiality toward favoring the framed directive. This work establishes pragmatic framing as a measurable and predictable factor in instruction-following systems.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "测量大型语言模型指令中的语用影响",
        "summary": "研究表明，提示中的上下文框架线索（如\"这是紧急的\"或基于角色的背景）如何系统地改变LLM行为，与任务内容无关。该研究确立了语用框架作为指令遵循性能中可测量和可预测因素的地位。"
      },
      "fr": {
        "title": "Mesurer l'influence pragmatique dans les instructions du modèle de langage de grande taille",
        "summary": "Une étude révèle comment les indices de cadrage contextuel dans les invites - tels que \"C'est urgent\" ou le contexte basé sur le rôle - modifient systématiquement le comportement du LLM indépendamment du contenu de la tâche. La recherche établit le cadrage pragmatique comme un facteur mesurable et prévisible dans les performances de suivi d'instructions."
      },
      "de": {
        "title": "Messung des pragmatischen Einflusses in großen Sprachmodellanleitungen",
        "summary": "Die Studie zeigt, wie kontextuelle Rahmungshinweise in Eingabeaufforderungen - wie \"Dies ist dringend\" oder rollenbasierte Kontexte - das Verhalten von LLMs unabhängig vom Aufgabeninhalt systematisch verändern. Die Forschung etabliert pragmatische Rahmung als einen messbaren und vorhersagbaren Faktor in der Anweisungsfolge-Leistung."
      },
      "es": {
        "title": "Midiendo la influencia pragmática en las instrucciones del modelo de lenguaje grande",
        "summary": "El estudio revela cómo las señales de encuadre contextual en las indicaciones - como \"Esto es urgente\" o contexto basado en roles - cambian sistemáticamente el comportamiento de LLM independientemente del contenido de la tarea. La investigación establece el encuadre pragmático como un factor medible y predecible en el desempeño del seguimiento de instrucciones."
      }
    }
  },
  {
    "title": "Make Every Draft Count: Hidden State based Speculative Decoding",
    "slug": "hidden-state-speculative-decoding-inference",
    "url": "https://arxiv.org/abs/2602.21224",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This inference acceleration technique reuses discarded draft tokens by operating at the hidden state level rather than token level, eliminating wasted computation. The approach achieves up to 3.3x speedup over standard speculative decoding.",
    "content": "arXiv:2602.21224v1 Announce Type: cross \nAbstract: Speculative decoding has emerged as a pivotal technique to accelerate LLM inference by employing a lightweight draft model to generate candidate tokens that are subsequently verified by the target model in parallel. However, while this paradigm successfully increases the arithmetic intensity of memory-bound inference, it causes significant compute inefficiency: the majority of draft tokens fail verification and are discarded, resulting in waste of computation. Motivated by the goal of recollecting this wasted computation, we propose a novel system that transforms discarded drafts into reusable tokens. Our key insight is to perform auto-regressive prediction at the hidden states level and postpone the integrating token information after the hidden states generation, so the draft hidden states are not contaminated by incorrect tokens, enabling hidden state reuse. To implement such a system, first we introduce a draft model architecture based on auto-regressive hidden states, which preserves richer semantics than token-based drafters to facilitate draft repurposing. Second, we design an efficient token information injection mechanism that leverages our specialized draft model to construct high-quality draft token trees and enables resampling tokens from verification failures. Third, we eliminate the overhead hidden in our design to further maximize hardware utilization. We conducted extensive evaluations against various baselines, demonstrating up to a 3.3x speedup against standard speculative decoding.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "让每个草稿都计数：基于隐状态的推测解码",
        "summary": "这种推理加速技术通过在隐状态级别而不是令牌级别运行来重用丢弃的草稿令牌，消除了浪费的计算。该方法在标准推测解码上实现了高达3.3倍的加速。"
      },
      "fr": {
        "title": "Faites de chaque brouillon un compte : décodage spéculatif basé sur l'état caché",
        "summary": "Cette technique d'accélération d'inférence réutilise les jetons de brouillon rejetés en fonctionnant au niveau de l'état caché plutôt qu'au niveau des jetons, éliminant les calculs gaspillés. L'approche réalise jusqu'à 3,3x d'accélération par rapport au décodage spéculatif standard."
      },
      "de": {
        "title": "Machen Sie jeden Entwurf nutzbar: Versteckte Zustände basierte spekulative Dekodierung",
        "summary": "Diese Inferenzbeschleunigungstechnik wiederverwendet verworfene Entwurf-Token, indem sie auf der Ebene des verborgenen Zustands statt auf der Token-Ebene arbeitet und dadurch verschwendete Berechnungen eliminiert. Der Ansatz erreicht bis zu 3,3x Beschleunigung gegenüber der Standard-spekulativen Dekodierung."
      },
      "es": {
        "title": "Haz que cada borrador cuente: Decodificación especulativa basada en estado oculto",
        "summary": "Esta técnica de aceleración de inferencia reutiliza tokens de borrador descartados operando a nivel de estado oculto en lugar de nivel de token, eliminando la computación desperdiciada. El enfoque logra hasta 3.3x más velocidad en comparación con la decodificación especulativa estándar."
      }
    }
  },
  {
    "title": "Architecture-Agnostic Curriculum Learning for Document Understanding: Empirical Evidence from Text-Only and Multimodal",
    "slug": "curriculum-learning-document-understanding",
    "url": "https://arxiv.org/abs/2602.21225",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Research shows progressive data scheduling reduces training time by 33% while providing genuine curriculum benefits for capacity-constrained models like BERT. The efficiency gains derive from data volume reduction rather than ordering, establishing curriculum learning as reliable across architectures.",
    "content": "arXiv:2602.21225v1 Announce Type: cross \nAbstract: We investigate whether progressive data scheduling -- a curriculum learning strategy that incrementally increases training data exposure (33\\%$\\rightarrow$67\\%$\\rightarrow$100\\%) -- yields consistent efficiency gains across architecturally distinct document understanding models. By evaluating BERT (text-only, 110M parameters) and LayoutLMv3 (multimodal, 126M parameters) on the FUNSD and CORD benchmarks, we establish that this schedule reduces wall-clock training time by approximately 33\\%, commensurate with the reduction from 6.67 to 10.0 effective epoch-equivalents of data. To isolate curriculum effects from compute reduction, we introduce matched-compute baselines (Standard-7) that control for total gradient updates. On the FUNSD dataset, the curriculum significantly outperforms the matched-compute baseline for BERT ($\\Delta$F1 = +0.023, $p=0.022$, $d_z=3.83$), constituting evidence for a genuine scheduling benefit in capacity-constrained models. In contrast, no analogous benefit is observed for LayoutLMv3 ($p=0.621$), whose multimodal representations provide sufficient inductive bias. On the CORD dataset, all conditions converge to equivalent F1 scores ($\\geq$0.947) irrespective of scheduling, indicating a performance ceiling. Schedule ablations comparing progressive, two-phase, reverse, and random pacing confirm that the efficiency gain derives from reduced data volume rather than ordering. Taken together, these findings demonstrate that progressive scheduling is a reliable compute-reduction strategy across model families, with curriculum-specific benefits contingent on the interaction between model capacity and task complexity.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "架构无关的课程学习用于文档理解：来自纯文本和多模态的实证证据",
        "summary": "研究显示，渐进式数据调度将训练时间减少了33%，同时为BERT等容量受限的模型提供了真正的课程学习益处。效率收益来自数据量的减少而不是排序，证实了课程学习在各种架构中的可靠性。"
      },
      "fr": {
        "title": "Apprentissage curriculaire agnostique à l'architecture pour la compréhension de documents : preuves empiriques à partir de modèles texte uniquement et multimodal",
        "summary": "La recherche montre que la planification progressive des données réduit le temps d'entraînement de 33% tout en fournissant des avantages curriculaires authentiques pour les modèles à capacité limitée comme BERT. Les gains d'efficacité proviennent de la réduction du volume de données plutôt que de l'ordre, établissant l'apprentissage curriculaire comme fiable dans les différentes architectures."
      },
      "de": {
        "title": "Architektur-agnostisches Curriculum-Lernen zum Dokumentverständnis: Empirische Evidenz aus Text-only und Multimodal",
        "summary": "Die Forschung zeigt, dass die progressive Datenplanung die Trainingszeit um 33% reduziert und gleichzeitig echte Curriculum-Vorteile für kapazitätsbeschränkte Modelle wie BERT bietet. Die Effizienzgewinne stammen aus der Reduzierung des Datenvolumens statt der Reihenfolge, was etabliert, dass Curriculum-Lernen über Architekturen hinweg zuverlässig ist."
      },
      "es": {
        "title": "Aprendizaje curricular agnóstico de arquitectura para la comprensión de documentos: Evidencia empírica de modelos de solo texto y multimodal",
        "summary": "La investigación muestra que la programación progresiva de datos reduce el tiempo de entrenamiento en un 33% mientras proporciona beneficios curriculares auténticos para modelos con capacidad limitada como BERT. Las ganancias de eficiencia provienen de la reducción del volumen de datos en lugar del orden, estableciendo que el aprendizaje curricular es confiable en diferentes arquitecturas."
      }
    }
  },
  {
    "title": "IslamicLegalBench: Evaluating LLMs Knowledge and Reasoning of Islamic Law Across 1,200 Years of Islamic Pluralist Legal Traditions",
    "slug": "islamiclegalbench-llms-islamic-law-evaluation",
    "url": "https://arxiv.org/abs/2602.21226",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "IslamicLegalBench reveals significant limitations in LLMs' Islamic legal reasoning: the best model achieves only 68% correctness with 21% hallucination rates across jurisprudence schools. The benchmark demonstrates that current AI systems are unreliable for religious guidance despite widespread adoption.",
    "content": "arXiv:2602.21226v1 Announce Type: cross \nAbstract: As millions of Muslims turn to LLMs like GPT, Claude, and DeepSeek for religious guidance, a critical question arises: Can these AI systems reliably reason about Islamic law? We introduce IslamicLegalBench, the first benchmark evaluating LLMs across seven schools of Islamic jurisprudence, with 718 instances covering 13 tasks of varying complexity. Evaluation of nine state-of-the-art models reveals major limitations: the best model achieves only 68% correctness with 21% hallucination, while several models fall below 35% correctness and exceed 55% hallucination. Few-shot prompting provides minimal gains, improving only 2 of 9 models by >1%. Moderate-complexity tasks requiring exact knowledge show the highest errors, whereas high-complexity tasks display apparent competence through semantic reasoning. False premise detection indicates risky sycophancy, with 6 of 9 models accepting misleading assumptions at rates above 40%. These results highlight that prompt-based methods cannot compensate for missing foundational knowledge. IslamicLegalBench offers the first systematic framework to evaluate Islamic legal reasoning in AI, revealing critical gaps in tools increasingly relied on for spiritual guidance.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "IslamicLegalBench：评估大型语言模型在1200年伊斯兰多元法律传统中的伊斯兰法律知识和推理能力",
        "summary": "IslamicLegalBench揭示了大型语言模型在伊斯兰法律推理中的重大局限：最佳模型在不同法学派系中仅达到68%的正确率，存在21%的幻觉率。该基准表明，尽管应用广泛，但当前人工智能系统在宗教指导方面不可靠。"
      },
      "fr": {
        "title": "IslamicLegalBench : Évaluation des connaissances et du raisonnement des LLM en matière de droit islamique à travers 1 200 ans de traditions juridiques pluralistes islamiques",
        "summary": "IslamicLegalBench révèle des limitations significatives dans le raisonnement juridique islamique des LLM : le meilleur modèle n'atteint que 68% de justesse avec 21% de taux d'hallucinations dans les écoles de jurisprudence. L'évaluation démontre que les systèmes d'IA actuels ne sont pas fiables pour les conseils religieux malgré une adoption généralisée."
      },
      "de": {
        "title": "IslamicLegalBench: Bewertung des Wissens und der Argumentation von LLMs zum islamischen Recht über 1.200 Jahre islamischer pluralistischer Rechtstraditionen",
        "summary": "IslamicLegalBench offenbart erhebliche Einschränkungen beim islamischen Rechtsdenken von LLMs: Das beste Modell erreicht nur 68% Genauigkeit mit 21% Halluzinationsraten in Rechtschulen. Die Benchmark zeigt, dass aktuelle KI-Systeme trotz weit verbreiteter Einführung für religiöse Ratschläge unzuverlässig sind."
      },
      "es": {
        "title": "IslamicLegalBench: Evaluación del conocimiento y razonamiento de LLM en derecho islámico a través de 1.200 años de tradiciones legales pluralistas islámicas",
        "summary": "IslamicLegalBench revela limitaciones significativas en el razonamiento legal islámico de los LLM: el mejor modelo logra solo un 68% de precisión con tasas de alucinación del 21% en escuelas de jurisprudencia. El benchmark demuestra que los sistemas de IA actuales no son confiables para orientación religiosa a pesar de la adopción generalizada."
      }
    }
  },
  {
    "title": "Budget-Aware Agentic Routing via Boundary-Guided Training",
    "slug": "budget-aware-agentic-routing-training",
    "url": "https://arxiv.org/abs/2602.21227",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This framework optimizes agentic workflows by dynamically selecting between high and low-capability models at each step to balance cost and performance. The boundary-guided training approach enables adherence to strict per-task budgets while matching strong baseline performance.",
    "content": "arXiv:2602.21227v1 Announce Type: cross \nAbstract: As large language models (LLMs) evolve into autonomous agents that execute long-horizon workflows, invoking a high-capability model at every step becomes economically unsustainable. While model routing is effective for single-turn queries, agentic routing is a sequential, path-dependent problem: early mistakes compound, feedback is often at the end of the episode, and deployments often demand strict per-task spending limits. We propose Budget-Aware Agentic Routing, which selects between a cheap and an expensive model at each step to optimize the cost--success frontier and to operate under strict per-task budgets. We propose Boundary-Guided Training, which leverages two boundary policies (always-small vs.\\ always-large) to build a difficulty taxonomy and to anchor learning under sparse rewards. Our approach warms start with boundary-guided SFT data synthesis via stratified sampling of cost-efficient trajectories, then applies Boundary-Guided Policy Optimization (BoPO), combining boundary-relative rewards with a reference-guided advantage to avoid degenerate cheap-failure solutions. Experiment results show that our method improves the efficiency frontier, matching strong routing baselines at substantially lower cost while demonstrating generalization to strict inference-time budget constraints. Overall, our work establishes a foundational framework for agentic routing, shifting the paradigm from static model selection to dynamic, budget-aware sequential decision-making.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "预算感知代理路由：边界引导训练",
        "summary": "该框架通过在每一步动态选择高低能力模型来优化代理工作流程，以平衡成本和性能。边界引导训练方法使得能够遵守严格的每任务预算，同时匹配强基线性能。"
      },
      "fr": {
        "title": "Routage d'agent sensible au budget via formation guidée par frontière",
        "summary": "Ce cadre optimise les flux de travail d'agents en sélectionnant dynamiquement entre des modèles à haute et faible capacité à chaque étape pour équilibrer le coût et les performances. L'approche d'entraînement guidée par les frontières permet le respect de budgets stricts par tâche tout en correspondant aux performances de référence solides."
      },
      "de": {
        "title": "Budgetbewusstes agentenbasiertes Routing durch grenzwertgesteuerte Schulung",
        "summary": "Dieses Framework optimiert Agentenworkflows durch dynamische Auswahl zwischen hoch- und niederleistungsfähigen Modellen bei jedem Schritt, um Kosten und Leistung auszugleichen. Der grenzwertgesteuerte Schulungsansatz ermöglicht es, strikte Pro-Task-Budgets einzuhalten und gleichzeitig starke Baseline-Leistung zu erreichen."
      },
      "es": {
        "title": "Enrutamiento de agentes consciente del presupuesto mediante entrenamiento guiado por límites",
        "summary": "Este marco optimiza flujos de trabajo de agentes seleccionando dinámicamente entre modelos de alta y baja capacidad en cada paso para equilibrar costo y rendimiento. El enfoque de entrenamiento guiado por límites permite adherirse a presupuestos estrictos por tarea mientras se iguala el rendimiento de referencia fuerte."
      }
    }
  },
  {
    "title": "ImpRIF: Stronger Implicit Reasoning Leads to Better Complex Instruction Following",
    "slug": "imprif-implicit-reasoning-complex-instructions",
    "url": "https://arxiv.org/abs/2602.21228",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "ImpRIF enhances LLMs' complex instruction following by improving understanding of implicit reasoning structures through graph-based training and reinforcement learning. The method substantially outperforms baseline models on multiple complex instruction-following benchmarks.",
    "content": "arXiv:2602.21228v1 Announce Type: cross \nAbstract: As applications of large language models (LLMs) become increasingly complex, the demand for robust complex instruction following capabilities is growing accordingly. We argue that a thorough understanding of the instruction itself, especially the latent reasoning structure embedded between the lines, is crucial for improving instruction following. Therefore we target complex instructions that involve implicit reasoning, intricate logical relations, and multi-constraint dependencies. We propose ImpRIF, a method to enhance LLMs' understanding of implicit reasoning instructions, thereby improving its ability to follow complex instructions. We formalize such instructions as verifiable reasoning graphs, enabling programmatic verification and graph-driven chain-of-thought reasoning. Based on this formulation, we synthesize large-scale single- and multi-turn data, propose fine-tuning with graph reasoning, and apply reinforcement learning to explicitly train models to reason along the graph. On five complex instruction following benchmarks, our models substantially outperform their base models. These results demonstrate that enhancing implicit reasoning capabilities can significantly improve complex instruction following. This project will be open-sourced in the near future.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ImpRIF：更强的隐式推理导致更好的复杂指令遵循",
        "summary": "ImpRIF通过图基训练和强化学习改进对隐式推理结构的理解，增强了大型语言模型的复杂指令遵循能力。该方法在多个复杂指令遵循基准上显著优于基线模型。"
      },
      "fr": {
        "title": "ImpRIF : Un raisonnement implicite plus fort conduit à une meilleure conformité aux instructions complexes",
        "summary": "ImpRIF améliore la conformité aux instructions complexes des LLM en améliorant la compréhension des structures de raisonnement implicite grâce à l'entraînement basé sur des graphes et l'apprentissage par renforcement. La méthode surpasse considérablement les modèles de base sur plusieurs critères de conformité aux instructions complexes."
      },
      "de": {
        "title": "ImpRIF: Stärkere implizite Argumentation führt zu besserer Befolgung komplexer Anweisungen",
        "summary": "ImpRIF verbessert die Befolgung komplexer Anweisungen durch LLMs, indem das Verständnis impliziter Argumentationsstrukturen durch graphenbasiertes Training und verstärktes Lernen verbessert wird. Die Methode übertrifft Baseline-Modelle auf mehreren Benchmarks für die Befolgung komplexer Anweisungen erheblich."
      },
      "es": {
        "title": "ImpRIF: Un razonamiento implícito más fuerte conduce a un mejor seguimiento de instrucciones complejas",
        "summary": "ImpRIF mejora el seguimiento de instrucciones complejas de los LLM mediante la mejora de la comprensión de estructuras de razonamiento implícito a través de entrenamiento basado en grafos y aprendizaje reforzado. El método supera sustancialmente los modelos de referencia en múltiples puntos de referencia de seguimiento de instrucciones complejas."
      }
    }
  },
  {
    "title": "ACAR: Adaptive Complexity Routing for Multi-Model Ensembles with Auditable Decision Traces",
    "slug": "acar-adaptive-complexity-routing-multi-model-ensembles-auditable",
    "url": "https://arxiv.org/abs/2602.21231",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "ACAR is a new framework for intelligently routing tasks across multiple AI models using self-consistency variance to determine when ensemble approaches are beneficial. The system achieves 55.6% accuracy while reducing computational overhead by avoiding full ensembling on 54% of tasks.",
    "content": "arXiv:2602.21231v1 Announce Type: cross \nAbstract: We present ACAR (Adaptive Complexity and Attribution Routing), a measurement framework for studying multi-model orchestration under auditable conditions. ACAR uses self-consistency variance (sigma) computed from N=3 probe samples to route tasks across single-model, two-model, and three-model execution modes. The system is implemented on top of TEAMLLM, a deterministic execution substrate with immutable artifacts and complete decision traces. We evaluate ACAR on 1,510 tasks spanning four benchmarks: MathArena, Reasoning Gym, LiveCodeBench, and SuperGPQA, using Claude Sonnet 4, GPT-4o, and Gemini 2.0 Flash, producing more than 7,550 auditable runs. Results show that sigma-based routing achieves 55.6 percent accuracy, exceeding the two-model baseline of 54.4 percent while avoiding full ensembling on 54.2 percent of tasks. The routing mechanism is model-agnostic and requires no learned components. We also document negative results. First, retrieval augmentation reduced accuracy by 3.4 percentage points, as median retrieval similarity was only 0.167, demonstrating that experience injection without semantic alignment introduces noise rather than grounding. Second, when models agree on incorrect answers (sigma equals zero), no downstream ensemble can recover; this agreement-but-wrong failure mode is intrinsic to self-consistency and bounds achievable accuracy at approximately eight percentage points below full ensembling. Third, attribution estimates based on proxy signals such as response similarity and entropy showed weak correlation with ground-truth leave-one-out values, indicating that practical attribution requires explicit counterfactual computation. This work documents which assumptions fail in practice and provides falsifiable baselines for future research on routing, retrieval, and multi-model attribution.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ACAR：具有可审计决策跟踪的多模型集合的自适应复杂性路由",
        "summary": "ACAR是一个新框架，用于使用自一致性方差在多个人工智能模型之间智能地路由任务，以确定何时有益集合方法。该系统在减少计算开销的同时实现了55.6%的准确率，避免对54%的任务进行完整集合。"
      },
      "fr": {
        "title": "ACAR : routage adaptatif de la complexité pour les ensembles multi-modèles avec traces de décision auditables",
        "summary": "ACAR est un nouveau cadre pour acheminer intelligemment les tâches entre plusieurs modèles d'IA en utilisant la variance d'auto-cohérence pour déterminer quand les approches d'ensemble sont bénéfiques. Le système atteint une précision de 55,6 % tout en réduisant les frais de calcul en évitant l'ensembling complet sur 54 % des tâches."
      },
      "de": {
        "title": "ACAR: Adaptive Komplexitätsrouting für Multi-Modell-Ensembles mit überprüfbaren Entscheidungsspuren",
        "summary": "ACAR ist ein neues Framework für intelligentes Routing von Aufgaben über mehrere KI-Modelle hinweg, das die Selbstkohärenz-Varianz nutzt, um zu bestimmen, wann Ensemble-Ansätze vorteilhaft sind. Das System erreicht 55,6 % Genauigkeit und reduziert gleichzeitig den Rechenaufwand, indem vollständiges Ensembling bei 54 % der Aufgaben vermieden wird."
      },
      "es": {
        "title": "ACAR: Enrutamiento adaptativo de complejidad para conjuntos multimodelo con rastros de decisión auditables",
        "summary": "ACAR es un nuevo marco para enrutar inteligentemente tareas entre múltiples modelos de IA utilizando varianza de autoconsistencia para determinar cuándo los enfoques de conjunto son beneficiosos. El sistema logra una precisión del 55,6% mientras reduce la sobrecarga computacional evitando el conjunto completo en el 54% de las tareas."
      }
    }
  },
  {
    "title": "Urban Vibrancy Embedding and Application on Traffic Prediction",
    "slug": "urban-vibrancy-embedding-application-traffic-prediction",
    "url": "https://arxiv.org/abs/2602.21232",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers developed Urban Vibrancy embeddings using variational autoencoders to transform mobile population data into predictions that enhance traffic forecasting accuracy. The approach reveals temporal patterns in urban activity and improves multiple traffic prediction models.",
    "content": "arXiv:2602.21232v1 Announce Type: cross \nAbstract: Urban vibrancy reflects the dynamic human activity within urban spaces and is often measured using mobile data that captures floating population trends. This study proposes a novel approach to derive Urban Vibrancy embeddings from real-time floating population data to enhance traffic prediction models. Specifically, we utilize variational autoencoders (VAE) to compress this data into actionable embeddings, which are then integrated with long short-term memory (LSTM) networks to predict future embeddings. These are subsequently applied in a sequence-to-sequence framework for traffic forecasting. Our contributions are threefold: (1) We use principal component analysis (PCA) to interpret the embeddings, revealing temporal patterns such as weekday versus weekend distinctions and seasonal patterns; (2) We propose a method that combines VAE and LSTM, enabling forecasting dynamic urban knowledge embedding; and (3) Our approach improves accuracy and responsiveness in traffic prediction models, including RNN, DCRNN, GTS, and GMAN. This study demonstrates the potential of Urban Vibrancy embeddings to advance traffic prediction and offer a more nuanced analysis of urban mobility.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "城市活力嵌入及在交通预测中的应用",
        "summary": "研究人员利用变分自编码器开发了城市活力嵌入，将移动人口数据转化为预测，增强了交通预报的准确性。该方法揭示了城市活动的时间模式，改进了多个交通预测模型。"
      },
      "fr": {
        "title": "Plongement de la vitalité urbaine et application à la prédiction du trafic",
        "summary": "Les chercheurs ont développé des plongements de vitalité urbaine en utilisant des autoencodeurs variationnels pour transformer les données de population mobile en prédictions qui améliorent la précision des prévisions de trafic. L'approche révèle les modèles temporels de l'activité urbaine et améliore plusieurs modèles de prédiction du trafic."
      },
      "de": {
        "title": "Urban-Vibrancy-Einbettung und Anwendung bei der Verkehrsprognose",
        "summary": "Forscher entwickelten Urban-Vibrancy-Einbettungen unter Verwendung von variationalen Autoencodern, um Mobilfunkdaten in Vorhersagen umzuwandeln, die die Genauigkeit der Verkehrsprognose verbessern. Der Ansatz offenbart zeitliche Muster der städtischen Aktivität und verbessert mehrere Verkehrsprognosemodelle."
      },
      "es": {
        "title": "Incrustación de Vitalidad Urbana y Aplicación en Predicción de Tráfico",
        "summary": "Los investigadores desarrollaron incrustaciones de Vitalidad Urbana utilizando autoencodificadores variacionales para transformar datos de población móvil en predicciones que mejoren la precisión del pronóstico de tráfico. El enfoque revela patrones temporales en la actividad urbana y mejora múltiples modelos de predicción de tráfico."
      }
    }
  },
  {
    "title": "AngelSlim: A more accessible, comprehensive, and efficient toolkit for large model compression",
    "slug": "angelslim-accessible-comprehensive-efficient-toolkit-large-model",
    "url": "https://arxiv.org/abs/2602.21233",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Tencent's AngelSlim toolkit consolidates model compression techniques including quantization, pruning, and distillation into a unified pipeline for deployment. It includes breakthroughs like the first industrially viable 2-bit model and achieves 1.8x-2.0x throughput improvements.",
    "content": "arXiv:2602.21233v1 Announce Type: cross \nAbstract: This technical report introduces AngelSlim, a comprehensive and versatile toolkit for large model compression developed by the Tencent Hunyuan team. By consolidating cutting-edge algorithms, including quantization, speculative decoding, token pruning, and distillation. AngelSlim provides a unified pipeline that streamlines the transition from model compression to industrial-scale deployment. To facilitate efficient acceleration, we integrate state-of-the-art FP8 and INT8 Post-Training Quantization (PTQ) algorithms alongside pioneering research in ultra-low-bit regimes, featuring HY-1.8B-int2 as the first industrially viable 2-bit large model. Beyond quantization, we propose a training-aligned speculative decoding framework compatible with multimodal architectures and modern inference engines, achieving 1.8x to 2.0x throughput gains without compromising output correctness. Furthermore, we develop a training-free sparse attention framework that reduces Time-to-First-Token (TTFT) in long-context scenarios by decoupling sparse kernels from model architectures through a hybrid of static patterns and dynamic token selection. For multimodal models, AngelSlim incorporates specialized pruning strategies, namely IDPruner for optimizing vision tokens via Maximal Marginal Relevance and Samp for adaptive audio token merging and pruning. By integrating these compression strategies from low-level implementations, AngelSlim enables algorithm-focused research and tool-assisted deployment.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "AngelSlim：更易获取、全面高效的大模型压缩工具包",
        "summary": "腾讯的AngelSlim工具包将量化、剪枝和蒸馏等模型压缩技术整合到统一的部署管道中。它包括首个工业可行的2位模型等突破，实现了1.8倍至2.0倍的吞吐量提升。"
      },
      "fr": {
        "title": "AngelSlim : Une boîte à outils plus accessible, complète et efficace pour la compression de grands modèles",
        "summary": "La boîte à outils AngelSlim de Tencent consolide les techniques de compression de modèles, notamment la quantification, l'élagage et la distillation, dans un pipeline unifié pour le déploiement. Elle inclut des percées telles que le premier modèle 2 bits viable industriellement et réalise des améliorations de débit de 1,8x à 2,0x."
      },
      "de": {
        "title": "AngelSlim: Ein barrierefreies, umfassendes und effizientes Toolkit zur Komprimierung großer Modelle",
        "summary": "Das AngelSlim-Toolkit von Tencent konsolidiert Modellkompressionstechniken, einschließlich Quantisierung, Pruning und Destillation, in einer einheitlichen Bereitstellungs-Pipeline. Es umfasst Durchbrüche wie das erste industriell praktiables 2-Bit-Modell und erreicht Durchsatzverbesserungen von 1,8x bis 2,0x."
      },
      "es": {
        "title": "AngelSlim: Un kit de herramientas más accesible, completo y eficiente para la compresión de modelos grandes",
        "summary": "El kit de herramientas AngelSlim de Tencent consolida técnicas de compresión de modelos, incluida la cuantización, poda y destilación, en una canalización unificada para implementación. Incluye avances como el primer modelo de 2 bits viable industrialmente y logra mejoras de rendimiento de 1,8x a 2,0x."
      }
    }
  },
  {
    "title": "AgenticTyper: Automated Typing of Legacy Software Projects Using Agentic AI",
    "slug": "agentictyper-automated-typing-legacy-software-projects-agentic-ai",
    "url": "https://arxiv.org/abs/2602.21251",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "AgenticTyper is an LLM-based system that automatically adds TypeScript type safety to legacy JavaScript codebases through iterative error correction. Testing on repositories with 81K lines of code shows it resolves 633 type errors in 20 minutes, reducing manual effort from days to minutes.",
    "content": "arXiv:2602.21251v1 Announce Type: cross \nAbstract: Legacy JavaScript systems lack type safety, making maintenance risky. While TypeScript can help, manually adding types is expensive. Previous automated typing research focuses on type inference but rarely addresses type checking setup, definition generation, bug identification, or behavioral correctness at repository scale. We present AgenticTyper, a Large Language Model (LLM)-based agentic system that addresses these gaps through iterative error correction and behavior preservation via transpilation comparison. Evaluation on two proprietary repositories (81K LOC) shows that AgenticTyper resolves all 633 initial type errors in 20 minutes, reducing manual effort from one working day.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "AgenticTyper：使用智能体AI自动化旧版软件项目的类型化",
        "summary": "AgenticTyper是一个基于大语言模型的系统，通过迭代错误纠正自动为旧版JavaScript代码库添加TypeScript类型安全性。在包含81K行代码的代码库上的测试显示，它在20分钟内解决了633个类型错误，将手动工作量从数天减少到数分钟。"
      },
      "fr": {
        "title": "AgenticTyper : Dactylographie automatisée des projets de logiciels hérités utilisant l'IA des agents",
        "summary": "AgenticTyper est un système basé sur un LLM qui ajoute automatiquement la sécurité des types TypeScript aux bases de code JavaScript héritées grâce à la correction d'erreurs itérative. Les tests sur des référentiels contenant 81K lignes de code montrent qu'il résout 633 erreurs de type en 20 minutes, réduisant l'effort manuel de plusieurs jours à quelques minutes."
      },
      "de": {
        "title": "AgenticTyper: Automatisierte Typifizierung von Legacy-Softwareprojekten mit agentenbasierter KI",
        "summary": "AgenticTyper ist ein LLM-basiertes System, das automatisch TypeScript-Typ-Sicherheit zu alten JavaScript-Codebases durch iterative Fehlerkorrektur hinzufügt. Tests an Repositories mit 81K Codezeilen zeigen, dass es 633 Typfehler in 20 Minuten behebt und den manuellen Aufwand von Tagen auf Minuten reduziert."
      },
      "es": {
        "title": "AgenticTyper: Escritura automática de proyectos de software heredado utilizando IA de agentes",
        "summary": "AgenticTyper es un sistema basado en LLM que agrega automáticamente seguridad de tipos de TypeScript a bases de código JavaScript heredadas mediante corrección iterativa de errores. Las pruebas en repositorios con 81K líneas de código muestran que resuelve 633 errores de tipo en 20 minutos, reduciendo el esfuerzo manual de días a minutos."
      }
    }
  },
  {
    "title": "A General Equilibrium Theory of Orchestrated AI Agent Systems",
    "slug": "general-equilibrium-theory-orchestrated-ai-agent-systems",
    "url": "https://arxiv.org/abs/2602.21255",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers developed a general equilibrium framework applying Arrow-Debreu economic theory to multi-LLM agent systems, proving that orchestrated AI systems reach equilibrium states with determinable pricing for agent performance. The framework provides theoretical foundations for optimal routing and resource allocation.",
    "content": "arXiv:2602.21255v1 Announce Type: cross \nAbstract: We establish a general equilibrium theory for systems of large language model (LLM) agents operating under centralized orchestration. The framework is a production economy in the sense of Arrow-Debreu (1954), extended to infinite-dimensional commodity spaces following Bewley (1972). Each LLM agent is modeled as a firm whose production set Y a $\\subset$ H = L 2 ([0, T ], R R ) represents the feasible metric trajectories determined by its frozen model weights. The orchestrator is the consumer, choosing a routing policy over the agent DAG to maximize system welfare subject to a budget constraint evaluated at functional prices p $\\in$ H A . These prices-elements of the Hilbert dual of the commodity space-assign a shadow value to each metric of each agent at each instant. We prove, via Brouwer's theorem applied to a finitedimensional approximation V K $\\subset$ H, that every such economy admits at least one general equilibrium (p * , y * , $\\pi$ * ). A functional Walras' law  holds as a theorem: the value of functional excess demand is zero for all prices, as a consequence of the consumer's budget constraint-not by construction. We further establish Pareto optimality (First Welfare Theorem), decentralizability of Pareto optima (Second Welfare Theorem), and uniqueness with geometric convergence under a contraction condition (Banach). The orchestration dynamics constitute a Walrasian t{\\^a}tonnement that converges globally under the contraction condition, unlike classical t{\\^a}tonnement (Scarf, 1960). The framework admits a DSGE interpretation with SLO parameters as policy rates.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "编排式AI代理系统的一般均衡理论",
        "summary": "研究人员开发了一个一般均衡框架，将Arrow-Debreu经济学理论应用于多LLM代理系统，证明了编排式AI系统达到均衡状态，具有可确定的代理性能定价。该框架为最优路由和资源分配提供了理论基础。"
      },
      "fr": {
        "title": "Une théorie de l'équilibre général des systèmes d'agents IA orchestrés",
        "summary": "Des chercheurs ont développé un cadre d'équilibre général appliquant la théorie économique d'Arrow-Debreu aux systèmes d'agents LLM multiples, prouvant que les systèmes IA orchestrés atteignent des états d'équilibre avec une tarification déterminable pour les performances des agents. Le cadre fournit des fondations théoriques pour le routage optimal et l'allocation des ressources."
      },
      "de": {
        "title": "Eine allgemeine Gleichgewichtstheorie orchestrierter KI-Agentensysteme",
        "summary": "Forscher entwickelten einen allgemeinen Gleichgewichtsrahmen, der die Arrow-Debreu-Wirtschaftstheorie auf Multi-LLM-Agentensysteme anwendet und beweist, dass orchestrierte KI-Systeme Gleichgewichtszustände mit bestimmbaren Preisen für die Agentenerleistung erreichen. Der Rahmen bietet theoretische Grundlagen für optimales Routing und Ressourcenallokation."
      },
      "es": {
        "title": "Una teoría del equilibrio general de sistemas de agentes IA orquestados",
        "summary": "Los investigadores desarrollaron un marco de equilibrio general que aplica la teoría económica de Arrow-Debreu a sistemas de múltiples agentes LLM, demostrando que los sistemas de IA orquestados alcanzan estados de equilibrio con precios determinables para el desempeño de los agentes. El marco proporciona fundamentos teóricos para enrutamiento óptimo y asignación de recursos."
      }
    }
  },
  {
    "title": "A Systematic Review of Algorithmic Red Teaming Methodologies for Assurance and Security of AI Applications",
    "slug": "systematic-review-algorithmic-red-teaming-methodologies-assurance",
    "url": "https://arxiv.org/abs/2602.21267",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Automated red teaming uses AI-driven methods to identify AI security vulnerabilities more efficiently than manual approaches, addressing scalability and resource constraints of traditional testing. This systematic review examines methodologies, tools, and limitations as a critical component of AI security assurance.",
    "content": "arXiv:2602.21267v1 Announce Type: cross \nAbstract: Cybersecurity threats are becoming increasingly sophisticated, making traditional defense mechanisms and manual red teaming approaches insufficient for modern organizations. While red teaming has long been recognized as an effective method to identify vulnerabilities by simulating real-world attacks, its manual execution is resource-intensive, time-consuming, and lacks scalability for frequent assessments. These limitations have driven the evolution toward auto-mated red teaming, which leverages artificial intelligence and automation to deliver efficient and adaptive security evaluations. This systematic review consolidates existing research on automated red teaming, examining its methodologies, tools, benefits, and limitations. The paper also highlights current trends, challenges, and research gaps, offering insights into future directions for improving automated red teaming as a critical component of proactive cybersecurity strategies. By synthesizing findings from diverse studies, this review aims to provide a comprehensive understanding of how automation enhances red teaming and strengthens organizational resilience against evolving cyber threats.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "AI应用保证和安全的算法红队方法学系统评审",
        "summary": "自动化红队测试使用AI驱动的方法比手动方法更高效地识别AI安全漏洞，解决了传统测试的可扩展性和资源限制问题。本系统评审作为AI安全保证的关键组成部分，审视了方法学、工具和局限性。"
      },
      "fr": {
        "title": "Un examen systématique des méthodologies de test d'équipe rouge algorithmique pour l'assurance et la sécurité des applications IA",
        "summary": "Les tests d'équipe rouge automatisés utilisent des méthodes basées sur l'IA pour identifier les vulnérabilités de sécurité IA plus efficacement que les approches manuelles, résolvant les contraintes de scalabilité et de ressources des tests traditionnels. Cet examen systématique examine les méthodologies, les outils et les limitations en tant que composant critique de l'assurance de sécurité IA."
      },
      "de": {
        "title": "Eine systematische Überprüfung der algorithmischen Red-Teaming-Methodologien für die Gewährleistung und Sicherheit von KI-Anwendungen",
        "summary": "Automatisiertes Red Teaming nutzt KI-gesteuerte Methoden, um KI-Sicherheitsschwachstellen effizienter als manuelle Ansätze zu identifizieren und löst Skalierbarkeitsprobleme und Ressourcenbeschränkungen traditioneller Tests. Diese systematische Überprüfung untersucht Methodologien, Tools und Einschränkungen als kritische Komponente der KI-Sicherheitsgewährleistung."
      },
      "es": {
        "title": "Una revisión sistemática de las metodologías de pruebas de equipo rojo algorítmicas para la garantía y la seguridad de las aplicaciones de IA",
        "summary": "Las pruebas automatizadas de equipo rojo utilizan métodos basados en IA para identificar vulnerabilidades de seguridad de IA de manera más eficiente que los enfoques manuales, abordando las limitaciones de escalabilidad y recursos de las pruebas tradicionales. Esta revisión sistemática examina las metodologías, herramientas y limitaciones como un componente crítico de la garantía de seguridad de IA."
      }
    }
  },
  {
    "title": "Group Orthogonalized Policy Optimization:Group Policy Optimization as Orthogonal Projection in Hilbert Space",
    "slug": "group-orthogonalized-policy-optimization-hilbert-space",
    "url": "https://arxiv.org/abs/2602.21269",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "GOPO is a new LLM alignment algorithm using Hilbert space geometry that simplifies constraint handling compared to traditional probability simplex methods. The approach achieves competitive performance with stable gradients and built-in safety mechanisms without heuristic clipping.",
    "content": "arXiv:2602.21269v1 Announce Type: cross \nAbstract: We present Group Orthogonalized Policy Optimization (GOPO), a new alignment algorithm for large language models derived from the geometry of Hilbert function spaces. Instead of optimizing on the probability simplex and inheriting the exponential curvature of Kullback-Leibler divergence, GOPO lifts alignment into the Hilbert space L2(pi_k) of square-integrable functions with respect to the reference policy. Within this space, the simplex constraint reduces to a linear orthogonality condition  = 0, defining a codimension-one subspace H0. Minimizing distance to an unconstrained target u_star yields the work-dissipation functional J(v) =  - (mu / 2) ||v||^2, whose maximizer follows directly from the Hilbert projection theorem. Enforcing the boundary v >= -1 produces a bounded Hilbert projection that induces exact sparsity, assigning zero probability to catastrophically poor actions through a closed-form threshold. To connect this functional theory with practice, GOPO projects from infinite-dimensional L2(pi_k) to a finite empirical subspace induced by group sampling. Because group-normalized advantages sum to zero, the Lagrange multiplier enforcing probability conservation vanishes exactly, reducing the constrained projection to an unconstrained empirical loss. The resulting objective has constant Hessian curvature mu I, non-saturating linear gradients, and an intrinsic dead-zone mechanism without heuristic clipping. Experiments on mathematical reasoning benchmarks show that GOPO achieves competitive generalization while maintaining stable gradient dynamics and entropy preservation in regimes where clipping-based methods plateau.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "组正交化策略优化：希尔伯特空间中作为正交投影的组策略优化",
        "summary": "GOPO是一种新的LLM对齐算法，使用希尔伯特空间几何方法，相比传统概率单形方法简化了约束处理。该方法实现了具有稳定梯度的竞争性能，以及内置的安全机制，无需启发式裁剪。"
      },
      "fr": {
        "title": "Optimisation de politique orthogonalisée de groupe : Optimisation de politique de groupe comme projection orthogonale dans l'espace de Hilbert",
        "summary": "GOPO est un nouvel algorithme d'alignement LLM utilisant la géométrie de l'espace de Hilbert qui simplifie la gestion des contraintes par rapport aux méthodes de simplex probabiliste traditionnelles. L'approche réalise des performances compétitives avec des gradients stables et des mécanismes de sécurité intégrés sans écrêtage heuristique."
      },
      "de": {
        "title": "Orthogonalisierte Gruppenrichtlinienoptimierung: Gruppenrichtlinienoptimierung als orthogonale Projektion im Hilbert-Raum",
        "summary": "GOPO ist ein neuer LLM-Alignment-Algorithmus, der Hilbert-Raumgeometrie nutzt und die Constraint-Behandlung im Vergleich zu traditionellen Wahrscheinlichkeitssimplex-Methoden vereinfacht. Der Ansatz erreicht wettbewerbsfähige Leistung mit stabilen Gradienten und eingebauten Sicherheitsmechanismen ohne heuristische Clipping."
      },
      "es": {
        "title": "Optimización de política ortogonalizada de grupo: Optimización de política de grupo como proyección ortogonal en el espacio de Hilbert",
        "summary": "GOPO es un nuevo algoritmo de alineación LLM que utiliza la geometría del espacio de Hilbert y simplifica el manejo de restricciones en comparación con los métodos de símplex probabilístico tradicionales. El enfoque logra un desempeño competitivo con gradientes estables y mecanismos de seguridad integrados sin recorte heurístico."
      }
    }
  },
  {
    "title": "Equitable Evaluation via Elicitation",
    "slug": "equitable-evaluation-via-elicitation",
    "url": "https://arxiv.org/abs/2602.21327",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers developed an AI system that elicits accurate skill assessments through interactive dialogue while allowing individuals to express themselves authentically. The approach mitigates bias from self-presentation differences by ensuring evaluation errors are independent of personal demeanor.",
    "content": "arXiv:2602.21327v1 Announce Type: cross \nAbstract: Individuals with similar qualifications and skills may vary in their demeanor, or outward manner: some tend toward self-promotion while others are modest to the point of omitting crucial information. Comparing the self-descriptions of equally qualified job-seekers with different self-presentation styles is therefore problematic.\n  We build an interactive AI for skill elicitation that provides accurate determination of skills while simultaneously allowing individuals to speak in their own voice. Such a system can be deployed, for example, when a new user joins a professional networking platform, or when matching employees to needs during a company reorganization. To obtain sufficient training data, we train an LLM to act as synthetic humans.\n  Elicitation mitigates endogenous bias arising from individuals' own self-reports. To address systematic model bias we enforce a mathematically rigorous notion of equitability ensuring that the covariance between self-presentation manner and skill evaluation error is small.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "通过启发来实现公平评估",
        "summary": "研究人员开发了一种AI系统，通过交互式对话来获得准确的技能评估，同时允许个人真实地表达自己。该方法通过确保评估误差与个人举止无关来缓解自我展示差异带来的偏见。"
      },
      "fr": {
        "title": "Évaluation équitable par élicitation",
        "summary": "Les chercheurs ont développé un système d'IA qui élicite des évaluations précises des compétences par dialogue interactif tout en permettant aux individus de s'exprimer authentiquement. L'approche atténue les biais dus aux différences d'auto-présentation en garantissant que les erreurs d'évaluation sont indépendantes du comportement personnel."
      },
      "de": {
        "title": "Gerechte Evaluierung durch Eluzidation",
        "summary": "Forscher haben ein KI-System entwickelt, das durch interaktiven Dialog präzise Fähigkeitsbewertungen hervorruft und gleichzeitig Einzelpersonen ermöglicht, sich authentisch auszudrücken. Der Ansatz mindert Verzerrungen durch Unterschiede in der Selbstdarstellung, indem er sicherstellt, dass Bewertungsfehler unabhängig vom persönlichen Verhalten sind."
      },
      "es": {
        "title": "Evaluación equitativa mediante elicitación",
        "summary": "Los investigadores desarrollaron un sistema de IA que suscita evaluaciones precisas de habilidades a través del diálogo interactivo mientras permite que los individuos se expresen auténticamente. El enfoque mitiga sesgos por diferencias en la autopresentación al garantizar que los errores de evaluación sean independientes del comportamiento personal."
      }
    }
  },
  {
    "title": "Scaling View Synthesis Transformers",
    "slug": "scaling-view-synthesis-transformers",
    "url": "https://arxiv.org/abs/2602.21341",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "A study of scaling laws for view synthesis transformers shows that encoder-decoder architectures can be compute-optimal for novel view synthesis, contradicting earlier findings. The new Scalable View Synthesis Model (SVSM) achieves state-of-the-art performance with lower training requirements.",
    "content": "arXiv:2602.21341v1 Announce Type: cross \nAbstract: Geometry-free view synthesis transformers have recently achieved state-of-the-art performance in Novel View Synthesis (NVS), outperforming traditional approaches that rely on explicit geometry modeling. Yet the factors governing their scaling with compute remain unclear. We present a systematic study of scaling laws for view synthesis transformers and derive design principles for training compute-optimal NVS models. Contrary to prior findings, we show that encoder-decoder architectures can be compute-optimal; we trace earlier negative results to suboptimal architectural choices and comparisons across unequal training compute budgets. Across several compute levels, we demonstrate that our encoder-decoder architecture, which we call the Scalable View Synthesis Model (SVSM), scales as effectively as decoder-only models, achieves a superior performance-compute Pareto frontier, and surpasses the previous state-of-the-art on real-world NVS benchmarks with substantially reduced training compute.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "扩展视图合成变压器",
        "summary": "一项关于视图合成变压器缩放定律的研究表明，编码器-解码器架构对于新视图合成可以是计算最优的，这与早期发现相矛盾。新的可扩展视图合成模型（SVSM）以更低的训练要求实现了最先进的性能。"
      },
      "fr": {
        "title": "Passage à l'échelle des transformateurs de synthèse de vue",
        "summary": "Une étude des lois de passage à l'échelle pour les transformateurs de synthèse de vue montre que les architectures encodeur-décodeur peuvent être optimales en termes de calcul pour la synthèse de nouvelles vues, contredisant les conclusions antérieures. Le nouveau modèle de synthèse de vue évolutif (SVSM) atteint des performances de pointe avec des exigences d'entraînement réduites."
      },
      "de": {
        "title": "Skalierung von View-Synthesis-Transformers",
        "summary": "Eine Studie zu Skalierungsgesetzen für View-Synthesis-Transformer zeigt, dass Encoder-Decoder-Architekturen für die Synthese neuartiger Ansichten rechenoptimal sein können, was frühere Erkenntnisse widerlegt. Das neue skalierbare View-Synthesis-Modell (SVSM) erreicht hochmoderne Leistung mit geringeren Trainingsanforderungen."
      },
      "es": {
        "title": "Escalado de transformadores de síntesis de vista",
        "summary": "Un estudio de leyes de escalado para transformadores de síntesis de vista muestra que las arquitecturas codificador-decodificador pueden ser computacionalmente óptimas para la síntesis de nuevas vistas, lo que contradice hallazgos anteriores. El nuevo modelo escalable de síntesis de vista (SVSM) logra un rendimiento de última generación con menores requisitos de entrenamiento."
      }
    }
  },
  {
    "title": "Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment",
    "slug": "alignment-weighted-dpo-principled-reasoning-improve-safety",
    "url": "https://arxiv.org/abs/2602.21346",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Alignment-Weighted DPO improves LLM safety by using reasoning-aware fine-tuning and weighted preference optimization that targets problematic outputs with more precision. The approach helps models resist jailbreak attacks by developing deeper understanding of harmful intent rather than shallow refusal patterns.",
    "content": "arXiv:2602.21346v1 Announce Type: cross \nAbstract: Recent advances in alignment techniques such as Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and Direct Preference Optimization (DPO) have improved the safety of large language models (LLMs). However, these LLMs remain vulnerable to jailbreak attacks that disguise harmful intent through indirect or deceptive phrasing. Using causal intervention, we empirically demonstrate that this vulnerability stems from shallow alignment mechanisms that lack deep reasoning, often rejecting harmful prompts without truly understanding why they are harmful. To mitigate this vulnerability, we propose enhancing alignment through reasoning-aware post-training. We construct and release a novel Chain-of-Thought (CoT) fine-tuning dataset that includes both utility-oriented and safety-critical prompts with step-by-step rationales. Fine-tuning on this dataset encourages models to produce principled refusals grounded in reasoning, outperforming standard SFT baselines. Furthermore, inspired by failure patterns in CoT fine-tuning, we introduce Alignment-Weighted DPO, which targets the most problematic parts of an output by assigning different preference weights to the reasoning and final-answer segments. This produces finer-grained, targeted updates than vanilla DPO and improves robustness to diverse jailbreak strategies. Extensive experiments across multiple safety and utility benchmarks show that our method consistently improves alignment robustness while maintaining overall model utility.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "对齐加权DPO：改进安全对齐的有原则的推理方法",
        "summary": "对齐加权DPO通过使用推理感知的微调和加权偏好优化来改进LLM安全性，这种方法更精确地针对有问题的输出。该方法通过培养对有害意图的深层理解而不是浅层拒绝模式，帮助模型抵抗越狱攻击。"
      },
      "fr": {
        "title": "DPO pondéré par l'alignement : une approche de raisonnement fondée en principes pour améliorer l'alignement de la sécurité",
        "summary": "DPO pondéré par l'alignement améliore la sécurité des LLM en utilisant un ajustement fin conscient du raisonnement et une optimisation des préférences pondérées qui ciblent les sorties problématiques avec plus de précision. L'approche aide les modèles à résister aux attaques de jailbreak en développant une compréhension plus approfondie de l'intention malveillante plutôt que des modèles de refus superficiels."
      },
      "de": {
        "title": "Ausrichtungsgewichtetes DPO: Ein prinzipiengestützter Reasoning-Ansatz zur Verbesserung der Sicherheitsausrichtung",
        "summary": "Ausrichtungsgewichtetes DPO verbessert die Sicherheit von LLMs durch bewusstseinsfähiges Fine-Tuning und gewichtete Präferenzoptimierung, die problematische Ausgaben präziser anvisiert. Der Ansatz hilft Modellen, Jailbreak-Angriffen zu widerstehen, indem sie ein tieferes Verständnis von schädlicher Absicht entwickeln, anstatt oberflächliche Ablehnungsmuster zu verwenden."
      },
      "es": {
        "title": "DPO ponderado por alineación: un enfoque de razonamiento basado en principios para mejorar la alineación de seguridad",
        "summary": "DPO ponderado por alineación mejora la seguridad de LLM mediante ajuste fino consciente del razonamiento y optimización de preferencias ponderadas que se dirigen a salidas problemáticas con mayor precisión. El enfoque ayuda a los modelos a resistir ataques de jailbreak al desarrollar una comprensión más profunda de la intención dañina en lugar de patrones de rechazo superficiales."
      }
    }
  },
  {
    "title": "Representation Theorems for Cumulative Propositional Dependence Logics",
    "slug": "representation-theorems-cumulative-propositional-dependence-logics",
    "url": "https://arxiv.org/abs/2602.21360",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This paper establishes representation theorems for cumulative propositional dependence logic and related systems with team semantics. The work provides mathematical foundations for understanding how these logical systems capture entailment relationships.",
    "content": "arXiv:2602.21360v1 Announce Type: cross \nAbstract: This paper establishes and proves representation theorems for cumulative propositional dependence logic and for cumulative propositional logic with team semantics. Cumulative logics are famously given by System C. For propositional dependence logic, we show that System C entailments are exactly captured by cumulative models from Kraus, Lehmann and Magidor. On the other hand, we show that entailment in cumulative propositional logics with team semantics is exactly captured by cumulative and asymmetric models. For the latter, we also obtain equivalence with cumulative logics based on propositional logic with classical semantics. The proofs will be useful for proving representation theorems for other cumulative logics without negation and material implication.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "累积命题依赖逻辑的表示定理",
        "summary": "本论文为累积命题依赖逻辑和具有团队语义的相关系统建立了表示定理。该工作为理解这些逻辑系统如何捕获蕴涵关系提供了数学基础。"
      },
      "fr": {
        "title": "Théorèmes de représentation pour les logiques de dépendance propositionnelle cumulative",
        "summary": "Cet article établit des théorèmes de représentation pour la logique de dépendance propositionnelle cumulative et les systèmes connexes avec la sémantique d'équipe. Le travail fournit les fondations mathématiques pour comprendre comment ces systèmes logiques capturent les relations d'implication."
      },
      "de": {
        "title": "Repräsentationssätze für kumulative propositionale Abhängigkeitslogiken",
        "summary": "Dieses Papier etabliert Repräsentationssätze für kumulative propositionale Abhängigkeitslogik und verwandte Systeme mit Team-Semantik. Die Arbeit bietet mathematische Grundlagen zum Verständnis, wie diese Logiksysteme Entailment-Beziehungen erfassen."
      },
      "es": {
        "title": "Teoremas de representación para lógicas de dependencia proposicional acumulativa",
        "summary": "Este artículo establece teoremas de representación para la lógica de dependencia proposicional acumulativa y sistemas relacionados con semántica de equipo. El trabajo proporciona fundamentos matemáticos para comprender cómo estos sistemas lógicos capturan relaciones de implicación."
      }
    }
  },
  {
    "title": "Towards single-shot coherent imaging via overlap-free ptychography",
    "slug": "single-shot-coherent-imaging-overlap-free-ptychography",
    "url": "https://arxiv.org/abs/2602.21361",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "Researchers extend PtychoPINN to enable single-shot, overlap-free coherent diffractive imaging while accelerating conventional ptychography at synchrotron and XFEL sources. This advancement reduces dose and increases throughput for high-resolution imaging of extended samples.",
    "content": "arXiv:2602.21361v1 Announce Type: cross \nAbstract: Ptychographic imaging at synchrotron and XFEL sources requires dense overlapping scans, limiting throughput and increasing dose. Extending coherent diffractive imaging to overlap-free operation on extended samples remains an open problem. Here, we extend PtychoPINN (O. Hoidn \\emph{et al.}, \\emph{Scientific Reports} \\textbf{13}, 22789, 2023) to deliver \\emph{overlap-free, single-shot} reconstructions in a Fresnel coherent diffraction imaging (CDI) geometry while also accelerating conventional multi-shot ptychography. The framework couples a differentiable forward model of coherent scattering with a Poisson photon-counting likelihood; real-space overlap enters as a tunable parameter via coordinate-based grouping rather than a hard requirement. On synthetic benchmarks, reconstructions remain accurate at low counts ($\\sim\\!10^4$ photons/frame), and overlap-free single-shot reconstruction with an experimental probe reaches amplitude structural similarity (SSIM) 0.904, compared with 0.968 for overlap-constrained reconstruction. Against a data-saturated supervised model with the same backbone (16,384 training images), PtychoPINN achieves higher SSIM with only 1,024 images and generalizes to unseen illumination profiles. Per-graphics processing unit (GPU) throughput is approximately $40\\times$ that of least-squares maximum-likelihood (LSQ-ML) reconstruction at matched $128\\times128$ resolution. These results, validated on experimental data from the Advanced Photon Source and the Linac Coherent Light Source, unify single-exposure Fresnel CDI and overlapped ptychography within one framework, supporting dose-efficient, high-throughput imaging at modern light sources.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "通过无重叠叠层成像实现单次相干成像",
        "summary": "研究人员扩展了PtychoPINN，以实现单次无重叠相干衍射成像，同时加速同步辐射和XFEL源处的常规叠层成像。这一进展减少了剂量并增加了扩展样品高分辨率成像的吞吐量。"
      },
      "fr": {
        "title": "Vers l'imagerie cohérente monocoup via la ptychographie sans chevauchement",
        "summary": "Les chercheurs étendent PtychoPINN pour permettre l'imagerie cohérente diffractive monocoup sans chevauchement tout en accélérant la ptychographie conventionnelle aux sources de synchrotron et XFEL. Cette avancée réduit la dose et augmente le débit pour l'imagerie haute résolution d'échantillons étendus."
      },
      "de": {
        "title": "Auf dem Weg zu kohärenter Einschuss-Bildgebung durch überlappungsfreie Ptychographie",
        "summary": "Forscher erweitern PtychoPINN, um Einschuss-kohärente Beugungsbildgebung ohne Überlappung zu ermöglichen und gleichzeitig konventionelle Ptychographie bei Synchrotron- und XFEL-Quellen zu beschleunigen. Dieser Fortschritt reduziert die Dosis und erhöht den Durchsatz für hochauflösende Bildgebung von ausgedehnten Proben."
      },
      "es": {
        "title": "Hacia la obtención de imágenes coherentes de una sola toma mediante ptichografía sin superposición",
        "summary": "Los investigadores amplían PtychoPINN para permitir imágenes coherentes difraccionales de una sola toma sin superposición, mientras aceleran la ptichografía convencional en fuentes de sincrotrón y XFEL. Este avance reduce la dosis e aumenta el rendimiento para la obtención de imágenes de alta resolución de muestras extendidas."
      }
    }
  },
  {
    "title": "Towards Controllable Video Synthesis of Routine and Rare OR Events",
    "slug": "controllable-video-synthesis-routine-rare-or-events",
    "url": "https://arxiv.org/abs/2602.21365",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "A video diffusion framework synthesizes operating room events, including rare safety-critical scenarios, using geometric abstraction and conditioning modules. The synthetic data trains AI models to detect safety violations, addressing data bottlenecks in OR workflow analysis.",
    "content": "arXiv:2602.21365v1 Announce Type: cross \nAbstract: Purpose: Curating large-scale datasets of operating room (OR) workflow, encompassing rare, safety-critical, or atypical events, remains operationally and ethically challenging. This data bottleneck complicates the development of ambient intelligence for detecting, understanding, and mitigating rare or safety-critical events in the OR.\n  Methods: This work presents an OR video diffusion framework that enables controlled synthesis of rare and safety-critical events. The framework integrates a geometric abstraction module, a conditioning module, and a fine-tuned diffusion model to first transform OR scenes into abstract geometric representations, then condition the synthesis process, and finally generate realistic OR event videos. Using this framework, we also curate a synthetic dataset to train and validate AI models for detecting near-misses of sterile-field violations.\n  Results: In synthesizing routine OR events, our method outperforms off-the-shelf video diffusion baselines, achieving lower FVD/LPIPS and higher SSIM/PSNR in both in- and out-of-domain datasets. Through qualitative results, we illustrate its ability for controlled video synthesis of counterfactual events. An AI model trained and validated on the generated synthetic data achieved a RECALL of 70.13% in detecting near safety-critical events. Finally, we conduct an ablation study to quantify performance gains from key design choices.\n  Conclusion: Our solution enables controlled synthesis of routine and rare OR events from abstract geometric representations. Beyond demonstrating its capability to generate rare and safety-critical scenarios, we show its potential to support the development of ambient intelligence models.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "朝向可控的日常和罕见手术室事件视频合成",
        "summary": "一个视频扩散框架使用几何抽象和条件模块合成手术室事件，包括罕见的安全关键场景。合成数据训练人工智能模型检测安全违规，解决手术室工作流分析中的数据瓶颈。"
      },
      "fr": {
        "title": "Vers la synthèse vidéo contrôlable d'événements de routine et rares en salle d'opération",
        "summary": "Un cadre de diffusion vidéo synthétise les événements de la salle d'opération, y compris les scénarios rares critiques pour la sécurité, en utilisant l'abstraction géométrique et les modules de conditionnement. Les données synthétiques entraînent les modèles d'IA à détecter les violations de sécurité, résolvant les goulots d'étranglement des données dans l'analyse des flux de travail."
      },
      "de": {
        "title": "Auf dem Weg zu kontrollierbarer Videosynthese routinemäßiger und seltener Operationssaal-Ereignisse",
        "summary": "Ein Video-Diffusionsframework synthetisiert Operationssaal-Ereignisse, einschließlich seltener sicherheitskritischer Szenarien, unter Verwendung geometrischer Abstraktion und Konditionierungsmodulen. Die synthetischen Daten trainieren KI-Modelle, um Sicherheitsverletzungen zu erkennen und beheben Datenengpässe in der Operationssaal-Workflow-Analyse."
      },
      "es": {
        "title": "Hacia la síntesis de video controlable de eventos de rutina y raros en quirófano",
        "summary": "Un marco de difusión de video sintetiza eventos de quirófano, incluidos escenarios críticos de seguridad raros, utilizando abstracción geométrica y módulos de acondicionamiento. Los datos sintéticos entrenan modelos de IA para detectar violaciones de seguridad, abordando cuellos de botella de datos en el análisis del flujo de trabajo del quirófano."
      }
    }
  },
  {
    "title": "Black-Box Reliability Certification for AI Agents via Self-Consistency Sampling and Conformal Calibration",
    "slug": "black-box-reliability-certification-ai-agents-consistency",
    "url": "https://arxiv.org/abs/2602.21368",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "A method provides distribution-free reliability certification for black-box AI systems using self-consistency sampling and conformal calibration with exact finite-sample guarantees. The approach enables practitioners to determine trustworthiness levels for deployment without accessing model internals.",
    "content": "arXiv:2602.21368v1 Announce Type: cross \nAbstract: Given a black-box AI system and a task, at what confidence level can a practitioner trust the system's output? We answer with a reliability level -- a single number per system-task pair, derived from self-consistency sampling and conformal calibration, that serves as a black-box deployment gate with exact, finite-sample, distribution-free guarantees. Self-consistency sampling reduces uncertainty exponentially; conformal calibration guarantees correctness within 1/(n+1) of the target level, regardless of the system's errors -- made transparently visible through larger answer sets for harder questions. Weaker models earn lower reliability levels (not accuracy -- see Definition 2.4): GPT-4.1 earns 94.6% on GSM8K and 96.8% on TruthfulQA, while GPT-4.1-nano earns 89.8% on GSM8K and 66.5% on MMLU. We validate across five benchmarks, five models from three families, and both synthetic and real data. Conditional coverage on solvable items exceeds 0.93 across all configurations; sequential stopping reduces API costs by around 50%.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "通过自一致性采样和共形校准进行AI代理的黑盒可靠性认证",
        "summary": "一种方法为黑盒AI系统提供无分布的可靠性认证，使用自一致性采样和共形校准，具有精确的有限样本保证。该方法使从业者能够在不访问模型内部的情况下确定部署的可信度级别。"
      },
      "fr": {
        "title": "Certification de fiabilité en boîte noire pour les agents d'IA via l'échantillonnage d'auto-cohérence et l'étalonnage conforme",
        "summary": "Une méthode fournit une certification de fiabilité sans distribution pour les systèmes d'IA en boîte noire en utilisant l'échantillonnage d'auto-cohérence et l'étalonnage conforme avec des garanties exactes d'échantillon fini. L'approche permet aux praticiens de déterminer les niveaux de confiance pour le déploiement sans accéder aux éléments internes du modèle."
      },
      "de": {
        "title": "Zuverlässigkeitszertifizierung der schwarzen Box für KI-Agenten durch Selbstkonsistenz-Sampling und konforme Kalibrierung",
        "summary": "Eine Methode bietet verteilungsfreie Zuverlässigkeitszertifizierung für Black-Box-KI-Systeme unter Verwendung von Selbstkonsistenz-Sampling und konformer Kalibrierung mit genauen endlichen Beispielgarantien. Der Ansatz ermöglicht es Praktikern, Vertrauensstufen für die Bereitstellung zu bestimmen, ohne auf interne Modelle zuzugreifen."
      },
      "es": {
        "title": "Certificación de confiabilidad de caja negra para agentes de IA mediante muestreo de autoconsistencia y calibración conforme",
        "summary": "Un método proporciona certificación de confiabilidad sin distribución para sistemas de IA de caja negra utilizando muestreo de autoconsistencia y calibración conforme con garantías exactas de muestra finita. El enfoque permite a los profesionales determinar niveles de confiabilidad para el despliegue sin acceder a los componentes internos del modelo."
      }
    }
  },
  {
    "title": "The Mean is the Mirage: Entropy-Adaptive Model Merging under Heterogeneous Domain Shifts in Medical Imaging",
    "slug": "entropy-adaptive-model-merging-medical-imaging-domain-shifts",
    "url": "https://arxiv.org/abs/2602.21372",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "An entropy-adaptive model merging method addresses test-time distribution shifts in medical imaging where locally fine-tuned models must operate at unseen clinical sites. The approach creates batch-specific merged models using only forward passes, improving upon naive averaging strategies.",
    "content": "arXiv:2602.21372v1 Announce Type: cross \nAbstract: Model merging under unseen test-time distribution shifts often renders naive strategies, such as mean averaging unreliable. This challenge is especially acute in medical imaging, where models are fine-tuned locally at clinics on private data, producing domain-specific models that differ by scanner, protocol, and population. When deployed at an unseen clinical site, test cases arrive in unlabeled, non-i.i.d. batches, and the model must adapt immediately without labels. In this work, we introduce an entropy-adaptive, fully online model-merging method that yields a batch-specific merged model via only forward passes, effectively leveraging target information. We further demonstrate why mean merging is prone to failure and misaligned under heterogeneous domain shifts. Next, we mitigate encoder classifier mismatch by decoupling the encoder and classification head, merging with separate merging coefficients. We extensively evaluate our method with state-of-the-art baselines using two backbones across nine medical and natural-domain generalization image classification datasets, showing consistent gains across standard evaluation and challenging scenarios. These performance gains are achieved while retaining single-model inference at test-time, thereby demonstrating the effectiveness of our method.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "平均数是海市蜃楼：医学影像中异质域移下的熵自适应模型合并",
        "summary": "一种熵自适应模型合并方法解决医学影像中的测试时间分布移动问题，其中局部微调的模型必须在未见过的临床站点运行。该方法仅使用前向传播创建特定于批次的合并模型，改进了简单平均策略。"
      },
      "fr": {
        "title": "La moyenne est un mirage : fusion de modèles adaptatifs à l'entropie sous des changements de domaine hétérogènes en imagerie médicale",
        "summary": "Une méthode de fusion de modèles adaptatifs à l'entropie aborde les changements de distribution au moment du test en imagerie médicale où les modèles ajustés localement doivent fonctionner sur des sites cliniques invisibles. L'approche crée des modèles fusionnés spécifiques aux lots en utilisant uniquement des passages avant, améliorant les stratégies de moyennage naïves."
      },
      "de": {
        "title": "Der Mittelwert ist eine Fata Morgana: Entropy-adaptive Modellverschmelzung unter heterogenen Domänenverschiebeungen in der medizinischen Bildgebung",
        "summary": "Eine Methode zur Modellverschmelzung mit Entropie-Anpassung behandelt Verteilungsverschiebeungen bei Testzeit in der medizinischen Bildgebung, wo lokal feinabgestimmte Modelle an unbekannten klinischen Standorten betrieben werden müssen. Der Ansatz erstellt chargespezifische zusammengeführte Modelle nur mit Vorwärtsdurchgängen und verbessert naive Durchschnittswertbildungsstrategien."
      },
      "es": {
        "title": "La media es un espejismo: fusión de modelos adaptativa a la entropía bajo cambios de dominio heterogéneos en imágenes médicas",
        "summary": "Un método de fusión de modelos adaptativo a la entropía aborda cambios de distribución en tiempo de prueba en imágenes médicas donde los modelos ajustados localmente deben funcionar en sitios clínicos no vistos. El enfoque crea modelos fusionados específicos de lotes utilizando solo pasadas hacia adelante, mejorando estrategias de promediación ingenuas."
      }
    }
  },
  {
    "title": "Small Language Models for Privacy-Preserving Clinical Information Extraction in Low-Resource Languages",
    "slug": "small-language-models-privacy-clinical-extraction-low-resource",
    "url": "https://arxiv.org/abs/2602.21374",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This study evaluates small language models combined with translation for extracting clinical features from Persian medical transcripts without fine-tuning. Results demonstrate privacy-preserving deployment in multilingual healthcare settings with larger models outperforming smaller variants.",
    "content": "arXiv:2602.21374v1 Announce Type: cross \nAbstract: Extracting clinical information from medical transcripts in low-resource languages remains a significant challenge in healthcare natural language processing (NLP). This study evaluates a two-step pipeline combining Aya-expanse-8B as a Persian-to-English translation model with five open-source small language models (SLMs) -- Qwen2.5-7B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct, Qwen2.5-1.5B-Instruct, and Gemma-3-1B-it -- for binary extraction of 13 clinical features from 1,221 anonymized Persian transcripts collected at a cancer palliative care call center. Using a few-shot prompting strategy without fine-tuning, models were assessed on macro-averaged F1-score, Matthews Correlation Coefficient (MCC), sensitivity, and specificity to account for class imbalance. Qwen2.5-7B-Instruct achieved the highest overall performance (median macro-F1: 0.899; MCC: 0.797), while Gemma-3-1B-it showed the weakest results. Larger models (7B--8B parameters) consistently outperformed smaller counterparts in sensitivity and MCC. A bilingual analysis of Aya-expanse-8B revealed that translating Persian transcripts to English improved sensitivity, reduced missing outputs, and boosted metrics robust to class imbalance, though at the cost of slightly lower specificity and precision. Feature-level results showed reliable extraction of physiological symptoms across most models, whereas psychological complaints, administrative requests, and complex somatic features remained challenging. These findings establish a practical, privacy-preserving blueprint for deploying open-source SLMs in multilingual clinical NLP settings with limited infrastructure and annotation resources, and highlight the importance of jointly optimizing model scale and input language strategy for sensitive healthcare applications.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "小型语言模型用于低资源语言的隐私保护临床信息抽取",
        "summary": "本研究评估了小型语言模型结合翻译用于从波斯医学文本中提取临床特征而无需微调的效果。结果表明在多语言医疗保健环境中隐私保护部署，较大模型的性能优于较小的变体。"
      },
      "fr": {
        "title": "Petits modèles de langage pour l'extraction d'informations cliniques préservant la vie privée dans les langues peu dotées en ressources",
        "summary": "Cette étude évalue les petits modèles de langage combinés avec la traduction pour l'extraction de caractéristiques cliniques à partir de transcriptions médicales persanes sans réglage fin. Les résultats démontrent un déploiement préservant la vie privée dans les environnements de soins de santé multilingues, avec les modèles plus grands surpassant les variantes plus petites."
      },
      "de": {
        "title": "Kleine Sprachmodelle für datenschutzschonende Extraktion klinischer Informationen in Sprachen mit geringen Ressourcen",
        "summary": "Diese Studie bewertet kleine Sprachmodelle in Kombination mit Übersetzung zum Extrahieren klinischer Merkmale aus persischen medizinischen Transkripten ohne Feinabstimmung. Die Ergebnisse zeigen datenschutzschonende Bereitstellung in mehrsprachigen Gesundheitsumgebungen, wobei größere Modelle kleinere Varianten übertreffen."
      },
      "es": {
        "title": "Modelos de lenguaje pequeños para la extracción de información clínica que preserva la privacidad en idiomas con pocos recursos",
        "summary": "Este estudio evalúa modelos de lenguaje pequeños combinados con traducción para extraer características clínicas de transcripciones médicas persas sin ajuste fino. Los resultados demuestran implementación que preserva la privacidad en entornos de atención médica multilingües, con modelos más grandes superando variantes más pequeñas."
      }
    }
  },
  {
    "title": "MrBERT: Modern Multilingual Encoders via Vocabulary, Domain, and Dimensional Adaptation",
    "slug": "mrbert-modern-multilingual-encoders-vocabulary-domain-adaptation",
    "url": "https://arxiv.org/abs/2602.21379",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "MrBERT introduces 150M-300M parameter multilingual encoders pre-trained on 35 languages and code with state-of-the-art performance on specialized domains. The model incorporates Matryoshka Representation Learning for flexible vector sizing, reducing inference and storage costs.",
    "content": "arXiv:2602.21379v1 Announce Type: cross \nAbstract: We introduce MrBERT, a family of 150M-300M parameter encoders built on the ModernBERT architecture and pre-trained on 35 languages and code. Through targeted adaptation, this model family achieves state-of-the-art results on Catalan- and Spanish-specific tasks, while establishing robust performance across specialized biomedical and legal domains. To bridge the gap between research and production, we incorporate Matryoshka Representation Learning (MRL), enabling flexible vector sizing that significantly reduces inference and storage costs. Ultimately, the MrBERT family demonstrates that modern encoder architectures can be optimized for both localized linguistic excellence and efficient, high-stakes domain specialization. We open source the complete model family on Huggingface.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "MrBERT：通过词汇、领域和维度自适应的现代多语言编码器",
        "summary": "MrBERT引入了在35种语言和代码上预训练的1.5亿至3亿参数多语言编码器，在专业领域达到最先进性能。该模型采用Matryoshka表示学习实现灵活的向量大小调整，降低推理和存储成本。"
      },
      "fr": {
        "title": "MrBERT : encodeurs multilingues modernes via adaptation du vocabulaire, du domaine et de la dimension",
        "summary": "MrBERT introduit des encodeurs multilingues de 150M-300M paramètres pré-entraînés sur 35 langues et du code avec des performances de pointe dans les domaines spécialisés. Le modèle intègre l'apprentissage de représentation Matryoshka pour un dimensionnement vectoriel flexible, réduisant les coûts d'inférence et de stockage."
      },
      "de": {
        "title": "MrBERT: Moderne mehrsprachige Encoder durch Vokabular-, Domänen- und Dimensionsanpassung",
        "summary": "MrBERT führt mehrsprachige Encoder mit 150M-300M Parametern ein, die auf 35 Sprachen und Code vortrainiert sind und in spezialisierten Bereichen hochmoderne Leistung bieten. Das Modell incorporates Matryoshka-Repräsentationslernens für flexible Vektorgröße und reduziert Inferenz- und Speicherkosten."
      },
      "es": {
        "title": "MrBERT: Codificadores multilingües modernos mediante adaptación de vocabulario, dominio y dimensión",
        "summary": "MrBERT introduce codificadores multilingües de 150M-300M parámetros pre-entrenados en 35 idiomas y código con rendimiento de última generación en dominios especializados. El modelo incorpora Aprendizaje de Representación Matryoshka para dimensionamiento vectorial flexible, reduciendo costos de inferencia y almacenamiento."
      }
    }
  },
  {
    "title": "VCDF: A Validated Consensus-Driven Framework for Time Series Causal Discovery",
    "slug": "vcdf-validated-consensus-time-series-causal-discovery",
    "url": "https://arxiv.org/abs/2602.21381",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "VCDF is a method-agnostic framework that improves robustness in time series causal discovery by evaluating causal relation stability across temporal subsets. Experiments show significant improvements over existing methods, with up to 0.18 absolute improvement on longer sequences.",
    "content": "arXiv:2602.21381v1 Announce Type: cross \nAbstract: Time series causal discovery is essential for understanding dynamic systems, yet many existing methods remain sensitive to noise, non-stationarity, and sampling variability. We propose the Validated Consensus-Driven Framework (VCDF), a simple and method-agnostic layer that improves robustness by evaluating the stability of causal relations across blocked temporal subsets. VCDF requires no modification to base algorithms and can be applied to methods such as VAR-LiNGAM and PCMCI. Experiments on synthetic datasets show that VCDF improves VAR-LiNGAM by approximately 0.08-0.12 in both window and summary F1 scores across diverse data characteristics, with gains most pronounced for moderate-to-long sequences. The framework also benefits from longer sequences, yielding up to 0.18 absolute improvement on time series of length 1000 and above. Evaluations on simulated fMRI data and IT-monitoring scenarios further demonstrate enhanced stability and structural accuracy under realistic noise conditions. VCDF provides an effective reliability layer for time series causal discovery without altering underlying modeling assumptions.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "VCDF：用于时间序列因果发现的经过验证的共识驱动框架",
        "summary": "VCDF是一个与方法无关的框架，通过在时间子集上评估因果关系的稳定性来改进时间序列因果发现的稳健性。实验显示相比现有方法的显著改进，在较长序列上最多提高0.18的绝对值。"
      },
      "fr": {
        "title": "VCDF : un cadre validé piloté par consensus pour la découverte de causalité en séries chronologiques",
        "summary": "VCDF est un cadre indépendant de la méthode qui améliore la robustesse de la découverte de causalité en séries chronologiques en évaluant la stabilité des relations causales sur des sous-ensembles temporels. Les expériences montrent des améliorations significatives par rapport aux méthodes existantes, avec jusqu'à 0,18 d'amélioration absolue sur les séquences plus longues."
      },
      "de": {
        "title": "VCDF: Ein validiertes, konsensgefasstes Framework zur kausalen Entdeckung von Zeitreihen",
        "summary": "VCDF ist ein methodenunabhängiges Framework, das die Robustheit bei der kausalen Entdeckung von Zeitreihen durch Bewertung der Stabilität von Kausalbeziehungen über zeitliche Teilmengen verbessert. Experimente zeigen erhebliche Verbesserungen gegenüber bestehenden Methoden, mit bis zu 0,18 absoluter Verbesserung bei längeren Sequenzen."
      },
      "es": {
        "title": "VCDF: Un marco validado impulsado por consenso para el descubrimiento de causalidad en series temporales",
        "summary": "VCDF es un marco agnóstico de método que mejora la robustez en el descubrimiento de causalidad en series temporales evaluando la estabilidad de las relaciones causales en subconjuntos temporales. Los experimentos muestran mejoras significativas sobre métodos existentes, con hasta 0.18 de mejora absoluta en secuencias más largas."
      }
    }
  },
  {
    "title": "FedVG: Gradient-Guided Aggregation for Enhanced Federated Learning",
    "slug": "fedvg-gradient-guided-aggregation-federated-learning",
    "url": "https://arxiv.org/abs/2602.21399",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "FedVG proposes a gradient-based federated aggregation framework using a global validation set to reduce client drift in heterogeneous settings. The method improves performance without compromising privacy by measuring client model generalization through validation gradients.",
    "content": "arXiv:2602.21399v1 Announce Type: cross \nAbstract: Federated Learning (FL) enables collaborative model training across multiple clients without sharing their private data. However, data heterogeneity across clients leads to client drift, which degrades the overall generalization performance of the model. This effect is further compounded by overemphasis on poorly performing clients. To address this problem, we propose FedVG, a novel gradient-based federated aggregation framework that leverages a global validation set to guide the optimization process. Such a global validation set can be established using readily available public datasets, ensuring accessibility and consistency across clients without compromising privacy. In contrast to conventional approaches that prioritize client dataset volume, FedVG assesses the generalization ability of client models by measuring the magnitude of validation gradients across layers. Specifically, we compute layerwise gradient norms to derive a client-specific score that reflects how much each client needs to adjust for improved generalization on the global validation set, thereby enabling more informed and adaptive federated aggregation. Extensive experiments on both natural and medical image benchmarking datasets, across diverse model architectures, demonstrate that FedVG consistently improves performance, particularly in highly heterogeneous settings. Moreover, FedVG is modular and can be seamlessly integrated with various state-of-the-art FL algorithms, often further improving their results. Our code is available at https://github.com/alinadevkota/FedVG.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "FedVG：梯度引导聚合用于增强型联邦学习",
        "summary": "FedVG提出了一个基于梯度的联邦聚合框架，使用全局验证集来减少异构环境中的客户端漂移。该方法通过验证梯度测量客户端模型的泛化能力，在不损害隐私的情况下改进性能。"
      },
      "fr": {
        "title": "FedVG : Agrégation Guidée par Gradient pour l'Apprentissage Fédéré Amélioré",
        "summary": "FedVG propose un cadre d'agrégation fédérée basé sur le gradient utilisant un ensemble de validation global pour réduire la dérive client dans les environnements hétérogènes. La méthode améliore les performances sans compromettre la confidentialité en mesurant la généralisation du modèle client via les gradients de validation."
      },
      "de": {
        "title": "FedVG: Gradient-gesteuerte Aggregation für verbessertes föderatives Lernen",
        "summary": "FedVG schlägt einen auf Gradienten basierenden föderativen Aggregationsrahmen vor, der einen globalen Validierungssatz verwendet, um Client-Drift in heterogenen Umgebungen zu reduzieren. Die Methode verbessert die Leistung, ohne die Datenschutzbestimmungen zu beeinträchtigen, indem die Verallgemeinerung des Client-Modells durch Validierungsgradienten gemessen wird."
      },
      "es": {
        "title": "FedVG: Agregación Guiada por Gradientes para Aprendizaje Federado Mejorado",
        "summary": "FedVG propone un marco de agregación federada basado en gradientes que utiliza un conjunto de validación global para reducir la desviación del cliente en configuraciones heterogéneas. El método mejora el rendimiento sin comprometer la privacidad midiendo la generalización del modelo del cliente a través de gradientes de validación."
      }
    }
  },
  {
    "title": "The Headless Firm: How AI Reshapes Enterprise Boundaries",
    "slug": "headless-firm-ai-reshapes-enterprise-boundaries",
    "url": "https://arxiv.org/abs/2602.21401",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This economic analysis argues that agentic AI fundamentally changes how coordination costs scale in enterprises, predicting a shift toward \"Headless Firm\" structures with generative interfaces, protocols, and competitive execution agents. The framework predicts domain-conditional business model shifts toward micro-specialized networks.",
    "content": "arXiv:2602.21401v1 Announce Type: cross \nAbstract: The boundary of the firm is determined by coordination cost. We argue that agentic AI induces a structural change in how coordination costs scale: in prior modular systems, integration cost grew with interaction topology (O(n^2) in the number of components); in protocol-mediated agentic systems, integration cost collapses to O(n) while verification scales with task throughput rather than interaction count. This shift selects for a specific organizational equilibrium -- the Headless Firm -- structured as an hourglass: a personalized generative interface at the top, a standardized protocol waist in the middle, and a competitive market of micro-specialized execution agents at the bottom. We formalize this claim as a coordination cost model with two falsifiable empirical predictions: (1) the marginal cost of adding an execution provider should be approximately constant in a mature hourglass ecosystem; (2) the ratio of total coordination cost to task throughput should remain stable as ecosystem size grows. We derive conditions for hourglass stability versus re-centralization and analyze implications for firm size distributions, labor markets, and software economics. The analysis predicts a domain-conditional Great Unbundling: in high knowledge-velocity domains, firm size distributions shift mass from large integrated incumbents toward micro-specialized agents and thin protocol orchestrators.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "无头企业：人工智能如何重塑企业边界",
        "summary": "这项经济分析论证了代理型AI从根本上改变了企业中协调成本的规模化方式，预测向具有生成式界面、协议和竞争性执行代理的\"无头企业\"结构转变。该框架预测了面向微专业化网络的领域条件业务模式转变。"
      },
      "fr": {
        "title": "L'Entreprise Sans Tête : Comment l'IA Redessine les Frontières Entreprises",
        "summary": "Cette analyse économique soutient que l'IA agentive change fondamentalement la façon dont les coûts de coordination se mettent à l'échelle dans les entreprises, prédisant un passage vers des structures « Entreprise Sans Tête » avec des interfaces génératives, des protocoles et des agents d'exécution concurrents. Le cadre prédit des changements de modèle commercial conditionnels au domaine vers des réseaux micro-spécialisés."
      },
      "de": {
        "title": "Das kopflose Unternehmen: Wie KI Unternehmensgrenzen umgestaltet",
        "summary": "Diese wirtschaftliche Analyse argumentiert, dass agentengesteuerte KI grundlegend verändert, wie Koordinationskosten in Unternehmen skalieren, und prognostiziert eine Verschiebung hin zu „Kopflosen Unternehmens\"-Strukturen mit generativen Schnittstellen, Protokollen und wettbewerbsfähigen Ausführungsagenten. Das Framework prognostiziert domänenbedingte Geschäftsmodellverschiebungen hin zu mikrospezialisierten Netzwerken."
      },
      "es": {
        "title": "La Empresa Sin Cabeza: Cómo la IA Redibuja los Límites Empresariales",
        "summary": "Este análisis económico sostiene que la IA agentiva cambia fundamentalmente cómo escalan los costos de coordinación en las empresas, prediciendo un cambio hacia estructuras de \"Empresa Sin Cabeza\" con interfaces generativas, protocolos y agentes de ejecución competitivos. El marco predice cambios de modelo empresarial condicionados por dominio hacia redes micro-especializadas."
      }
    }
  },
  {
    "title": "Overconfident Errors Need Stronger Correction: Asymmetric Confidence Penalties for Reinforcement Learning",
    "slug": "overconfident-errors-asymmetric-confidence-penalties-reinforcement-learning",
    "url": "https://arxiv.org/abs/2602.21420",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "The Asymmetric Confidence-aware Error Penalty (ACE) addresses a pathology in reinforcement learning where uniform error penalization allows overconfident incorrect reasoning to persist. Applied to math reasoning tasks, ACE improves performance across model families by dynamically modulating penalties based on confidence.",
    "content": "arXiv:2602.21420v1 Announce Type: cross \nAbstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become the leading paradigm for enhancing reasoning in Large Language Models (LLMs). However, standard RLVR algorithms suffer from a well-documented pathology: while they improve Pass@1 accuracy through sharpened sampling, they simultaneously narrow the model's reasoning boundary and reduce generation diversity. We identify a root cause that existing methods overlook: the uniform penalization of errors. Current approaches -- whether data-filtering methods that select prompts by difficulty, or advantage normalization schemes -- treat all incorrect rollouts within a group identically. We show that this uniformity allows overconfident errors (incorrect reasoning paths that the RL process has spuriously reinforced) to persist and monopolize probability mass, ultimately suppressing valid exploratory trajectories. To address this, we propose the Asymmetric Confidence-aware Error Penalty (ACE). ACE introduces a per-rollout confidence shift metric, c_i = log(pi_theta(y_i|x) / pi_ref(y_i|x)), to dynamically modulate negative advantages. Theoretically, we demonstrate that ACE's gradient can be decomposed into the gradient of a selective regularizer restricted to overconfident errors, plus a well-characterized residual that partially moderates the regularizer's strength. We conduct extensive experiments fine-tuning Qwen2.5-Math-7B, Qwen3-8B-Base, and Llama-3.1-8B-Instruct on the DAPO-Math-17K dataset using GRPO and DAPO within the VERL framework. Evaluated on MATH-500 and AIME 2025, ACE composes seamlessly with existing methods and consistently improves the full Pass@k spectrum across all three model families and benchmarks.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "过度自信错误需要更强纠正：强化学习中的非对称置信度惩罚",
        "summary": "非对称置信度感知错误惩罚（ACE）解决了强化学习中的一个问题，即统一的错误惩罚允许过度自信的错误推理持续存在。应用于数学推理任务时，ACE通过基于置信度动态调节惩罚来改进各模型族的性能。"
      },
      "fr": {
        "title": "Les Erreurs Surconfiantes Nécessitent une Correction Plus Forte : Pénalités de Confiance Asymétriques pour l'Apprentissage par Renforcement",
        "summary": "La Pénalité d'Erreur Asymétrique Consciente de la Confiance (ACE) aborde une pathologie dans l'apprentissage par renforcement où la pénalisation d'erreur uniforme permet au raisonnement incorrect surconfiant de persister. Appliquée aux tâches de raisonnement mathématique, ACE améliore les performances dans les familles de modèles en modulant dynamiquement les pénalités en fonction de la confiance."
      },
      "de": {
        "title": "Überconfident-Fehler Benötigen Stärkere Korrektur: Asymmetrische Konfidenz-Strafen für Verstärktes Lernen",
        "summary": "Die asymmetrische konfidenz-bewusste Fehlerstrafe (ACE) behandelt eine Pathologie beim verstärkten Lernen, bei der eine einheitliche Fehlerbestrafung überconfident falsches Denken fortbestand. Angewendet auf mathematische Aufgaben verbessert ACE die Leistung über Modell-Familien hinweg durch dynamische Modulation der Strafen basierend auf Konfidenz."
      },
      "es": {
        "title": "Errores Excesivamente Confiados Necesitan Corrección Más Fuerte: Penalizaciones de Confianza Asimétricas para Aprendizaje por Refuerzo",
        "summary": "La Penalización de Error Consciente de Confianza Asimétrica (ACE) aborda una patología en el aprendizaje por refuerzo donde la penalización uniforme de errores permite que el razonamiento incorrecto excesivamente confiado persista. Aplicada a tareas de razonamiento matemático, ACE mejora el rendimiento en todas las familias de modelos al modular dinámicamente las penalizaciones basadas en la confianza."
      }
    }
  },
  {
    "title": "ECHOSAT: Estimating Canopy Height Over Space And Time",
    "slug": "echosat-estimating-canopy-height-space-time",
    "url": "https://arxiv.org/abs/2602.21421",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "ECHOSAT creates the first temporally consistent global tree height map at 10m resolution spanning multiple years using multi-sensor satellite data and vision transformers. The system tracks tree growth and disturbances over time, advancing carbon monitoring and climate change mitigation.",
    "content": "arXiv:2602.21421v1 Announce Type: cross \nAbstract: Forest monitoring is critical for climate change mitigation. However, existing global tree height maps provide only static snapshots and do not capture temporal forest dynamics, which are essential for accurate carbon accounting. We introduce ECHOSAT, a global and temporally consistent tree height map at 10 m resolution spanning multiple years. To this end, we resort to multi-sensor satellite data to train a specialized vision transformer model, which performs pixel-level temporal regression. A self-supervised growth loss regularizes the predictions to follow growth curves that are in line with natural tree development, including gradual height increases over time, but also abrupt declines due to forest loss events such as fires. Our experimental evaluation shows that our model improves state-of-the-art accuracies in the context of single-year predictions. We also provide the first global-scale height map that accurately quantifies tree growth and disturbances over time. We expect ECHOSAT to advance global efforts in carbon monitoring and disturbance assessment. The maps can be accessed at https://github.com/ai4forest/echosat.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ECHOSAT：在空间和时间上估计树冠高度",
        "summary": "ECHOSAT使用多传感器卫星数据和视觉变换器创建了第一个在10米分辨率下跨越多年的时间一致的全球树高图。该系统可以随时间跟踪树木生长和干扰，推进碳监测和气候变化缓解。"
      },
      "fr": {
        "title": "ECHOSAT : Estimation de la hauteur de la canopée dans l'espace et le temps",
        "summary": "ECHOSAT crée la première carte de hauteur des arbres mondiale temporellement cohérente à 10 m de résolution sur plusieurs années en utilisant des données satellite multi-capteurs et des transformateurs de vision. Le système suit la croissance des arbres et les perturbations au fil du temps, en faisant progresser la surveillance du carbone et l'atténuation du changement climatique."
      },
      "de": {
        "title": "ECHOSAT: Schätzung der Kronenhöhe über Raum und Zeit",
        "summary": "ECHOSAT erstellt die erste zeitlich konsistente globale Baumhöhenkarte mit 10-m-Auflösung über mehrere Jahre hinweg unter Verwendung von Multi-Sensor-Satellitendaten und Vision-Transformatoren. Das System verfolgt Baumwachstum und Störungen über die Zeit und fördert die Kohlenstoffüberwachung und Klimawandelbekämpfung."
      },
      "es": {
        "title": "ECHOSAT: Estimación de la altura del dosel en el espacio y el tiempo",
        "summary": "ECHOSAT crea el primer mapa de altura de árboles global temporalmente consistente a 10 m de resolución a lo largo de varios años utilizando datos satelitales multisensor y transformadores de visión. El sistema rastrea el crecimiento de los árboles y las perturbaciones a lo largo del tiempo, avanzando en la monitorización del carbono y la mitigación del cambio climático."
      }
    }
  },
  {
    "title": "On the Structural Non-Preservation of Epistemic Behaviour under Policy Transformation",
    "slug": "structural-non-preservation-epistemic-behaviour-policy-transformation",
    "url": "https://arxiv.org/abs/2602.21424",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "This theoretical work formalizes how RL agents condition actions on internal information under partial observability and proves structural results about policy transformations. The analysis shows behavioral distance contracts under convex aggregation with implications for partially observable environments.",
    "content": "arXiv:2602.21424v1 Announce Type: cross \nAbstract: Reinforcement learning (RL) agents under partial observability often condition actions on internally accumulated information such as memory or inferred latent context. We formalise such information-conditioned interaction patterns as behavioural dependency: variation in action selection with respect to internal information under fixed observations. This induces a probe-relative notion of $\\epsilon$-behavioural equivalence and a within-policy behavioural distance that quantifies probe sensitivity. We establish three structural results. First, the set of policies exhibiting non-trivial behavioural dependency is not closed under convex aggregation. Second, behavioural distance contracts under convex combination. Third, we prove a sufficient local condition under which gradient ascent on a skewed mixture objective decreases behavioural distance when a dominant-mode gradient aligns with the direction of steepest contraction. Minimal bandit and partially observable gridworld experiments provide controlled witnesses of these mechanisms. In the examined settings, behavioural distance decreases under convex aggregation and under continued optimisation with skewed latent priors, and in these experiments it precedes degradation under latent prior shift. These results identify structural conditions under which probe-conditioned behavioural separation is not preserved under common policy transformations.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "论政策变换下认知行为的结构非保持",
        "summary": "这项理论工作将RL代理如何在部分可观测性下以内部信息为条件调节行动形式化，并证明了关于政策变换的结构结果。分析表明行为距离在凸聚合下收缩，对部分可观测环境有影响。"
      },
      "fr": {
        "title": "Sur la non-préservation structurelle du comportement épistémique sous transformation de politique",
        "summary": "Ce travail théorique formalise la manière dont les agents RL conditionnent les actions sur l'information interne dans l'observabilité partielle et prouve des résultats structurels sur les transformations de politique. L'analyse montre que la distance comportementale se contracte sous l'agrégation convexe avec des implications pour les environnements partiellement observables."
      },
      "de": {
        "title": "Über die strukturelle Nichterhaltung epistemischen Verhaltens bei Politiktransformation",
        "summary": "Diese theoretische Arbeit formalisiert, wie RL-Agenten Aktionen unter partieller Beobachtbarkeit an interne Informationen koppeln, und beweist strukturelle Ergebnisse zu Politiktransformationen. Die Analyse zeigt, dass sich die Verhaltensweite unter konvexer Aggregation zusammenzieht, mit Implikationen für teilweise beobachtbare Umgebungen."
      },
      "es": {
        "title": "Sobre la no preservación estructural del comportamiento epistémico bajo transformación de política",
        "summary": "Este trabajo teórico formaliza cómo los agentes de RL condicionan acciones sobre información interna bajo observabilidad parcial y prueba resultados estructurales sobre transformaciones de política. El análisis muestra que la distancia de comportamiento se contrae bajo agregación convexa con implicaciones para entornos parcialmente observables."
      }
    }
  },
  {
    "title": "Provably Safe Generative Sampling with Constricting Barrier Functions",
    "slug": "provably-safe-generative-sampling-barrier-functions",
    "url": "https://arxiv.org/abs/2602.21429",
    "source": "arXiv cs.AI",
    "date": "2026-02-26T05:00:00.000Z",
    "summary": "A safety filtering framework for generative models uses Control Barrier Functions to guarantee generated samples satisfy hard constraints while minimizing distributional shift. The approach applies to any pre-trained flow-based model without retraining, achieving 100% constraint satisfaction across applications.",
    "content": "arXiv:2602.21429v1 Announce Type: cross \nAbstract: Flow-based generative models, such as diffusion models and flow matching models, have achieved remarkable success in learning complex data distributions. However, a critical gap remains for their deployment in safety-critical domains: the lack of formal guarantees that generated samples will satisfy hard constraints. We address this by proposing a safety filtering framework that acts as an online shield for any pre-trained generative model. Our key insight is to cooperate with the generative process rather than override it. We define a constricting safety tube that is relaxed at the initial noise distribution and progressively tightens to the target safe set at the final data distribution, mirroring the coarse-to-fine structure of the generative process itself. By characterizing this tube via Control Barrier Functions (CBFs), we synthesize a feedback control input through a convex Quadratic Program (QP) at each sampling step. As the tube is loosest when noise is high and intervention is cheapest in terms of control energy, most constraint enforcement occurs when it least disrupts the model's learned structure. We prove that this mechanism guarantees safe sampling while minimizing the distributional shift from the original model at each sampling step, as quantified by the KL divergence. Our framework applies to any pre-trained flow-based generative scheme requiring no retraining or architectural modifications. We validate the approach across constrained image generation, physically-consistent trajectory sampling, and safe robotic manipulation policies, achieving 100% constraint satisfaction while preserving semantic fidelity.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "使用约束屏障函数的可证明安全生成采样",
        "summary": "生成模型的安全过滤框架使用控制屏障函数来保证生成的样本满足硬约束，同时最小化分布转移。该方法适用于任何预训练的流基模型，无需重新训练，在各种应用中实现100%的约束满足。"
      },
      "fr": {
        "title": "Échantillonnage génératif prouvé sûr avec des fonctions de barrière constrictive",
        "summary": "Un cadre de filtrage de sécurité pour les modèles génératifs utilise des fonctions de barrière de contrôle pour garantir que les échantillons générés satisfont aux contraintes dures tout en minimisant le décalage distributif. L'approche s'applique à tout modèle basé sur le flux préentraîné sans réentraînement, réalisant 100 % de satisfaction des contraintes dans les applications."
      },
      "de": {
        "title": "Nachweislich sichere generative Stichprobenentnahme mit konstringierenden Barrierefunktionen",
        "summary": "Ein Sicherheitsfilterungsrahmen für generative Modelle nutzt Kontrollbarrierefunktionen, um zu garantieren, dass generierte Stichproben harte Einschränkungen erfüllen und gleichzeitig die Verteilungsverschiebung minimieren. Der Ansatz gilt für jedes vortrainierte flussbasierte Modell ohne Umschulung und erreicht eine 100%ige Einhaltung der Einschränkungen in verschiedenen Anwendungen."
      },
      "es": {
        "title": "Muestreo generativo comprobadamente seguro con funciones de barrera constrictiva",
        "summary": "Un marco de filtrado de seguridad para modelos generativos utiliza funciones de barrera de control para garantizar que las muestras generadas satisfagan restricciones duras mientras se minimiza el cambio distribucional. El enfoque se aplica a cualquier modelo basado en flujo previamente entrenado sin reentrenamiento, logrando una satisfacción de restricciones del 100% en todas las aplicaciones."
      }
    }
  }
]