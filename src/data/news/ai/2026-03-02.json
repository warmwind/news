[
  {
    "title": "HumanMCP: A Human-Like Query Dataset for Evaluating MCP Tool Retrieval Performance",
    "slug": "humanmcp-human-like-query-dataset-mcp-tool-retrieval",
    "url": "https://arxiv.org/abs/2602.23367",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "This paper introduces the first large-scale dataset of human-like user queries for Model Context Protocol (MCP) servers, covering 2,800 tools across 308 servers with diverse user personas. The dataset addresses a critical gap in evaluating tool-use systems by providing realistic, varied queries that better represent real-world interaction patterns beyond existing benchmarks.",
    "content": "arXiv:2602.23367v1 Announce Type: new \nAbstract: Model Context Protocol (MCP) servers contain a collection of thousands of open-source standardized tools, linking LLMs to external systems; however, existing datasets and benchmarks lack realistic, human-like user queries, remaining a critical gap in evaluating the tool usage and ecosystems of MCP servers. Existing datasets often do contain tool descriptions but fail to represent how different users portray their requests, leading to poor generalization and inflated reliability of certain benchmarks. This paper introduces the first large-scale MCP dataset featuring diverse, high-quality diverse user queries generated specifically to match 2800 tools across 308 MCP servers, developing on the MCP Zero dataset. Each tool is paired with multiple unique user personas that we have generated, to capture varying levels of user intent ranging from precise task requests, and ambiguous, exploratory commands, reflecting the complexity of real-world interaction patterns.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "HumanMCP：用于评估MCP工具检索性能的类人查询数据集",
        "summary": "本文介绍了第一个大规模类人用户查询数据集，适用于模型上下文协议（MCP）服务器，涵盖308个服务器中的2,800个工具和多样化的用户角色。该数据集通过提供真实的、多样化的查询，更好地代表真实世界的交互模式，超越现有基准，填补了评估工具使用系统的关键空白。"
      },
      "fr": {
        "title": "HumanMCP : Un ensemble de données de requêtes similaires à l'homme pour évaluer les performances de récupération d'outils MCP",
        "summary": "Cet article introduit le premier ensemble de données à grande échelle de requêtes utilisateur similaires à l'homme pour les serveurs du protocole de contexte de modèle (MCP), couvrant 2 800 outils dans 308 serveurs avec des personas d'utilisateurs diversifiés. L'ensemble de données comble un écart critique dans l'évaluation des systèmes d'utilisation d'outils en fournissant des requêtes réalistes et variées qui représentent mieux les modèles d'interaction du monde réel au-delà des benchmarks existants."
      },
      "de": {
        "title": "HumanMCP: Ein Human-ähnlicher Query-Datensatz zur Bewertung der MCP-Toolabruf-Leistung",
        "summary": "Dieses Papier stellt den ersten großmaßstäblichen Datensatz menschenähnlicher Benutzerabfragen für Model Context Protocol (MCP)-Server vor und deckt 2.800 Tools auf 308 Servern mit vielfältigen Benutzerpersonas ab. Der Datensatz schließt eine kritische Lücke bei der Bewertung von Tool-Nutzungssystemen, indem er realistische, vielfältige Abfragen bereitstellt, die reale Interaktionsmuster besser darstellen als bestehende Benchmarks."
      },
      "es": {
        "title": "HumanMCP: Un conjunto de datos de consultas similares a humanos para evaluar el desempeño de la recuperación de herramientas MCP",
        "summary": "Este artículo presenta el primer conjunto de datos a gran escala de consultas de usuario similares a humanos para servidores del Protocolo de Contexto de Modelo (MCP), cubriendo 2.800 herramientas en 308 servidores con diversos perfiles de usuario. El conjunto de datos aborda una brecha crítica en la evaluación de sistemas de uso de herramientas al proporcionar consultas realistas y variadas que representan mejor los patrones de interacción del mundo real más allá de los puntos de referencia existentes."
      }
    }
  },
  {
    "title": "An Agentic LLM Framework for Adverse Media Screening in AML Compliance",
    "slug": "agentic-llm-framework-adverse-media-screening-aml-compliance",
    "url": "https://arxiv.org/abs/2602.23373",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "This work presents an LLM-based agentic system using retrieval-augmented generation to automate adverse media screening for financial compliance. By reducing reliance on keyword searches and manual review, the system demonstrates improved accuracy in distinguishing high-risk from low-risk individuals in AML/KYC processes.",
    "content": "arXiv:2602.23373v1 Announce Type: new \nAbstract: Adverse media screening is a critical component of anti-money laundering (AML) and know-your-customer (KYC) compliance processes in financial institutions. Traditional approaches rely on keyword-based searches that generate high false-positive rates or require extensive manual review. We present an agentic system that leverages Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) to automate adverse media screening. Our system implements a multi-step approach where an LLM agent searches the web, retrieves and processes relevant documents, and computes an Adverse Media Index (AMI) score for each subject. We evaluate our approach using multiple LLM backends on a dataset comprising Politically Exposed Persons (PEPs), persons from regulatory watchlists, and sanctioned persons from OpenSanctions and clean names from academic sources, demonstrating the system's ability to distinguish between high-risk and low-risk individuals.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "用于AML合规的不良媒体筛查的代理LLM框架",
        "summary": "这项工作提出了一个基于LLM的代理系统，使用检索增强生成来自动化不良媒体筛查以实现财务合规。通过减少对关键词搜索和人工审查的依赖，该系统在AML/KYC流程中区分高风险和低风险个人的准确性得到了改善。"
      },
      "fr": {
        "title": "Un cadre LLM agentique pour la détection des médias adverses dans la conformité AML",
        "summary": "Ce travail présente un système agentique basé sur LLM utilisant la génération augmentée par récupération pour automatiser la détection des médias adverses pour la conformité financière. En réduisant la dépendance aux recherches par mots-clés et à l'examen manuel, le système démontre une précision améliorée dans la distinction entre les individus à haut risque et à faible risque dans les processus AML/KYC."
      },
      "de": {
        "title": "Ein agentisches LLM-Framework für das Screening von negativen Medien bei der AML-Compliance",
        "summary": "Diese Arbeit präsentiert ein agentisches LLM-System, das generative Retrievals zur Automatisierung des Screenings von negativen Medien für finanzielle Compliance nutzt. Durch die Verringerung der Abhängigkeit von Schlüsselwortsuchen und manueller Überprüfung zeigt das System verbesserte Genauigkeit bei der Unterscheidung zwischen Personen mit hohem und niedrigem Risiko in AML/KYC-Prozessen."
      },
      "es": {
        "title": "Un marco LLM agéntico para la detección de medios adversos en la conformidad AML",
        "summary": "Este trabajo presenta un sistema agéntico basado en LLM utilizando generación aumentada por recuperación para automatizar la detección de medios adversos para el cumplimiento financiero. Al reducir la dependencia de búsquedas por palabras clave y revisión manual, el sistema demuestra una precisión mejorada en la distinción entre individuos de alto riesgo y bajo riesgo en los procesos AML/KYC."
      }
    }
  },
  {
    "title": "Causal Identification from Counterfactual Data: Completeness and Bounding Results",
    "slug": "causal-identification-counterfactual-data-completeness-bounds",
    "url": "https://arxiv.org/abs/2602.23541",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "This paper develops the CTFIDU+ algorithm for identifying counterfactual quantities from experimentally realizable distributions and establishes theoretical limits on exact causal inference. The work provides both completeness guarantees and novel analytical bounds for non-identifiable counterfactuals in non-parametric settings.",
    "content": "arXiv:2602.23541v1 Announce Type: new \nAbstract: Previous work establishing completeness results for $\\textit{counterfactual identification}$ has been circumscribed to the setting where the input data belongs to observational or interventional distributions (Layers 1 and 2 of Pearl's Causal Hierarchy), since it was generally presumed impossible to obtain data from counterfactual distributions, which belong to Layer 3. However, recent work (Raghavan & Bareinboim, 2025) has formally characterized a family of counterfactual distributions which can be directly estimated via experimental methods - a notion they call $\\textit{counterfactual realizabilty}$. This leaves open the question of what $\\textit{additional}$ counterfactual quantities now become identifiable, given this new access to (some) Layer 3 data. To answer this question, we develop the CTFIDU+ algorithm for identifying counterfactual queries from an arbitrary set of Layer 3 distributions, and prove that it is complete for this task. Building on this, we establish the theoretical limit of which counterfactuals can be identified from physically realizable distributions, thus implying the $\\textit{fundamental limit to exact causal inference in the non-parametric setting}$. Finally, given the impossibility of identifying certain critical types of counterfactuals, we derive novel analytic bounds for such quantities using realizable counterfactual data, and corroborate using simulations that counterfactual data helps tighten the bounds for non-identifiable quantities in practice.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "反事实数据中的因果识别：完全性和界限结果",
        "summary": "本文开发了CTFIDU+算法，用于从实验可实现的分布中识别反事实量，并建立了精确因果推理的理论限制。该工作在非参数设置中为不可识别的反事实提供了完全性保证和新颖的分析界限。"
      },
      "fr": {
        "title": "Identification causale à partir de données contrefactuelles : résultats de complétude et de limitation",
        "summary": "Cet article développe l'algorithme CTFIDU+ pour identifier les quantités contrefactuelles à partir de distributions réalisables expérimentalement et établit des limites théoriques sur l'inférence causale exacte. Le travail fournit à la fois des garanties de complétude et des limites analytiques nouvelles pour les contrefactuels non identifiables dans des paramètres non paramétriques."
      },
      "de": {
        "title": "Kausale Identifikation aus kontrafaktischen Daten: Vollständigkeit und Begrenzungsergebnisse",
        "summary": "Dieses Papier entwickelt den CTFIDU+-Algorithmus zur Identifikation kontrafaktischer Größen aus experimentell realisierbaren Verteilungen und legt theoretische Grenzen für exakte kausale Inferenz fest. Die Arbeit bietet sowohl Vollständigkeitsgarantien als auch neuartige analytische Grenzen für nicht identifizierbare Kontrafaktika in nicht-parametrischen Einstellungen."
      },
      "es": {
        "title": "Identificación causal a partir de datos contrafácticos: resultados de completitud y limitaciones",
        "summary": "Este artículo desarrolla el algoritmo CTFIDU+ para identificar cantidades contrafácticas a partir de distribuciones realizables experimentalmente y establece límites teóricos en la inferencia causal exacta. El trabajo proporciona tanto garantías de completitud como límites analíticos novedosos para contrafácticos no identificables en configuraciones no paramétricas."
      }
    }
  },
  {
    "title": "Planning under Distribution Shifts with Causal POMDPs",
    "slug": "planning-distribution-shifts-causal-pomdps",
    "url": "https://arxiv.org/abs/2602.23545",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "The paper proposes a causal POMDP framework enabling planning under partial observability when environment distributions shift. By maintaining belief over both latent state and domain changes while preserving computational tractability, the approach addresses real-world challenges where learned models become invalid due to environmental changes.",
    "content": "arXiv:2602.23545v1 Announce Type: new \nAbstract: In the real world, planning is often challenged by distribution shifts. As such, a model of the environment obtained under one set of conditions may no longer remain valid as the distribution of states or the environment dynamics change, which in turn causes previously learned strategies to fail. In this work, we propose a theoretical framework for planning under partial observability using Partially Observable Markov Decision Processes (POMDPs) formulated using causal knowledge. By representing shifts in the environment as interventions on this causal POMDP, the framework enables evaluating plans under hypothesized changes and actively identifying which components of the environment have been altered. We show how to maintain and update a belief over both the latent state and the underlying domain, and we prove that the value function remains piecewise linear and convex (PWLC) in this augmented belief space. Preservation of PWLC under distribution shifts has the advantage of maintaining the tractability of planning via $\\alpha$-vector-based POMDP methods.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "因果POMDP框架下的分布偏移规划",
        "summary": "该论文提出了一个因果POMDP框架，在环境分布发生偏移时实现部分可观测性下的规划。通过维护对潜在状态和域变化的信念，同时保持计算可行性，该方法解决了真实世界中由于环境变化导致学习模型失效的挑战。"
      },
      "fr": {
        "title": "Planification sous des changements de distribution avec les POMDPs causaux",
        "summary": "L'article propose un cadre causal POMDP permettant la planification sous observabilité partielle lorsque les distributions d'environnement changent. En maintenant une croyance sur l'état latent et les changements de domaine tout en préservant la tractabilité informatique, l'approche aborde les défis du monde réel où les modèles appris deviennent invalides en raison des changements environnementaux."
      },
      "de": {
        "title": "Planung unter Verteilungsverschiebungen mit kausalen POMDPs",
        "summary": "Das Papier schlägt einen kausalen POMDP-Rahmen vor, der Planung unter partieller Beobachtbarkeit ermöglicht, wenn sich Umgebungsverteilungen verschieben. Durch die Aufrechterhaltung von Überzeugungen über latente Zustände und Domänenänderungen bei Beibehaltung der Rechentraktabilität adressiert der Ansatz reale Herausforderungen, bei denen gelernte Modelle aufgrund von Umweltveränderungen ungültig werden."
      },
      "es": {
        "title": "Planificación bajo cambios de distribución con POMDPs causales",
        "summary": "El artículo propone un marco causal POMDP que permite la planificación bajo observabilidad parcial cuando las distribuciones del entorno cambian. Al mantener creencias sobre el estado latente y los cambios de dominio mientras se preserva la tractabilidad computacional, el enfoque aborda desafíos del mundo real donde los modelos aprendidos se vuelven inválidos debido a cambios ambientales."
      }
    }
  },
  {
    "title": "Construct, Merge, Solve & Adapt with Reinforcement Learning for the min-max Multiple Traveling Salesman Problem",
    "slug": "construct-merge-solve-adapt-reinforcement-learning-mtsp",
    "url": "https://arxiv.org/abs/2602.23579",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "RL-CMSA combines reinforcement learning with exact optimization for the min-max Multiple Traveling Salesman Problem, outperforming genetic algorithms on complex instances. The hybrid approach balances exploration and exploitation through learned pairwise q-values and restricted set-covering optimization.",
    "content": "arXiv:2602.23579v1 Announce Type: new \nAbstract: The Multiple Traveling Salesman Problem (mTSP) extends the Traveling Salesman Problem to m tours that start and end at a common depot and jointly visit all customers exactly once. In the min-max variant, the objective is to minimize the longest tour, reflecting workload balance. We propose a hybrid approach, Construct, Merge, Solve & Adapt with Reinforcement Learning (RL-CMSA), for the symmetric single-depot min-max mTSP. The method iteratively constructs diverse solutions using probabilistic clustering guided by learned pairwise q-values, merges routes into a compact pool, solves a restricted set-covering MILP, and refines solutions via inter-route remove, shift, and swap moves. The q-values are updated by reinforcing city-pair co-occurrences in high-quality solutions, while the pool is adapted through ageing and pruning. This combination of exact optimization and reinforcement-guided construction balances exploration and exploitation. Computational results on random and TSPLIB instances show that RL-CMSA consistently finds (near-)best solutions and outperforms a state-of-the-art hybrid genetic algorithm under comparable time limits, especially as instance size and the number of salesmen increase.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "用强化学习进行最小最大多旅行商问题的构造、合并、求解与自适应",
        "summary": "RL-CMSA将强化学习与精确优化相结合来解决最小最大多旅行商问题，在复杂实例上的表现优于遗传算法。该混合方法通过学习的成对Q值和受限的集合覆盖优化来平衡探索和利用。"
      },
      "fr": {
        "title": "Construction, fusion, résolution et adaptation avec apprentissage par renforcement pour le problème de voyageur de commerce multiple min-max",
        "summary": "RL-CMSA combine l'apprentissage par renforcement avec l'optimisation exacte pour le problème de voyageur de commerce multiple min-max, surpassant les algorithmes génétiques sur les instances complexes. L'approche hybride équilibre l'exploration et l'exploitation grâce aux valeurs q par paire apprises et à l'optimisation restreinte du set-covering."
      },
      "de": {
        "title": "Konstruieren, Zusammenführen, Lösen und Anpassen mit verstärktem Lernen für das min-max Multiple Traveling Salesman Problem",
        "summary": "RL-CMSA kombiniert verstärktes Lernen mit exakter Optimierung für das min-max Multiple Traveling Salesman Problem und übertrifft genetische Algorithmen bei komplexen Instanzen. Der hybride Ansatz balanciert Erkundung und Ausnutzung durch gelernte paarweise Q-Werte und eingeschränkte Set-Cover-Optimierung."
      },
      "es": {
        "title": "Construcción, fusión, resolución y adaptación con aprendizaje por refuerzo para el problema min-max de múltiples viajeros de comercio",
        "summary": "RL-CMSA combina el aprendizaje por refuerzo con la optimización exacta para el problema min-max de múltiples viajeros de comercio, superando a los algoritmos genéticos en instancias complejas. El enfoque híbrido equilibra la exploración y explotación a través de valores q por pares aprendidos y optimización de cobertura de conjuntos restringida."
      }
    }
  },
  {
    "title": "SleepLM: Natural-Language Intelligence for Human Sleep",
    "slug": "sleeplm-natural-language-intelligence-human-sleep",
    "url": "https://arxiv.org/abs/2602.23605",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "SleepLM is a foundation model family enabling natural language understanding of human sleep through multimodal alignment on a dataset of 100,000+ hours from 10,000+ individuals. The model supports zero-shot sleep event localization and insight generation, moving beyond traditional closed-label sleep classification approaches.",
    "content": "arXiv:2602.23605v1 Announce Type: new \nAbstract: We present SleepLM, a family of sleep-language foundation models that enable human sleep alignment, interpretation, and interaction with natural language. Despite the critical role of sleep, learning-based sleep analysis systems operate in closed label spaces (e.g., predefined stages or events) and fail to describe, query, or generalize to novel sleep phenomena. SleepLM bridges natural language and multimodal polysomnography, enabling language-grounded representations of sleep physiology. To support this alignment, we introduce a multilevel sleep caption generation pipeline that enables the curation of the first large-scale sleep-text dataset, comprising over 100K hours of data from more than 10,000 individuals. Furthermore, we present a unified pretraining objective that combines contrastive alignment, caption generation, and signal reconstruction to better capture physiological fidelity and cross-modal interactions. Extensive experiments on real-world sleep understanding tasks verify that SleepLM outperforms state-of-the-art in zero-shot and few-shot learning, cross-modal retrieval, and sleep captioning. Importantly, SleepLM also exhibits intriguing capabilities including language-guided event localization, targeted insight generation, and zero-shot generalization to unseen tasks. All code and data will be open-sourced.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "SleepLM: 人类睡眠的自然语言智能",
        "summary": "SleepLM是一个基础模型系列，通过在包含来自10,000多个个体的100,000多小时数据的多模态对齐数据集上进行训练，实现对人类睡眠的自然语言理解。该模型支持零样本睡眠事件定位和洞察生成，超越了传统的闭标签睡眠分类方法。"
      },
      "fr": {
        "title": "SleepLM: Intelligence en langage naturel pour le sommeil humain",
        "summary": "SleepLM est une famille de modèles fondamentaux permettant la compréhension du langage naturel du sommeil humain grâce à l'alignement multimodal sur un ensemble de données de 100 000+ heures de 10 000+ individus. Le modèle prend en charge la localisation d'événements de sommeil sans exemple et la génération d'insights, allant au-delà des approches traditionnelles de classification du sommeil avec étiquettes fermées."
      },
      "de": {
        "title": "SleepLM: Natürlichsprachige Intelligenz für menschlichen Schlaf",
        "summary": "SleepLM ist eine Grundmodell-Familie, die natürliches Sprachverständnis des menschlichen Schlafs durch multimodale Ausrichtung auf einem Datensatz von über 100.000 Stunden von über 10.000 Personen ermöglicht. Das Modell unterstützt schlaffreie Schlaf-Event-Lokalisierung und Insight-Generierung und geht über traditionelle geschlossene Schlafklassifizierungsansätze hinaus."
      },
      "es": {
        "title": "SleepLM: Inteligencia en lenguaje natural para el sueño humano",
        "summary": "SleepLM es una familia de modelos fundamentales que permite la comprensión del lenguaje natural del sueño humano a través de la alineación multimodal en un conjunto de datos de más de 100.000 horas de más de 10.000 individuos. El modelo admite localización de eventos de sueño sin ejemplos y generación de perspectivas, yendo más allá de los enfoques tradicionales de clasificación de sueño con etiquetas cerradas."
      }
    }
  },
  {
    "title": "MMKG-RDS: Reasoning Data Synthesis via Deep Mining of Multimodal Knowledge Graphs",
    "slug": "mmkg-rds-reasoning-data-synthesis-multimodal-knowledge-graphs",
    "url": "https://arxiv.org/abs/2602.23632",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "MMKG-RDS presents a framework for synthesizing high-quality training data through multimodal knowledge graphs with fine-grained extraction and multidimensional quality scoring. Fine-tuning models on synthesized data improves reasoning accuracy by 9.2%, demonstrating effectiveness across multiple domains.",
    "content": "arXiv:2602.23632v1 Announce Type: new \nAbstract: Synthesizing high-quality training data is crucial for enhancing domain models' reasoning abilities. Existing methods face limitations in long-tail knowledge coverage, effectiveness verification, and interpretability. Knowledge-graph-based approaches still fall short in functionality, granularity, customizability, and evaluation. To address these issues, we propose MMKG-RDS, a flexible framework for reasoning data synthesis that leverages multimodal knowledge graphs. It supports fine-grained knowledge extraction, customizable path sampling, and multidimensional data quality scoring. We validate MMKG-RDS with the MMKG-RDS-Bench dataset, covering five domains, 17 task types, and 14,950 samples. Experimental results show fine-tuning Qwen3 models (0.6B/8B/32B) on a small number of synthesized samples improves reasoning accuracy by 9.2%. The framework also generates distinct data, challenging existing models on tasks involving tables and formulas, useful for complex benchmark construction. The dataset and code are available at https://github.com/360AILAB-NLP/MMKG-RDS",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "MMKG-RDS：通过多模态知识图谱深度挖掘进行推理数据合成",
        "summary": "MMKG-RDS提出了一个框架，通过具有细粒度提取和多维质量评分的多模态知识图谱来合成高质量的训练数据。在合成数据上微调模型可将推理准确率提高9.2%，展示了其在多个领域的有效性。"
      },
      "fr": {
        "title": "MMKG-RDS : Synthèse de données de raisonnement par exploration approfondie des graphes de connaissances multimodaux",
        "summary": "MMKG-RDS présente un cadre pour synthétiser des données d'entraînement de haute qualité via des graphes de connaissances multimodaux avec extraction fine et notation de qualité multidimensionnelle. L'ajustement fin des modèles sur les données synthétisées améliore la précision du raisonnement de 9,2%, démontrant l'efficacité dans plusieurs domaines."
      },
      "de": {
        "title": "MMKG-RDS: Synthesisierung von Reasoning-Daten durch tiefe Analyse von Multimodalen Wissensgraphen",
        "summary": "MMKG-RDS präsentiert einen Rahmen zur Synthesisierung von hochwertigen Trainingsdaten durch Multimodale Wissensgraphen mit feingranularer Extraktion und mehrdimensionaler Qualitätsbewertung. Das Feintuning von Modellen auf synthetisierten Daten verbessert die Reasoning-Genauigkeit um 9,2% und demonstriert Effektivität über mehrere Domänen."
      },
      "es": {
        "title": "MMKG-RDS: Síntesis de Datos de Razonamiento mediante Minería Profunda de Gráficos de Conocimiento Multimodales",
        "summary": "MMKG-RDS presenta un marco para sintetizar datos de entrenamiento de alta calidad mediante gráficos de conocimiento multimodales con extracción de grano fino y puntuación de calidad multidimensional. El ajuste fino de modelos en datos sintetizados mejora la precisión del razonamiento en un 9,2%, demostrando efectividad en múltiples dominios."
      }
    }
  },
  {
    "title": "AI Must Embrace Specialization via Superhuman Adaptable Intelligence",
    "slug": "ai-specialization-superhuman-adaptable-intelligence",
    "url": "https://arxiv.org/abs/2602.23643",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "This paper critiques AGI as a flawed concept and proposes Superhuman Adaptable Intelligence (SAI) as a more practical framework emphasizing specialization and superhuman performance. The shift from generality to specialization provides clearer guidance for AI development and more realistic expectations.",
    "content": "arXiv:2602.23643v1 Announce Type: new \nAbstract: Everyone from AI executives and researchers to doomsayers, politicians, and activists is talking about Artificial General Intelligence (AGI). Yet, they often don't seem to agree on its exact definition. One common definition of AGI is an AI that can do everything a human can do, but are humans truly general? In this paper, we address what's wrong with our conception of AGI, and why, even in its most coherent formulation, it is a flawed concept to describe the future of AI. We explore whether the most widely accepted definitions are plausible, useful, and truly general. We argue that AI must embrace specialization, rather than strive for generality, and in its specialization strive for superhuman performance, and introduce Superhuman Adaptable Intelligence (SAI). SAI is defined as intelligence that can learn to exceed humans at anything important that we can do, and that can fill in the skill gaps where humans are incapable. We then lay out how SAI can help hone a discussion around AI that was blurred by an overloaded definition of AGI, and extrapolate the implications of using it as a guide for the future.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "AI必须通过超人类适应性智能拥抱专业化",
        "summary": "本文批评AGI是一个有缺陷的概念，提议超人类适应性智能(SAI)作为更实用的框架，强调专业化和超人类性能。从通用性到专业化的转变为AI发展提供了更清晰的指导和更现实的期望。"
      },
      "fr": {
        "title": "L'IA doit adopter la spécialisation via l'Intelligence Adaptable Surhumaine",
        "summary": "Cet article critique l'AGI comme un concept défectueux et propose l'Intelligence Adaptable Surhumaine (IAS) comme un cadre plus pratique mettant l'accent sur la spécialisation et les performances surhumaines. Le passage de la généralité à la spécialisation fournit une orientation plus claire pour le développement de l'IA et des attentes plus réalistes."
      },
      "de": {
        "title": "KI muss Spezialisierung durch Superhuman Adaptive Intelligence annehmen",
        "summary": "Dieses Papier kritisiert AGI als fehlerhaftes Konzept und schlägt Superhuman Adaptive Intelligence (SAI) als praktischeres Rahmenwerk vor, das Spezialisierung und übermenschliche Leistung betont. Der Wandel von Allgemeinheit zu Spezialisierung bietet klarere Anleitung für KI-Entwicklung und realistischere Erwartungen."
      },
      "es": {
        "title": "La IA debe abrazar la especialización a través de la Inteligencia Adaptable Sobrehumana",
        "summary": "Este artículo critica la AGI como un concepto defectuoso y propone la Inteligencia Adaptable Sobrehumana (SAI) como un marco más práctico que enfatiza la especialización y el desempeño sobrehumano. El cambio de la generalidad a la especialización proporciona orientación más clara para el desarrollo de la IA y expectativas más realistas."
      }
    }
  },
  {
    "title": "PseudoAct: Leveraging Pseudocode Synthesis for Flexible Planning and Action Control in Large Language Model Agents",
    "slug": "pseudoact-pseudocode-synthesis-llm-agent-planning-control",
    "url": "https://arxiv.org/abs/2602.23668",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "PseudoAct enables LLM agents to synthesize explicit pseudocode plans that structure tasks with clear control flows before execution. This approach significantly reduces redundant actions and token consumption while achieving state-of-the-art results on complex multi-step reasoning benchmarks.",
    "content": "arXiv:2602.23668v1 Announce Type: new \nAbstract: Large language model (LLM) agents typically rely on reactive decision-making paradigms such as ReAct, selecting actions conditioned on growing execution histories. While effective for short tasks, these approaches often lead to redundant tool usage, unstable reasoning, and high token consumption in complex long-horizon tasks involving branching, iteration, or multi-tool coordination. To address these limitations, this paper introduces PseudoAct, a novel framework for flexible planning and action control in LLM agents through pseudocode synthesis. Leveraging the ability of LLMs to express task-solving strategies as code, PseudoAct synthesizes a structured pseudocode plan that decomposes a task into subtasks and explicitly encodes control flow, including sequencing, conditionals, loops, parallel composition, and combinations of these logic primitives. Actions are then executed by following this global plan, making the decision logic explicit and temporally coherent. This design reduces redundant actions, prevents infinite loops, and avoids uninformative alternative exploration, enabling consistent and efficient long-horizon decision-making. Experiments on benchmark datasets show that our method significantly outperforms existing reactive agent approaches, achieving a 20.93% absolute gain in success rate on FEVER and setting a new state-of-the-art on HotpotQA.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "PseudoAct：利用伪代码合成实现大语言模型代理的灵活规划和动作控制",
        "summary": "PseudoAct使LLM代理能够合成明确的伪代码计划，在执行前使用清晰的控制流结构化任务。这种方法显著减少了冗余动作和令牌消耗，同时在复杂多步骤推理基准上达到了最先进的结果。"
      },
      "fr": {
        "title": "PseudoAct : Exploitation de la synthèse de pseudocode pour une planification flexible et un contrôle d'action dans les agents de modèles de langage volumineux",
        "summary": "PseudoAct permet aux agents LLM de synthétiser des plans pseudocode explicites qui structurent les tâches avec des flux de contrôle clairs avant l'exécution. Cette approche réduit considérablement les actions redondantes et la consommation de jetons tout en obtenant des résultats de pointe sur les benchmarks complexes de raisonnement multi-étapes."
      },
      "de": {
        "title": "PseudoAct: Nutzung von Pseudocode-Synthese für flexible Planung und Aktionssteuerung in Large Language Model Agenten",
        "summary": "PseudoAct ermöglicht es LLM-Agenten, explizite Pseudocode-Pläne zu synthetisieren, die Aufgaben mit klaren Kontrollflüssen vor der Ausführung strukturieren. Dieser Ansatz reduziert erheblich redundante Aktionen und Token-Verbrauch, während gleichzeitig hochmoderne Ergebnisse bei komplexen mehrstufigen Reasoning-Benchmarks erreicht werden."
      },
      "es": {
        "title": "PseudoAct: Aprovechamiento de la síntesis de pseudocódigo para planificación flexible y control de acciones en agentes de modelos de lenguaje grandes",
        "summary": "PseudoAct permite que los agentes LLM sintetizen planes de pseudocódigo explícitos que estructuran tareas con flujos de control claros antes de la ejecución. Este enfoque reduce significativamente las acciones redundantes y el consumo de tokens mientras logra resultados de vanguardia en benchmarks complejos de razonamiento de múltiples pasos."
      }
    }
  },
  {
    "title": "ODAR: Principled Adaptive Routing for LLM Reasoning via Active Inference",
    "slug": "odar-adaptive-routing-llm-reasoning-active-inference",
    "url": "https://arxiv.org/abs/2602.23681",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "ODAR-Expert optimizes the accuracy-efficiency trade-off in LLM reasoning through adaptive routing between fast and slow paths grounded in active inference. The framework achieves strong benchmark performance while reducing computational costs by 82% through principled free-energy-based decision-making.",
    "content": "arXiv:2602.23681v1 Announce Type: new \nAbstract: The paradigm of large language model (LLM) reasoning is shifting from parameter scaling to test-time compute scaling, yet many existing approaches still rely on uniform brute-force sampling (for example, fixed best-of-N or self-consistency) that is costly, hard to attribute, and can trigger overthinking with diminishing returns. We propose ODAR-Expert, an adaptive routing framework that optimizes the accuracy-efficiency trade-off via principled resource allocation. ODAR uses a difficulty estimator grounded in amortized active inference to dynamically route queries between a heuristic Fast Agent and a deliberative Slow Agent. We further introduce a free-energy-principled, risk-sensitive fusion mechanism that selects answers by minimizing a variational free energy objective, balancing log-likelihood with epistemic uncertainty (varentropy) as a principled alternative to ad hoc voting over heterogeneous candidates. Extensive evaluation across 23 benchmarks shows strong and consistent gains, including 98.2% accuracy on MATH and 54.8% on Humanity's Last Exam (HLE), while improving the compute-accuracy frontier under compute-matched settings. We also validate reproducibility on a fully open-source stack (Llama 4 + DeepSeek), where ODAR surpasses homogeneous sampling strategies while reducing computational costs by 82%. Overall, our results suggest that thinking-optimal scaling requires adaptive resource allocation with free-energy-based decision-making rather than simply increasing test-time compute.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ODAR：通过主动推理为LLM推理的有原则自适应路由",
        "summary": "ODAR-Expert通过以主动推理为基础的快速和慢速路径之间的自适应路由来优化LLM推理中的准确性-效率权衡。该框架通过有原则的自由能决策，实现了强大的基准性能，同时将计算成本降低了82%。"
      },
      "fr": {
        "title": "ODAR : Routage Adaptatif Principié pour le Raisonnement des LLM via l'Inférence Active",
        "summary": "ODAR-Expert optimise le compromis précision-efficacité dans le raisonnement des LLM par le routage adaptatif entre des chemins rapides et lents fondés sur l'inférence active. Le framework atteint des performances de référence solides tout en réduisant les coûts informatiques de 82% grâce à une prise de décision basée sur l'énergie libre principée."
      },
      "de": {
        "title": "ODAR: Prinzipiertes adaptives Routing für LLM-Reasoning durch Active Inference",
        "summary": "ODAR-Expert optimiert den Genauigkeit-Effizienz-Kompromiss beim LLM-Reasoning durch adaptives Routing zwischen schnellen und langsamen Pfaden, die auf Active Inference basieren. Das Framework erreicht starke Benchmark-Leistungen und reduziert gleichzeitig Rechenkosten um 82% durch prinzipierte Free-Energy-basierte Entscheidungsfindung."
      },
      "es": {
        "title": "ODAR: Enrutamiento Adaptativo Fundamentado para Razonamiento de LLM mediante Inferencia Activa",
        "summary": "ODAR-Expert optimiza el equilibrio precisión-eficiencia en el razonamiento de LLM mediante el enrutamiento adaptativo entre rutas rápidas y lentas fundamentadas en inferencia activa. El framework logra un desempeño sólido en los puntos de referencia mientras reduce los costos computacionales en un 82% mediante la toma de decisiones basada en energía libre fundamentada."
      }
    }
  },
  {
    "title": "From Flat Logs to Causal Graphs: Hierarchical Failure Attribution for LLM-based Multi-Agent Systems",
    "slug": "hierarchical-failure-attribution-llm-multi-agent-systems-chief",
    "url": "https://arxiv.org/abs/2602.23701",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "CHIEF transforms flat execution logs into hierarchical causal graphs to attribute failures in LLM-based multi-agent systems. Through oracle-guided backtracking and counterfactual screening, it reliably distinguishes root causes from propagated symptoms with higher accuracy than existing methods.",
    "content": "arXiv:2602.23701v1 Announce Type: new \nAbstract: LLM-powered Multi-Agent Systems (MAS) have demonstrated remarkable capabilities in complex domains but suffer from inherent fragility and opaque failure mechanisms. Existing failure attribution methods, whether relying on direct prompting, costly replays, or supervised fine-tuning, typically treat execution logs as flat sequences. This linear perspective fails to disentangle the intricate causal links inherent to MAS, leading to weak observability and ambiguous responsibility boundaries. To address these challenges, we propose CHIEF, a novel framework that transforms chaotic trajectories into a structured hierarchical causal graph. It then employs hierarchical oracle-guided backtracking to efficiently prune the search space via sybthesized virtual oracles. Finally, it implements counterfactual attribution via a progressive causal screening strategy to rigorously distinguish true root causes from propagated symptoms. Experiments on Who&When benchmark show that CHIEF outperforms eight strong and state-of-the-art baselines on both agent- and step-level accuracy. Ablation studies further confirm the critical role of each proposed module.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "从平坦日志到因果图：基于LLM的多智能体系统的分层故障归因",
        "summary": "CHIEF将平坦执行日志转换为分层因果图，以归因基于LLM的多智能体系统中的故障。通过预言机指导的回溯和反事实筛选，它能可靠地区分根本原因和传播症状，准确性高于现有方法。"
      },
      "fr": {
        "title": "Des Journaux Plats aux Graphiques de Causalité : Attribution Hiérarchique des Défaillances pour les Systèmes Multi-Agents basés sur LLM",
        "summary": "CHIEF transforme les journaux d'exécution plats en graphiques de causalité hiérarchiques pour attribuer les défaillances dans les systèmes multi-agents basés sur LLM. Grâce au rétrotraçage guidé par oracle et au criblage contrefactuel, il distingue de manière fiable les causes racines des symptômes propagés avec une précision plus élevée que les méthodes existantes."
      },
      "de": {
        "title": "Von flachen Protokollen zu Kausalitätsgraphen: Hierarchische Fehlerattribution für LLM-basierte Multi-Agent-Systeme",
        "summary": "CHIEF wandelt flache Ausführungsprotokolle in hierarchische Kausalitätsgraphen um, um Fehler in LLM-basierten Multi-Agent-Systemen zuzuordnen. Durch Oracle-gesteuertes Backtracking und kontrafaktisches Screening unterscheidet es zuverlässig Grundursachen von propagierten Symptomen mit höherer Genauigkeit als bestehende Methoden."
      },
      "es": {
        "title": "De Registros Planos a Gráficos Causales: Atribución Jerárquica de Fallos para Sistemas Multi-Agente basados en LLM",
        "summary": "CHIEF transforma registros de ejecución planos en gráficos causales jerárquicos para atribuir fallos en sistemas multi-agente basados en LLM. A través de rastreo guiado por oráculo y filtrado contrafáctico, distingue de manera confiable las causas raíz de los síntomas propagados con mayor precisión que los métodos existentes."
      }
    }
  },
  {
    "title": "ProductResearch: Training E-Commerce Deep Research Agents via Multi-Agent Synthetic Trajectory Distillation",
    "slug": "productresearch-ecommerce-deep-research-agents-trajectory",
    "url": "https://arxiv.org/abs/2602.23716",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "ProductResearch synthesizes high-fidelity tool-use trajectories for training e-commerce shopping agents through multi-agent collaboration and reflective distillation. The framework enables compact models to achieve substantial improvements in research depth and user-perceived utility for complex shopping inquiries.",
    "content": "arXiv:2602.23716v1 Announce Type: new \nAbstract: Large Language Model (LLM)-based agents show promise for e-commerce conversational shopping, yet existing implementations lack the interaction depth and contextual breadth required for complex product research. Meanwhile, the Deep Research paradigm, despite advancing information synthesis in web search, suffers from domain gaps when transferred to e-commerce. We propose ProductResearch, a multi-agent framework that synthesizes high-fidelity, long-horizon tool-use trajectories for training robust e-commerce shopping agents. The framework employs a User Agent to infer nuanced shopping intents from behavioral histories, and a Supervisor Agent that orchestrates iterative collaboration with a Research Agent to generate synthetic trajectories culminating in comprehensive, insightful product research reports. These trajectories are rigorously filtered and distilled through a reflective internalization process that consolidates multi-agent supervisory interactions into coherent single-role training examples, enabling effective fine-tuning of LLM agents for complex shopping inquiries. Extensive experiments show that a compact MoE model fine-tuned on our synthetic data achieves substantial improvements over its base model in response comprehensiveness, research depth, and user-perceived utility, approaching the performance of frontier proprietary deep research systems and establishing multi-agent synthetic trajectory training as an effective and scalable paradigm for enhancing LLM-based shopping assistance.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ProductResearch：通过多智能体合成轨迹蒸馏训练电子商务深度研究智能体",
        "summary": "ProductResearch通过多智能体协作和反思蒸馏为电子商务购物智能体的训练合成高保真工具使用轨迹。该框架使紧凑模型能够在研究深度和用户感知的复杂购物查询效用方面实现实质性改进。"
      },
      "fr": {
        "title": "ProductResearch : Formation d'Agents de Recherche Profonde pour le Commerce Électronique via Distillation de Trajectoires Synthétiques Multi-Agents",
        "summary": "ProductResearch synthétise des trajectoires d'utilisation d'outils haute fidélité pour l'entraînement d'agents de shopping de commerce électronique grâce à la collaboration multi-agents et à la distillation réflexive. Le framework permet aux modèles compacts d'atteindre des améliorations substantielles dans la profondeur de la recherche et l'utilité perçue par l'utilisateur pour les recherches commerciales complexes."
      },
      "de": {
        "title": "ProductResearch: Training von E-Commerce-Tiefenforschungs-Agenten durch Multi-Agent-Synthetische-Trajectorie-Destillation",
        "summary": "ProductResearch synthetisiert hochgenaue Tool-Use-Trajektorien für das Training von E-Commerce-Shopping-Agenten durch Multi-Agent-Zusammenarbeit und reflektive Destillation. Das Framework ermöglicht es kompakten Modellen, substantielle Verbesserungen in der Forschungstiefe und benutzergenommener Nützlichkeit für komplexe Shopping-Anfragen zu erreichen."
      },
      "es": {
        "title": "ProductResearch: Entrenamiento de Agentes de Investigación Profunda de Comercio Electrónico mediante Destilación de Trayectorias Sintéticas Multiagente",
        "summary": "ProductResearch sintetiza trayectorias de uso de herramientas de alta fidelidad para entrenar agentes de compra de comercio electrónico a través de colaboración multiagente y destilación reflexiva. El framework permite que modelos compactos logren mejoras sustanciales en profundidad de investigación y utilidad percibida por el usuario para búsquedas de compra complejas."
      }
    }
  },
  {
    "title": "The Auton Agentic AI Framework",
    "slug": "auton-agentic-ai-framework-architecture-agents",
    "url": "https://arxiv.org/abs/2602.23720",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "The Auton Framework provides a principled architecture for autonomous agents separating declarative Cognitive Blueprints from Runtime Engines, addressing the mismatch between stochastic LLM outputs and deterministic backend systems. The design includes hierarchical memory, formal safety constraints, and runtime optimizations for efficient multi-step execution.",
    "content": "arXiv:2602.23720v1 Announce Type: new \nAbstract: The field of Artificial Intelligence is undergoing a transition from Generative AI -- probabilistic generation of text and images -- to Agentic AI, in which autonomous systems execute actions within external environments on behalf of users. This transition exposes a fundamental architectural mismatch: Large Language Models (LLMs) produce stochastic, unstructured outputs, whereas the backend infrastructure they must control -- databases, APIs, cloud services -- requires deterministic, schema-conformant inputs. The present paper describes the Auton Agentic AI Framework, a principled architecture for standardizing the creation, execution, and governance of autonomous agent systems. The framework is organized around a strict separation between the Cognitive Blueprint, a declarative, language-agnostic specification of agent identity and capabilities, and the Runtime Engine, the platform-specific execution substrate that instantiates and runs the agent. This separation enables cross-language portability, formal auditability, and modular tool integration via the Model Context Protocol (MCP). The paper formalizes the agent execution model as an augmented Partially Observable Markov Decision Process (POMDP) with a latent reasoning space, introduces a hierarchical memory consolidation architecture inspired by biological episodic memory systems, defines a constraint manifold formalism for safety enforcement via policy projection rather than post-hoc filtering, presents a three-level self-evolution framework spanning in-context adaptation through reinforcement learning, and describes runtime optimizations -- including parallel graph execution, speculative inference, and dynamic context pruning -- that reduce end-to-end latency for multi-step agent workflows.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "Auton智能AI框架",
        "summary": "Auton框架为自主智能体提供了有原则的架构，将声明式认知蓝图与运行时引擎分离，解决了随机LLM输出与确定性后端系统之间的不匹配。该设计包括分层内存、正式安全约束和运行时优化，用于高效的多步执行。"
      },
      "fr": {
        "title": "Le Framework d'IA Agentique Auton",
        "summary": "Le framework Auton fournit une architecture principiée pour les agents autonomes, séparant les Blueprints Cognitifs déclaratifs des moteurs d'exécution, résolvant l'inadéquation entre les résultats stochastiques des LLM et les systèmes backend déterministes. La conception comprend une mémoire hiérarchique, des contraintes de sécurité formelles et des optimisations à l'exécution pour une exécution multi-étapes efficace."
      },
      "de": {
        "title": "Das Auton Agentic-AI-Framework",
        "summary": "Das Auton-Framework bietet eine prinzipienbasierte Architektur für autonome Agenten und trennt deklarative Cognitive Blueprints von Runtime Engines, um die Diskrepanz zwischen stochastischen LLM-Ausgaben und deterministischen Backend-Systemen zu beheben. Das Design umfasst hierarchisches Speicher, formale Sicherheitsbeschränkungen und Laufzeitoptimierungen für effiziente mehrstufige Ausführung."
      },
      "es": {
        "title": "El Framework de IA Agentivo Auton",
        "summary": "El framework Auton proporciona una arquitectura principiada para agentes autónomos, separando Planos Cognitivos declarativos de motores de ejecución, abordando la discrepancia entre salidas estocásticas de LLM y sistemas backend deterministas. El diseño incluye memoria jerárquica, restricciones de seguridad formales y optimizaciones en tiempo de ejecución para una ejecución eficiente de múltiples pasos."
      }
    }
  },
  {
    "title": "Unlocking Cognitive Capabilities and Analyzing the Perception-Logic Trade-off",
    "slug": "unlocking-cognitive-capabilities-perception-logic-tradeoff-mlm",
    "url": "https://arxiv.org/abs/2602.23730",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "MERaLiON2-Omni (Alpha) is a multilingual omni-perception model for Southeast Asia that decouples perception and reasoning to address their efficiency-stability trade-off. The research reveals how extended reasoning can destabilize low-level sensory processing through temporal drift and visual over-interpretation.",
    "content": "arXiv:2602.23730v1 Announce Type: new \nAbstract: Recent advancements in Multimodal Large Language Models (MLLMs) pursue omni-perception capabilities, yet integrating robust sensory grounding with complex reasoning remains a challenge, particularly for underrepresented regions. In this report, we introduce the research preview of MERaLiON2-Omni (Alpha), a 10B-parameter multilingual omni-perception tailored for Southeast Asia (SEA). We present a progressive training pipeline that explicitly decouples and then integrates \"System 1\" (Perception) and \"System 2\" (Reasoning) capabilities. First, we establish a robust Perception Backbone by aligning region-specific audio-visual cues (e.g., Singlish code-switching, local cultural landmarks) with a multilingual LLM through orthogonal modality adaptation. Second, to inject cognitive capabilities without large-scale supervision, we propose a cost-effective Generate-Judge-Refine pipeline. By utilizing a Super-LLM to filter hallucinations and resolve conflicts via a consensus mechanism, we synthesize high-quality silver data that transfers textual Chain-of-Thought reasoning to multimodal scenarios.\n  Comprehensive evaluation on our newly introduced SEA-Omni Benchmark Suite reveals an Efficiency-Stability Paradox: while reasoning acts as a non-linear amplifier for abstract tasks (boosting mathematical and instruction-following performance significantly), it introduces instability in low-level sensory processing. Specifically, we identify Temporal Drift in long-context audio, where extended reasoning desynchronizes the model from acoustic timestamps, and Visual Over-interpretation, where logic overrides pixel-level reality. This report details the architecture, the data-efficient training recipe, and a diagnostic analysis of the trade-offs between robust perception and structured reasoning.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "解锁认知能力和分析感知-逻辑权衡",
        "summary": "MERaLiON2-Omni（Alpha）是为东南亚设计的多语言全感知模型，将感知和推理分离以解决效率-稳定性权衡。研究揭示了扩展推理如何通过时间漂移和视觉过度解释来破坏低级感官处理。"
      },
      "fr": {
        "title": "Débloquer les Capacités Cognitives et Analyser le Compromis Perception-Logique",
        "summary": "MERaLiON2-Omni (Alpha) est un modèle omni-perception multilingue pour l'Asie du Sud-Est qui découple la perception et le raisonnement pour résoudre leur compromis efficacité-stabilité. La recherche révèle comment le raisonnement étendu peut déstabiliser le traitement sensoriel de bas niveau à travers la dérive temporelle et la sur-interprétation visuelle."
      },
      "de": {
        "title": "Entsperren kognitiver Fähigkeiten und Analyse des Wahrnehmungs-Logik-Kompromisses",
        "summary": "MERaLiON2-Omni (Alpha) ist ein mehrsprachiges Omni-Perception-Modell für Südostasien, das Wahrnehmung und Reasoning entkoppelt, um ihren Effizienz-Stabilitäts-Kompromiss zu bewältigen. Die Forschung zeigt, wie erweitertes Reasoning die Verarbeitung sensorischer Signale auf niedriger Ebene durch zeitliche Verschiebung und visuelle Überinterpretation destabilisieren kann."
      },
      "es": {
        "title": "Desbloquear Capacidades Cognitivas y Analizar el Compromiso Percepción-Lógica",
        "summary": "MERaLiON2-Omni (Alpha) es un modelo omni-percepción multilingüe para el Sudeste Asiático que desacopla la percepción y el razonamiento para abordar su compensación eficiencia-estabilidad. La investigación revela cómo el razonamiento extendido puede desestabilizar el procesamiento sensorial de bajo nivel a través de la deriva temporal y la sobreinterpretación visual."
      }
    }
  },
  {
    "title": "Reasoning-Driven Multimodal LLM for Domain Generalization",
    "slug": "reasoning-driven-multimodal-llm-domain-generalization",
    "url": "https://arxiv.org/abs/2602.23777",
    "source": "arXiv cs.AI",
    "date": "2026-03-02T05:00:00.000Z",
    "summary": "RD-MLDG leverages reasoning chains in multimodal LLMs for domain generalization by addressing the trade-off between semantic richness and optimization efficiency. The framework achieves state-of-the-art results through multi-task cross-training and self-aligned reasoning regularization on standard benchmarks.",
    "content": "arXiv:2602.23777v1 Announce Type: new \nAbstract: This paper addresses the domain generalization (DG) problem in deep learning. While most DG methods focus on enforcing visual feature invariance, we leverage the reasoning capability of multimodal large language models (MLLMs) and explore the potential of constructing reasoning chains that derives image categories to achieve more robust predictions under domain shift. To this end, we systematically study the role of reasoning in DG using DomainBed-Reasoning, a newly constructed extension of DomainBed dataset, in which each sample is paired with class-relevant reasoning chains. Our analysis reveals two key challenges: (i) fine-tuning MLLMs with reasoning chains for classification is more challenging than direct label supervision, since the model must optimize complex reasoning sequences before label prediction; and (ii) mismatches in reasoning patterns between supervision signals and fine-tuned MLLMs lead to a trade-off between semantic richness (informative but harder to optimize) and optimization efficiency (easier to optimize but less informative). To address these issues, we propose RD-MLDG (Reasoning-Driven Multimodal LLM for Domain Generalization), a framework with two components: (i) MTCT (Multi-Task Cross-Training), which introduces an additional direct classification pathway to guide reasoning supervision; and (ii) SARR (Self-Aligned Reasoning Regularization), which preserves the semantic richness of reasoning chains while mitigating reasoning-pattern mismatches via iterative self-labeling. Experiments on standard DomainBed datasets (PACS, VLCS, OfficeHome, TerraInc) demonstrate that RD-MLDG achieves state-of-the-art performances, highlighting reasoning as a promising complementary signal for robust out-of-domain generalization.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "用于域泛化的推理驱动型多模态LLM",
        "summary": "RD-MLDG通过在多模态LLM中利用推理链来实现域泛化，解决语义丰富性和优化效率之间的权衡。该框架通过多任务交叉训练和自对齐推理正则化在标准基准上实现了最先进的结果。"
      },
      "fr": {
        "title": "LLM Multimodal Piloté par le Raisonnement pour la Généralisation de Domaine",
        "summary": "RD-MLDG exploite les chaînes de raisonnement dans les LLM multimodaux pour la généralisation de domaine en abordant le compromis entre la richesse sémantique et l'efficacité de l'optimisation. Le framework atteint des résultats à la pointe de la technologie grâce à l'entraînement croisé multi-tâches et à la régularisation du raisonnement auto-aligné sur les benchmarks standard."
      },
      "de": {
        "title": "Reasoning-gesteuertes Multimodales LLM zur Domänengeneralisierung",
        "summary": "RD-MLDG nutzt Reasoning-Ketten in multimodalen LLMs für die Domänengeneralisierung, indem es den Kompromiss zwischen semantischer Reichhaltigkeit und Optimierungseffizienz anspricht. Das Framework erreicht modernste Ergebnisse durch Multi-Task-Cross-Training und selbstausgerichtete Reasoning-Regularisierung auf Standard-Benchmarks."
      },
      "es": {
        "title": "LLM Multimodal Impulsado por Razonamiento para Generalización de Dominio",
        "summary": "RD-MLDG aprovecha las cadenas de razonamiento en LLM multimodales para la generalización de dominio abordando el compromiso entre riqueza semántica y eficiencia de optimización. El framework logra resultados de última generación a través del entrenamiento cruzado multi-tarea y regularización de razonamiento auto-alineado en referencias estándar."
      }
    }
  }
]