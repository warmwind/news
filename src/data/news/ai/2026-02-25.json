[
  {
    "title": "Multilevel Determinants of Overweight and Obesity Among U.S. Children Aged 10-17: Comparative Evaluation of Statistical and Machine Learning Approaches Using the 2021 National Survey of Children's Health",
    "slug": "childhood-obesity-prediction-ml-comparison",
    "url": "https://arxiv.org/abs/2602.20303",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "This study compares statistical and machine learning approaches to predict childhood obesity using data from 18,792 U.S. children, finding that logistic regression performs comparably to more complex models while persistent disparities across racial and socioeconomic groups remain. The research demonstrates that increased algorithmic complexity provides limited benefits over simpler approaches, emphasizing the need for improved data quality and equity-focused surveillance rather than more sophisticated models.",
    "content": "arXiv:2602.20303v1 Announce Type: new \nAbstract: Background: Childhood and adolescent overweight and obesity remain major public health concerns in the United States and are shaped by behavioral, household, and community factors. Their joint predictive structure at the population level remains incompletely characterized. Objectives: The study aims to identify multilevel predictors of overweight and obesity among U.S. adolescents and compare the predictive performance, calibration, and subgroup equity of statistical, machine-learning, and deep-learning models. Data and Methods: We analyze 18,792 children aged 10-17 years from the 2021 National Survey of Children's Health. Overweight/obesity is defined using BMI categories. Predictors included diet, physical activity, sleep, parental stress, socioeconomic conditions, adverse experiences, and neighborhood characteristics. Models include logistic regression, random forest, gradient boosting, XGBoost, LightGBM, multilayer perceptron, and TabNet. Performance is evaluated using AUC, accuracy, precision, recall, F1 score, and Brier score. Results: Discrimination range from 0.66 to 0.79. Logistic regression, gradient boosting, and MLP showed the most stable balance of discrimination and calibration. Boosting and deep learning modestly improve recall and F1 score. No model was uniformly superior. Performance disparities across race and poverty groups persist across algorithms. Conclusion: Increased model complexity yields limited gains over logistic regression. Predictors consistently span behavioral, household, and neighborhood domains. Persistent subgroup disparities indicate the need for improved data quality and equity-focused surveillance rather than greater algorithmic complexity.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "美国10-17岁儿童超重和肥胖的多层次决定因素：使用2021年全国儿童健康调查的统计和机器学习方法比较评估",
        "summary": "本研究比较统计和机器学习方法预测儿童肥胖症，使用来自18,792名美国儿童的数据，发现逻辑回归的性能与更复杂的模型相当，但种族和社会经济群体之间的持久差异依然存在。研究表明增加算法复杂性相比更简单的方法收益有限，强调需要改进数据质量和以公平性为重点的监测，而不是更复杂的模型。"
      },
      "ja": {
        "title": "米国10-17歳児童における過体重と肥満の多層的決定因子：2021年全国児童保健調査を使用した統計学的および機械学習アプローチの比較評価",
        "summary": "本研究は18,792人の米国児童のデータを用いた小児肥満症予測における統計的および機械学習アプローチを比較し、ロジスティック回帰がより複雑なモデルと同等の性能を発揮する一方、人種および社会経済的グループ間の持続的な格差が存在することを発見した。研究は、アルゴリズム複雑性の増加がより単純なアプローチに対して限定的な利益を提供することを示し、より洗練されたモデルではなく、データ品質の向上と公平性に焦点を当てた監視の必要性を強調している。"
      },
      "ko": {
        "title": "미국 10-17세 아동의 과체중 및 비만의 다층적 결정요인: 2021년 전국 아동 건강 조사를 사용한 통계 및 기계학습 방법의 비교 평가",
        "summary": "본 연구는 18,792명의 미국 아동 데이터를 사용하여 소아 비만 예측을 위한 통계적 및 기계학습 방법을 비교하였으며, 로지스틱 회귀가 더 복잡한 모델과 비슷한 성능을 보이면서 인종 및 사회경제적 집단 간 지속적인 격차가 존재함을 발견했다. 연구는 알고리즘 복잡성 증가가 더 간단한 방법에 비해 제한된 이점을 제공하며, 더 정교한 모델보다는 데이터 품질 개선 및 공평성 중심 모니터링의 필요성을 강조한다."
      },
      "fr": {
        "title": "Déterminants multiples du surpoids et de l'obésité chez les enfants américains âgés de 10 à 17 ans : évaluation comparative des approches statistiques et d'apprentissage automatique utilisant l'Enquête nationale sur la santé des enfants 2021",
        "summary": "Cette étude compare les approches statistiques et d'apprentissage automatique pour prédire l'obésité infantile en utilisant des données de 18 792 enfants américains, constatant que la régression logistique fonctionne de manière comparable aux modèles plus complexes tandis que les disparités persistantes entre les groupes raciaux et socioéconomiques demeurent. La recherche démontre que l'augmentation de la complexité algorithmique offre des bénéfices limités par rapport aux approches plus simples, soulignant le besoin d'améliorer la qualité des données et la surveillance axée sur l'équité plutôt que des modèles plus sophistiqués."
      },
      "de": {
        "title": "Mehrstufige Determinanten von Übergewicht und Adipositas bei US-Kindern im Alter von 10-17 Jahren: Vergleichende Bewertung statistischer und maschineller Lernansätze anhand der National Survey of Children's Health 2021",
        "summary": "Diese Studie vergleicht statistische und maschinelle Lernansätze zur Vorhersage von Adipositas bei Kindern anhand von Daten von 18.792 US-amerikanischen Kindern und stellt fest, dass die logistische Regression vergleichbar mit komplexeren Modellen funktioniert, während anhaltende Disparitäten zwischen rassischen und sozioökonomischen Gruppen bestehen bleiben. Die Forschung zeigt, dass eine erhöhte algorithmische Komplexität nur begrenzte Vorteile gegenüber einfacheren Ansätzen bietet und unterstreicht die Notwendigkeit verbesserter Datenqualität und auf Gerechtigkeit ausgerichteter Überwachung statt anspruchsvollerer Modelle."
      },
      "es": {
        "title": "Determinantes multiniveles del sobrepeso y la obesidad entre niños estadounidenses de 10-17 años: Evaluación comparativa de enfoques estadísticos y de aprendizaje automático utilizando la Encuesta Nacional de Salud Infantil de 2021",
        "summary": "Este estudio compara enfoques estadísticos y de aprendizaje automático para predecir la obesidad infantil utilizando datos de 18.792 niños estadounidenses, encontrando que la regresión logística funciona de manera comparable a modelos más complejos mientras persisten disparidades entre grupos raciales y socioeconómicos. La investigación demuestra que el aumento de la complejidad algorítmica proporciona beneficios limitados sobre enfoques más simples, enfatizando la necesidad de mejorar la calidad de los datos y la vigilancia centrada en la equidad en lugar de modelos más sofisticados."
      }
    }
  },
  {
    "title": "An artificial intelligence framework for end-to-end rare disease phenotyping from clinical notes using large language models",
    "slug": "rare-disease-phenotyping-llm-framework",
    "url": "https://arxiv.org/abs/2602.20324",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Researchers developed RARE-PHENIX, an AI framework that extracts disease phenotypes from clinical notes and standardizes them to medical ontology terms for rare disease diagnosis. The framework outperformed existing methods by combining natural language processing with supervised ranking, showing potential to support clinician-assisted diagnosis in real-world settings.",
    "content": "arXiv:2602.20324v1 Announce Type: new \nAbstract: Phenotyping is fundamental to rare disease diagnosis, but manual curation of structured phenotypes from clinical notes is labor-intensive and difficult to scale. Existing artificial intelligence approaches typically optimize individual components of phenotyping but do not operationalize the full clinical workflow of extracting features from clinical text, standardizing them to Human Phenotype Ontology (HPO) terms, and prioritizing diagnostically informative HPO terms. We developed RARE-PHENIX, an end-to-end AI framework for rare disease phenotyping that integrates large language model-based phenotype extraction, ontology-grounded standardization to HPO terms, and supervised ranking of diagnostically informative phenotypes. We trained RARE-PHENIX using data from 2,671 patients across 11 Undiagnosed Diseases Network clinical sites, and externally validated it on 16,357 real-world clinical notes from Vanderbilt University Medical Center. Using clinician-curated HPO terms as the gold standard, RARE-PHENIX consistently outperformed a state-of-the-art deep learning baseline (PhenoBERT) across ontology-based similarity and precision-recall-F1 metrics in end-to-end evaluation (i.e., ontology-based similarity of 0.70 vs. 0.58). Ablation analyses demonstrated performance improvements with the addition of each module in RARE-PHENIX (extraction, standardization, and prioritization), supporting the value of modeling the full clinical phenotyping workflow. By modeling phenotyping as a clinically aligned workflow rather than a single extraction task, RARE-PHENIX provides structured, ranked phenotypes that are more concordant with clinician curation and has the potential to support human-in-the-loop rare disease diagnosis in real-world settings.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "使用大型语言模型从临床笔记进行端到端罕见病表型鉴定的人工智能框架",
        "summary": "研究人员开发了RARE-PHENIX，一个从临床笔记中提取疾病表型并将其标准化为医学本体术语用于罕见病诊断的人工智能框架。该框架通过结合自然语言处理与监督排序优于现有方法，展示了在真实环境中支持临床医生辅助诊断的潜力。"
      },
      "ja": {
        "title": "大規模言語モデルを使用した臨床ノートからのエンドツーエンド罕少疾患表現型鑑別のための人工知能フレームワーク",
        "summary": "研究者らはRAREPHENIXを開発し、臨床ノートから疾患表現型を抽出し、罕少疾患診断のための医学オントロジー用語に標準化する人工知能フレームワークである。このフレームワークは自然言語処理と教師ありランキングを組み合わせることで既存の方法を上回り、実際の設定で臨床医支援診断をサポートする可能性を示した。"
      },
      "ko": {
        "title": "대규모 언어 모델을 사용한 임상 기록에서 희귀 질병 표현형의 종단 간 식별을 위한 인공지능 프레임워크",
        "summary": "연구자들은 임상 기록에서 질병 표현형을 추출하고 희귀 질병 진단을 위해 의학 온톨로지 용어로 표준화하는 인공지능 프레임워크인 RARE-PHENIX를 개발했다. 이 프레임워크는 자연어 처리와 지도학습 순위를 결합하여 기존 방법을 능가했으며, 실제 환경에서 임상의 보조 진단을 지원할 잠재력을 보여주었다."
      },
      "fr": {
        "title": "Un cadre d'intelligence artificielle pour l'identification phénotypique des maladies rares de bout en bout à partir de notes cliniques utilisant des modèles de langage de grande taille",
        "summary": "Les chercheurs ont développé RARE-PHENIX, un cadre d'IA qui extrait les phénotypes de maladies des notes cliniques et les standardise en termes d'ontologie médicale pour le diagnostic des maladies rares. Le cadre a surpassé les méthodes existantes en combinant le traitement du langage naturel avec le classement supervisé, montrant le potentiel de soutenir le diagnostic assisté par clinicien dans les paramètres du monde réel."
      },
      "de": {
        "title": "Ein Rahmen für künstliche Intelligenz zur End-to-End-Phänotypisierung seltener Krankheiten aus klinischen Notizen unter Verwendung großer Sprachmodelle",
        "summary": "Forscher entwickelten RARE-PHENIX, einen KI-Rahmen, der Krankheitsphänotypen aus klinischen Notizen extrahiert und sie auf medizinische Ontologie-Begriffe standardisiert für die Diagnose seltener Krankheiten. Der Rahmen übertraf bestehende Methoden durch die Kombination von Verarbeitung natürlicher Sprache mit überwachtem Ranking und zeigte das Potenzial, die kliniker-unterstützte Diagnose in realen Szenarien zu unterstützen."
      },
      "es": {
        "title": "Un marco de inteligencia artificial para la identificación fenotípica de enfermedades raras de extremo a extremo a partir de notas clínicas utilizando modelos de lenguaje grande",
        "summary": "Los investigadores desarrollaron RARE-PHENIX, un marco de IA que extrae fenotipos de enfermedades de notas clínicas y los estandariza en términos de ontología médica para el diagnóstico de enfermedades raras. El marco superó los métodos existentes al combinar procesamiento de lenguaje natural con clasificación supervisada, mostrando potencial para apoyar el diagnóstico asistido por clínicos en entornos del mundo real."
      }
    }
  },
  {
    "title": "DMCD: Semantic-Statistical Framework for Causal Discovery",
    "slug": "dmcd-causal-discovery-framework",
    "url": "https://arxiv.org/abs/2602.20333",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "DMCD combines large language models' semantic reasoning with statistical validation to discover causal relationships in data, using AI to propose initial causal structures that are then refined through statistical testing. The approach achieved competitive performance on real-world datasets spanning industrial and environmental domains, demonstrating the value of combining semantic priors with statistical verification.",
    "content": "arXiv:2602.20333v1 Announce Type: new \nAbstract: We present DMCD (DataMap Causal Discovery), a two-phase causal discovery framework that integrates LLM-based semantic drafting from variable metadata with statistical validation on observational data. In Phase I, a large language model proposes a sparse draft DAG, serving as a semantically informed prior over the space of possible causal structures. In Phase II, this draft is audited and refined via conditional independence testing, with detected discrepancies guiding targeted edge revisions.\n  We evaluate our approach on three metadata-rich real-world benchmarks spanning industrial engineering, environmental monitoring, and IT systems analysis. Across these datasets, DMCD achieves competitive or leading performance against diverse causal discovery baselines, with particularly large gains in recall and F1 score. Probing and ablation experiments suggest that these improvements arise from semantic reasoning over metadata rather than memorization of benchmark graphs. Overall, our results demonstrate that combining semantic priors with principled statistical verification yields a high-performing and practically effective approach to causal structure learning.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "DMCD：用于因果发现的语义-统计框架",
        "summary": "DMCD结合大型语言模型的语义推理和统计验证来发现数据中的因果关系，使用人工智能提出初始因果结构，然后通过统计测试进行优化。该方法在跨越工业和环境领域的真实数据集上取得竞争性性能，展示了结合语义先验与统计验证的价值。"
      },
      "ja": {
        "title": "DMCD：因果発見のための意味論-統計的フレームワーク",
        "summary": "DMCDは大規模言語モデルの意味論的推論と統計的検証を組み合わせてデータ内の因果関係を発見し、AIを使用して初期因果構造を提案し、その後統計的テストを通じて洗練される。このアプローチは産業および環境領域にまたがる実世界のデータセットで競争力のあるパフォーマンスを達成し、意味論的先験と統計的検証の組み合わせの価値を実証した。"
      },
      "ko": {
        "title": "DMCD: 인과 발견을 위한 의미-통계 프레임워크",
        "summary": "DMCD는 대규모 언어 모델의 의미론적 추론과 통계적 검증을 결합하여 데이터의 인과관계를 발견하며, AI를 사용하여 초기 인과구조를 제안한 후 통계적 검증을 통해 정제한다. 이 접근법은 산업 및 환경 분야에 걸친 실제 데이터셋에서 경쟁력 있는 성능을 달성했으며, 의미론적 선행정보와 통계적 검증 결합의 가치를 입증했다."
      },
      "fr": {
        "title": "DMCD : cadre sémantique-statistique pour la découverte causale",
        "summary": "DMCD combine le raisonnement sémantique des modèles de langage de grande taille avec la validation statistique pour découvrir les relations causales dans les données, en utilisant l'IA pour proposer des structures causales initiales qui sont ensuite affinées par des tests statistiques. L'approche a obtenu des performances compétitives sur des ensembles de données réelles couvrant les domaines industriel et environnemental, démontrant la valeur de la combinaison de priors sémantiques avec la vérification statistique."
      },
      "de": {
        "title": "DMCD: Semantisch-statistisches Rahmenwerk zur Ursachenentdeckung",
        "summary": "DMCD kombiniert semantisches Reasoning großer Sprachmodelle mit statistischer Validierung, um kausale Beziehungen in Daten zu entdecken. Es nutzt KI, um anfängliche kausale Strukturen vorzuschlagen, die dann durch statistisches Testen verfeinert werden. Der Ansatz erzielte wettbewerbsfähige Leistungen auf echten Datensätzen in industriellen und Umweltbereichen und demonstriert den Wert der Kombination semantischer Vorwissen mit statistischer Verifikation."
      },
      "es": {
        "title": "DMCD: Marco semántico-estadístico para el descubrimiento causal",
        "summary": "DMCD combina el razonamiento semántico de modelos de lenguaje grande con validación estadística para descubrir relaciones causales en datos, utilizando IA para proponer estructuras causales iniciales que luego se refinan mediante pruebas estadísticas. El enfoque logró un desempeño competitivo en conjuntos de datos del mundo real que abarcan dominios industriales y ambientales, demostrando el valor de combinar priors semánticos con verificación estadística."
      }
    }
  },
  {
    "title": "Diffusion Modulation via Environment Mechanism Modeling for Planning",
    "slug": "diffusion-modulation-environment-planning",
    "url": "https://arxiv.org/abs/2602.20422",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Researchers propose DMEMM, a novel method for offline reinforcement learning that improves diffusion-based planning by incorporating environment mechanics like transition dynamics and reward functions. The approach achieves state-of-the-art performance by ensuring consistency between generated trajectories and real-world environment behavior.",
    "content": "arXiv:2602.20422v1 Announce Type: new \nAbstract: Diffusion models have shown promising capabilities in trajectory generation for planning in offline reinforcement learning (RL). However, conventional diffusion-based planning methods often fail to account for the fact that generating trajectories in RL requires unique consistency between transitions to ensure coherence in real environments. This oversight can result in considerable discrepancies between the generated trajectories and the underlying mechanisms of a real environment. To address this problem, we propose a novel diffusion-based planning method, termed as Diffusion Modulation via Environment Mechanism Modeling (DMEMM). DMEMM modulates diffusion model training by incorporating key RL environment mechanisms, particularly transition dynamics and reward functions. Experimental results demonstrate that DMEMM achieves state-of-the-art performance for planning with offline reinforcement learning.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "通过环境机制建模的扩散调节用于规划",
        "summary": "研究人员提出DMEMM，一种新颖的离线强化学习方法，通过融合转移动力学和奖励函数等环境力学来改进扩散规划。该方法通过确保生成的轨迹与真实环境行为的一致性来达到最先进的性能。"
      },
      "ja": {
        "title": "環境メカニズムモデリングによる拡散変調計画",
        "summary": "研究者らがDMEMMを提案し、遷移ダイナミクスと報酬関数などの環境メカニズムを組み込むことで拡散ベースの計画を改善する、オフライン強化学習の新しい方法。生成された軌跡と実環境の動作の一貫性を確保することで、最先端のパフォーマンスを達成。"
      },
      "ko": {
        "title": "환경 메커니즘 모델링을 통한 확산 조절 계획",
        "summary": "연구자들이 전환 역학 및 보상 함수와 같은 환경 메커니즘을 통합하여 확산 기반 계획을 개선하는 오프라인 강화학습의 새로운 방법 DMEMM을 제안합니다. 생성된 궤적과 실제 환경 행동 간의 일관성을 보장하여 최첨단 성능을 달성합니다."
      },
      "fr": {
        "title": "Modulation de diffusion via modélisation des mécanismes environnementaux pour la planification",
        "summary": "Les chercheurs proposent DMEMM, une nouvelle méthode d'apprentissage par renforcement hors ligne qui améliore la planification basée sur la diffusion en intégrant la mécanique de l'environnement comme la dynamique de transition et les fonctions de récompense. L'approche atteint des performances de pointe en assurant la cohérence entre les trajectoires générées et le comportement de l'environnement réel."
      },
      "de": {
        "title": "Diffusionsmodulation durch Umweltmechanismus-Modellierung für Planung",
        "summary": "Forscher schlagen DMEMM vor, eine neuartige Methode des Offline-Reinforcement-Learning, die die diffusionsbasierte Planung durch Einbeziehung von Umweltmechaniken wie Übergangsdynamiken und Belohnungsfunktionen verbessert. Der Ansatz erreicht hochmoderne Leistung durch Gewährleistung der Konsistenz zwischen generierten Trajektorien und realem Umweltverhalten."
      },
      "es": {
        "title": "Modulación de difusión mediante modelado de mecanismos ambientales para la planificación",
        "summary": "Los investigadores proponen DMEMM, un nuevo método de aprendizaje por refuerzo fuera de línea que mejora la planificación basada en difusión incorporando mecánicas del ambiente como dinámicas de transición y funciones de recompensa. El enfoque logra rendimiento de vanguardia al garantizar la consistencia entre las trayectorias generadas y el comportamiento real del ambiente."
      }
    }
  },
  {
    "title": "Implicit Intelligence -- Evaluating Agents on What Users Don't Say",
    "slug": "implicit-intelligence-agent-evaluation",
    "url": "https://arxiv.org/abs/2602.20424",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "A new evaluation framework tests whether AI agents can reason about implicit requirements beyond literal instruction-following, such as accessibility needs, privacy concerns, and contextual constraints. Testing 16 frontier models revealed the best performance achieved only 48.3% scenario pass rate, indicating substantial gaps in agents' contextual reasoning abilities.",
    "content": "arXiv:2602.20424v1 Announce Type: new \nAbstract: Real-world requests to AI agents are fundamentally underspecified. Natural human communication relies on shared context and unstated constraints that speakers expect listeners to infer. Current agentic benchmarks test explicit instruction-following but fail to evaluate whether agents can reason about implicit requirements spanning accessibility needs, privacy boundaries, catastrophic risks, and contextual constraints. We present Implicit Intelligence, an evaluation framework testing whether AI agents can move beyond prompt-following to become genuine goal-fulfillers, paired with Agent-as-a-World (AaW), a harness where interactive worlds are defined in human-readable YAML files and simulated by language models. Our scenarios feature apparent simplicity in user requests, hidden complexity in correct solutions, and discoverability of constraints through environmental exploration. Evaluating 16 frontier and open-weight models across 205 scenarios, we find that even the best-performing model achieves only 48.3% scenario pass rate, revealing substantial room for improvement in bridging the gap between literal instruction-following and human-like contextual reasoning.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "隐性智能——评估代理对用户未说明内容的理解",
        "summary": "一个新的评估框架测试AI代理是否能够推理超越字面指令的隐性需求，例如无障碍需求、隐私问题和上下文约束。对16个前沿模型的测试显示最佳性能仅达到48.3%的场景通过率，表明代理在上下文推理能力上存在实质性差距。"
      },
      "ja": {
        "title": "暗黙的インテリジェンス——ユーザーが言わないことに関するエージェント評価",
        "summary": "新しい評価フレームワークは、アクセシビリティの必要性、プライバシーの懸念、文脈的制約など、字面的な指示に従うことを超えた暗黙的要件について推論できるかどうかをテストします。16の最先端モデルのテストでは、最高のパフォーマンスは48.3%のシナリオパスレートにすぎず、エージェントの文脈推理能力に実質的なギャップがあることを示しています。"
      },
      "ko": {
        "title": "암묵적 지능 -- 사용자가 말하지 않은 것에 대한 에이전트 평가",
        "summary": "새로운 평가 프레임워크는 접근성 필요, 개인정보 보호 우려, 상황 제약 등 문자 그대로의 지시 따르기를 넘어 암묵적 요구 사항을 추론할 수 있는지 테스트합니다. 16개의 최첨단 모델 테스트 결과 최고 성능은 48.3% 시나리오 통과율만 달성했으며, 에이전트의 상황 추론 능력에 실질적인 차이가 있음을 나타냅니다."
      },
      "fr": {
        "title": "Intelligence implicite -- Évaluation des agents sur ce que les utilisateurs ne disent pas",
        "summary": "Un nouveau cadre d'évaluation teste si les agents d'IA peuvent raisonner sur les exigences implicites au-delà du suivi littéral des instructions, telles que les besoins d'accessibilité, les préoccupations relatives à la confidentialité et les contraintes contextuelles. Les tests sur 16 modèles de pointe ont révélé que la meilleure performance ne réalisait que 48,3% de taux de réussite de scénario, indiquant des lacunes substantielles dans les capacités de raisonnement contextuel des agents."
      },
      "de": {
        "title": "Implizite Intelligenz -- Bewertung von Agenten anhand dessen, was Benutzer nicht sagen",
        "summary": "Ein neues Bewertungsrahmenwerk testet, ob KI-Agenten über explizite Anforderungen hinaus implizite Anforderungen wie Zugänglichkeitsbedarf, Datenschutzbedenken und kontextuelle Beschränkungen berücksichtigen können. Tests an 16 Frontier-Modellen zeigten, dass die beste Leistung nur 48,3% Szenario-Erfolgsquote erreichte, was auf erhebliche Lücken in den Kontextverständigungsfähigkeiten der Agenten hindeutet."
      },
      "es": {
        "title": "Inteligencia implícita -- Evaluación de agentes sobre lo que los usuarios no dicen",
        "summary": "Un nuevo marco de evaluación prueba si los agentes de IA pueden razonar sobre requisitos implícitos más allá del seguimiento literal de instrucciones, como necesidades de accesibilidad, preocupaciones de privacidad y restricciones contextuales. Las pruebas en 16 modelos fronterizos revelaron que el mejor desempeño logró solo una tasa de éxito de escenario del 48.3%, indicando brechas sustanciales en las capacidades de razonamiento contextual de los agentes."
      }
    }
  },
  {
    "title": "Learning to Rewrite Tool Descriptions for Reliable LLM-Agent Tool Use",
    "slug": "tool-description-optimization-llm-agents",
    "url": "https://arxiv.org/abs/2602.20426",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Trace-Free+ is a curriculum learning framework that optimizes tool interface descriptions to improve how language models select and use tools without requiring execution traces. Experiments showed up to 93% improvement in recommendation accuracy when agents use learned tool descriptions rather than template-based ones, with strong generalization to unseen tools.",
    "content": "arXiv:2602.20426v1 Announce Type: new \nAbstract: The performance of LLM-based agents depends not only on the agent itself but also on the quality of the tool interfaces it consumes. While prior work has focused heavily on agent fine-tuning, tool interfaces-including natural language descriptions and parameter schemas-remain largely human-oriented and often become a bottleneck, especially when agents must select from large candidate tool sets. Existing approaches to improving tool interfaces rely on execution traces, which are frequently unavailable in cold-start or privacy-constrained settings, and typically optimize each tool independently, limiting scalability and generalization to unseen tools. We propose Trace-Free+, a curriculum learning framework that progressively transfers supervision from trace-rich settings to trace-free deployment, encouraging the model to abstract reusable interface-usage patterns and tool usage outcomes. To support this approach, we construct a large-scale dataset of high-quality tool interfaces using a structured workflow over a diverse collection of tools. Experiments on StableToolBench and RestBench show consistent gains on unseen tools, strong cross-domain generalization, and robustness as the number of candidate tools scales to over 100, demonstrating that tool interface optimization is a practical and deployable complement to agent fine-tuning.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "学习重写工具描述以实现可靠的LLM代理工具使用",
        "summary": "Trace-Free+是一个课程学习框架，优化工具界面描述以改进语言模型选择和使用工具的方式，无需执行跟踪。实验显示当代理使用学习的工具描述而不是基于模板的描述时，推荐准确性提高了93%，对未见过的工具具有强的泛化能力。"
      },
      "ja": {
        "title": "信頼できるLLMエージェントツール使用のためのツール説明を書き直すことを学習",
        "summary": "Trace-Free+は、実行トレースを必要とせずに言語モデルがツールを選択して使用する方法を改善するためにツールインターフェース説明を最適化するカリキュラム学習フレームワークです。実験により、エージェントが学習したツール説明を使用する場合、テンプレートベースの説明ではなく、推奨精度が最大93%向上し、未知のツールへの強い一般化が示されました。"
      },
      "ko": {
        "title": "신뢰할 수 있는 LLM 에이전트 도구 사용을 위한 도구 설명 다시 쓰기 학습",
        "summary": "Trace-Free+는 실행 추적 없이 언어 모델이 도구를 선택하고 사용하는 방식을 개선하기 위해 도구 인터페이스 설명을 최적화하는 커리큘럼 학습 프레임워크입니다. 실험 결과 에이전트가 템플릿 기반 설명 대신 학습된 도구 설명을 사용할 때 권장 정확도가 최대 93% 향상되었으며, 보지 못한 도구에 강한 일반화 능력을 보였습니다."
      },
      "fr": {
        "title": "Apprendre à réécrire les descriptions d'outils pour l'utilisation fiable des outils LLM-Agent",
        "summary": "Trace-Free+ est un cadre d'apprentissage par curriculum qui optimise les descriptions d'interfaces d'outils pour améliorer la façon dont les modèles de langage sélectionnent et utilisent les outils sans nécessiter de traces d'exécution. Les expériences ont montré jusqu'à 93% d'amélioration de la précision des recommandations lorsque les agents utilisent des descriptions d'outils apprises plutôt que des descriptions basées sur des modèles, avec une forte généralisation aux outils non vus."
      },
      "de": {
        "title": "Lernen, Werkzeugbeschreibungen für zuverlässige LLM-Agent-Werkzeugnutzung umzuschreiben",
        "summary": "Trace-Free+ ist ein Curriculum-Learning-Framework, das Werkzeugschnittstellenbeschreibungen optimiert, um zu verbessern, wie Sprachmodelle Werkzeuge ohne Ausführungsverfolgung auswählen und verwenden. Experimente zeigten bis zu 93% Verbesserung der Empfehlungsgenauigkeit, wenn Agenten gelernte Werkzeugbeschreibungen verwenden, statt vorlagenbasierte, mit starker Verallgemeinerung auf unbekannte Werkzeuge."
      },
      "es": {
        "title": "Aprender a reescribir descripciones de herramientas para un uso confiable de herramientas LLM-Agent",
        "summary": "Trace-Free+ es un marco de aprendizaje por currículum que optimiza descripciones de interfaces de herramientas para mejorar cómo los modelos de lenguaje seleccionan y usan herramientas sin requerir trazas de ejecución. Los experimentos mostraron hasta 93% de mejora en la precisión de recomendaciones cuando los agentes usan descripciones de herramientas aprendidas en lugar de basadas en plantillas, con fuerte generalización a herramientas no vistas."
      }
    }
  },
  {
    "title": "PreScience: A Benchmark for Forecasting Scientific Contributions",
    "slug": "prescience-scientific-contribution-forecasting",
    "url": "https://arxiv.org/abs/2602.20459",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "PreScience is a benchmark dataset of 98K AI research papers designed to test whether AI can forecast scientific advances by predicting collaborators, relevant prior work, research contributions, and impact. The benchmark reveals substantial headroom in forecasting capabilities, with state-of-the-art language models achieving only moderate performance in predicting research contributions.",
    "content": "arXiv:2602.20459v1 Announce Type: new \nAbstract: Can AI systems trained on the scientific record up to a fixed point in time forecast the scientific advances that follow? Such a capability could help researchers identify collaborators and impactful research directions, and anticipate which problems and methods will become central next. We introduce PreScience -- a scientific forecasting benchmark that decomposes the research process into four interdependent generative tasks: collaborator prediction, prior work selection, contribution generation, and impact prediction. PreScience is a carefully curated dataset of 98K recent AI-related research papers, featuring disambiguated author identities, temporally aligned scholarly metadata, and a structured graph of companion author publication histories and citations spanning 502K total papers. We develop baselines and evaluations for each task, including LACERScore, a novel LLM-based measure of contribution similarity that outperforms previous metrics and approximates inter-annotator agreement. We find substantial headroom remains in each task -- e.g. in contribution generation, frontier LLMs achieve only moderate similarity to the ground-truth (GPT-5, averages 5.6 on a 1-10 scale). When composed into a 12-month end-to-end simulation of scientific production, the resulting synthetic corpus is systematically less diverse and less novel than human-authored research from the same period.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "预科学：科学贡献预测基准",
        "summary": "PreScience是一个包含98K篇AI研究论文的基准数据集，用于测试AI是否能通过预测合作者、相关先前工作、研究贡献和影响来预测科学进步。该基准揭示了预测能力中存在大量空间，最先进的语言模型在预测研究贡献方面只能取得中等水平的性能。"
      },
      "ja": {
        "title": "PreScience：科学的貢献予測ベンチマーク",
        "summary": "PreScience は 98K 個の AI 研究論文から構成されたベンチマークデータセットで、AI が共同研究者、関連する先行研究、研究貢献、および影響を予測することで科学的進歩を予測できるかをテストするために設計されています。このベンチマークは予測能力に大きな余地があることを明らかにし、最先端の言語モデルは研究貢献の予測においてのみ中程度のパフォーマンスを達成しています。"
      },
      "ko": {
        "title": "PreScience: 과학적 기여 예측 벤치마크",
        "summary": "PreScience는 98K개의 AI 연구 논문으로 구성된 벤치마크 데이터세트이며, AI가 협력자, 관련 선행 연구, 연구 기여도, 그리고 영향을 예측하여 과학적 진전을 예측할 수 있는지 테스트하도록 설계되었습니다. 이 벤치마크는 예측 능력에 상당한 여지가 있음을 보여주며, 최첨단 언어 모델은 연구 기여도 예측에서만 중간 정도의 성능을 달성합니다."
      },
      "fr": {
        "title": "PreScience: Un référentiel pour prédire les contributions scientifiques",
        "summary": "PreScience est un ensemble de données de référence contenant 98K articles de recherche en IA conçu pour tester si l'IA peut prévoir les avancées scientifiques en prédisant les collaborateurs, les travaux antérieurs pertinents, les contributions de recherche et l'impact. Le référentiel révèle un potentiel considérable dans les capacités de prévision, les modèles de langage de pointe n'atteignant que des performances modérées dans la prédiction des contributions de recherche."
      },
      "de": {
        "title": "PreScience: Ein Benchmarking-Datensatz zur Vorhersage wissenschaftlicher Beiträge",
        "summary": "PreScience ist ein Benchmark-Datensatz aus 98K KI-Forschungspapieren, der entwickelt wurde, um zu testen, ob KI wissenschaftliche Fortschritte durch die Vorhersage von Mitarbeitern, relevanten Vorgängern, Forschungsbeiträgen und deren Auswirkungen vorhersagen kann. Der Benchmark zeigt erhebliches Potenzial in den Prognosefähigkeiten, wobei hochmoderne Sprachmodelle nur moderate Leistungen bei der Vorhersage von Forschungsbeiträgen erreichen."
      },
      "es": {
        "title": "PreScience: Un Benchmark para Pronosticar Contribuciones Científicas",
        "summary": "PreScience es un conjunto de datos de referencia de 98K artículos de investigación en IA diseñado para probar si la IA puede pronosticar avances científicos prediciendo colaboradores, trabajos previos relevantes, contribuciones de investigación e impacto. El benchmark revela un considerable margen en las capacidades de pronóstico, con los modelos de lenguaje de última generación alcanzando solo un desempeño moderado en la predicción de contribuciones de investigación."
      }
    }
  },
  {
    "title": "KairosVL: Orchestrating Time Series and Semantics for Unified Reasoning",
    "slug": "kairosvl-time-series-semantic-reasoning",
    "url": "https://arxiv.org/abs/2602.20494",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "KairosVL extends time series analysis by incorporating semantic understanding and contextual reasoning alongside numerical modeling, using a two-round reinforcement learning approach to improve temporal reasoning. The model demonstrates competitive performance on complex time series tasks while improving generalization to unseen scenarios.",
    "content": "arXiv:2602.20494v1 Announce Type: new \nAbstract: Driven by the increasingly complex and decision-oriented demands of time series analysis, we introduce the Semantic-Conditional Time Series Reasoning task, which extends conventional time series analysis beyond purely numerical modeling to incorporate contextual and semantic understanding. To further enhance the mode's reasoning capabilities on complex time series problems, we propose a two-round reinforcement learning framework: the first round strengthens the mode's perception of fundamental temporal primitives, while the second focuses on semantic-conditioned reasoning. The resulting model, KairosVL, achieves competitive performance across both synthetic and real-world tasks. Extensive experiments and ablation studies demonstrate that our framework not only boosts performance but also preserves intrinsic reasoning ability and significantly improves generalization to unseen scenarios. To summarize, our work highlights the potential of combining semantic reasoning with temporal modeling and provides a practical framework for real-world time series intelligence, which is in urgent demand.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "KairosVL：编排时间序列和语义实现统一推理",
        "summary": "KairosVL通过在数值建模的基础上融合语义理解和上下文推理来扩展时间序列分析，使用两轮强化学习方法改进时间推理。该模型在复杂时间序列任务上展现了具有竞争力的性能，同时改进了对未见情景的泛化能力。"
      },
      "ja": {
        "title": "KairosVL：時系列とセマンティクスの統合推論のための調整",
        "summary": "KairosVL は、セマンティック理解と文脈推論を数値モデリングと統合することにより時系列分析を拡張し、2ラウンドの強化学習アプローチを使用して時間推論を改善します。このモデルは複雑な時系列タスクで競争力のあるパフォーマンスを示し、未見のシナリオへの汎化を向上させます。"
      },
      "ko": {
        "title": "KairosVL: 시계열과 의미론을 위한 통합 추론 조정",
        "summary": "KairosVL은 수치 모델링과 함께 의미론적 이해와 맥락적 추론을 통합하여 시계열 분석을 확장하며, 2라운드 강화학습 접근법을 사용하여 시간적 추론을 개선합니다. 이 모델은 복잡한 시계열 작업에서 경쟁력 있는 성능을 보이면서 보지 못한 시나리오에 대한 일반화를 개선합니다."
      },
      "fr": {
        "title": "KairosVL: Orchestrer les séries temporelles et la sémantique pour un raisonnement unifié",
        "summary": "KairosVL étend l'analyse des séries temporelles en intégrant la compréhension sémantique et le raisonnement contextuel aux côtés de la modélisation numérique, en utilisant une approche d'apprentissage par renforcement en deux étapes pour améliorer le raisonnement temporel. Le modèle démontre des performances compétitives sur les tâches complexes de séries temporelles tout en améliorant la généralisation aux scénarios non vus."
      },
      "de": {
        "title": "KairosVL: Orchestrierung von Zeitreihen und Semantik für einheitliches Denken",
        "summary": "KairosVL erweitert die Zeitreihenanalyse durch die Integration von semantischem Verständnis und kontextuellem Denken neben numerischer Modellierung und verwendet einen zweistufigen Verstärkungslernansatz zur Verbesserung des zeitlichen Denkens. Das Modell demonstriert wettbewerbsfähige Leistung bei komplexen Zeitreihenaufgaben und verbessert gleichzeitig die Verallgemeinerung auf ungesehene Szenarien."
      },
      "es": {
        "title": "KairosVL: Orquestación de series temporales y semántica para razonamiento unificado",
        "summary": "KairosVL extiende el análisis de series temporales incorporando comprensión semántica y razonamiento contextual junto con modelado numérico, utilizando un enfoque de aprendizaje por refuerzo de dos rondas para mejorar el razonamiento temporal. El modelo demuestra un desempeño competitivo en tareas complejas de series temporales mientras mejora la generalización a escenarios no vistos."
      }
    }
  },
  {
    "title": "ActionEngine: From Reactive to Programmatic GUI Agents via State Machine Memory",
    "slug": "actionengine-gui-agents-state-machine",
    "url": "https://arxiv.org/abs/2602.20502",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "ActionEngine transitions GUI agents from reactive step-by-step operation to programmatic planning by using one agent to map interface state machines and another to generate executable code for tasks. The approach achieved 95% task success on Reddit tasks with a single LLM call, reducing costs by 11.8x compared to vision-only baselines.",
    "content": "arXiv:2602.20502v1 Announce Type: new \nAbstract: Existing Graphical User Interface (GUI) agents operate through step-by-step calls to vision language models--taking a screenshot, reasoning about the next action, executing it, then repeating on the new page--resulting in high costs and latency that scale with the number of reasoning steps, and limited accuracy due to no persistent memory of previously visited pages.\n  We propose ActionEngine, a training-free framework that transitions from reactive execution to programmatic planning through a novel two-agent architecture: a Crawling Agent that constructs an updatable state-machine memory of the GUIs through offline exploration, and an Execution Agent that leverages this memory to synthesize complete, executable Python programs for online task execution.\n  To ensure robustness against evolving interfaces, execution failures trigger a vision-based re-grounding fallback that repairs the failed action and updates the memory.\n  This design drastically improves both efficiency and accuracy: on Reddit tasks from the WebArena benchmark, our agent achieves 95% task success with on average a single LLM call, compared to 66% for the strongest vision-only baseline, while reducing cost by 11.8x and end-to-end latency by 2x.\n  Together, these components yield scalable and reliable GUI interaction by combining global programmatic planning, crawler-validated action templates, and node-level execution with localized validation and repair.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ActionEngine：通过状态机内存从响应式转向编程式GUI代理",
        "summary": "ActionEngine通过使用一个代理映射界面状态机，另一个代理生成可执行代码来处理任务，将GUI代理从响应式逐步操作转向编程式规划。该方法在Reddit任务上实现了95%的任务成功率，通过单次LLM调用，相比仅基于视觉的基线降低成本11.8倍。"
      },
      "ja": {
        "title": "ActionEngine：状態機械メモリを介したリアクティブからプログラム的GUI エージェントへの転換",
        "summary": "ActionEngine は、1 つのエージェントがインターフェース状態機械をマップし、別のエージェントがタスク用の実行可能コードを生成することにより、GUI エージェントをリアクティブなステップバイステップ操作からプログラム的計画へと移行させます。このアプローチは Reddit タスクで 95% のタスク成功率を達成し、単一の LLM 呼び出しで、ビジョン専用ベースラインと比較してコストを 11.8 倍削減します。"
      },
      "ko": {
        "title": "ActionEngine: 상태 머신 메모리를 통한 반응형에서 프로그래밍 방식 GUI 에이전트로의 전환",
        "summary": "ActionEngine은 하나의 에이전트가 인터페이스 상태 머신을 매핑하고 다른 에이전트가 작업을 위한 실행 가능한 코드를 생성하여 GUI 에이전트를 반응형 단계별 작업에서 프로그래밍 방식 계획으로 전환합니다. 이 접근법은 Reddit 작업에서 95% 작업 성공률을 달성하며 단일 LLM 호출로 비전 전용 기준선에 비해 비용을 11.8배 절감합니다."
      },
      "fr": {
        "title": "ActionEngine: De la réaction à la programmation des agents GUI via la mémoire des machines d'état",
        "summary": "ActionEngine fait la transition des agents GUI d'une opération réactive étape par étape à une planification programmatique en utilisant un agent pour mapper les machines d'état de l'interface et un autre pour générer du code exécutable pour les tâches. L'approche a atteint un taux de succès de 95% sur les tâches Reddit avec un seul appel LLM, réduisant les coûts de 11,8x par rapport aux lignes de base basées sur la vision uniquement."
      },
      "de": {
        "title": "ActionEngine: Von reaktiven zu programmatischen GUI-Agenten über Zustandsmaschinengedächtnis",
        "summary": "ActionEngine übernimmt GUI-Agenten von reaktiven schrittweisen Operationen zu programmatischer Planung, indem ein Agent Schnittstellenzustandsmaschinen abbildet und ein anderer ausführbaren Code für Aufgaben generiert. Der Ansatz erreichte eine Aufgabenerfolgsquote von 95% bei Reddit-Aufgaben mit einem einzigen LLM-Aufruf und reduzierte die Kosten um das 11,8-fache im Vergleich zu reinen Vision-basierten Baselines."
      },
      "es": {
        "title": "ActionEngine: De agentes GUI reactivos a programáticos a través de la memoria de máquinas de estado",
        "summary": "ActionEngine transiciona los agentes GUI de operación reactiva paso a paso a planificación programática utilizando un agente para mapear máquinas de estado de interfaz y otro para generar código ejecutable para tareas. El enfoque logró una tasa de éxito del 95% en tareas de Reddit con una única llamada LLM, reduciendo costos 11.8x en comparación con líneas base solo de visión."
      }
    }
  },
  {
    "title": "Inner Speech as Behavior Guides: Steerable Imitation of Diverse Behaviors for Human-AI coordination",
    "slug": "inner-speech-behavior-guides-imitation",
    "url": "https://arxiv.org/abs/2602.20517",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "MIMIC is an imitation learning framework that uses natural language \"inner speech\" as an intermediate representation to enable AI agents to learn diverse human behaviors while allowing fine-grained control at inference time. The approach enhances behavior diversity and fidelity across robotic and human-AI collaboration tasks without requiring additional training data.",
    "content": "arXiv:2602.20517v1 Announce Type: new \nAbstract: Effective human-AI coordination requires artificial agents capable of exhibiting and responding to human-like behaviors while adapting to changing contexts. Imitation learning has emerged as one of the prominent approaches to build such agents by training them to mimic human-demonstrated behaviors. However, current methods struggle to capture the inherent diversity and non-Markovian nature of human behavior and lack the ability to steer behavior at inference time. Drawing inspiration from the theory of human cognitive processes, where inner speech guides action selection before execution, we propose MIMIC (Modeling Inner Motivations for Imitation and Control), a framework that uses language as an internal representation of behavioral intent. MIMIC employs the novel use of vision-language models as linguistic scaffolding to train a conditional variational autoencoder capable of generating inner speech from observations. A diffusion-based behavior cloning policy then selects actions conditioned on current observations and the generated inner speech. MIMIC enables fine-grained steering of behavior at inference time by conditioning the agent on behavior-specific speech. Experiments across robotic manipulation tasks and human-AI collaboration games demonstrate that MIMIC significantly enhances both behavior diversity and fidelity to human demonstrations while enabling nuanced behavioral steering without training on additional demonstrations. We open source our code and provide pre-trained MIMIC agents and qualitative demos at: https://mimic-research.github.io.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "内心语言作为行为指南:人类与AI协调的可控多样行为模仿",
        "summary": "MIMIC是一个模仿学习框架,使用自然语言\"内心语言\"作为中间表示,使AI代理能够学习多样的人类行为,同时在推理时允许细粒度控制。该方法在机器人和人类与AI协作任务中增强了行为多样性和保真度,无需额外的训练数据。"
      },
      "ja": {
        "title": "内心の音声を行動ガイドとして:人間-AI協調のための多様な行動の操作可能な模倣",
        "summary": "MIMICは、自然言語の\"内心の音声\"を中間表現として使用する模倣学習フレームワークです。AIエージェントが多様な人間の行動を学習できるようになり、推論時に細粒度の制御が可能になります。このアプローチは、ロボットと人間-AI協調タスク全体で行動の多様性と忠実度を向上させ、追加の訓練データを必要としません。"
      },
      "ko": {
        "title": "행동 가이드로서의 내적 음성: 인간-AI 협조를 위한 다양한 행동의 조종 가능한 모방",
        "summary": "MIMIC은 자연언어의 \"내적 음성\"을 중간 표현으로 사용하는 모방 학습 프레임워크입니다. AI 에이전트가 다양한 인간의 행동을 학습할 수 있게 해주며, 추론 시간에 세밀한 제어를 가능하게 합니다. 이 접근 방식은 로봇과 인간-AI 협력 작업 전반에 걸쳐 행동 다양성과 충실도를 향상시키며, 추가 학습 데이터가 필요하지 않습니다."
      },
      "fr": {
        "title": "Le langage intérieur comme guides de comportement: imitation contrôlable de comportements diversifiés pour la coordination humain-IA",
        "summary": "MIMIC est un cadre d'apprentissage par imitation qui utilise le \"langage intérieur\" en langage naturel comme représentation intermédiaire, permettant aux agents IA d'apprendre des comportements humains diversifiés tout en permettant un contrôle fin-grained au moment de l'inférence. L'approche améliore la diversité des comportements et la fidélité dans les tâches de collaboration robotique et humain-IA sans nécessiter de données d'entraînement supplémentaires."
      },
      "de": {
        "title": "Innere Sprache als Verhaltensleiter: Steuerbare Nachahmung vielfältiger Verhaltensweisen für Mensch-KI-Koordination",
        "summary": "MIMIC ist ein Imitationslernen-Framework, das natürliche Sprache \"innere Sprache\" als Zwischendarstellung verwendet, um KI-Agenten zu befähigen, vielfältige menschliche Verhaltensweisen zu erlernen, während gleichzeitig eine fein abgestimmte Kontrolle zur Inferenzzeit ermöglicht wird. Der Ansatz verbessert die Verhaltensvielfalt und -treue in Robotik- und Mensch-KI-Zusammenarbeitsaufgaben ohne zusätzliche Trainingsdaten."
      },
      "es": {
        "title": "El lenguaje interno como guías de comportamiento: imitación controlable de comportamientos diversos para la coordinación humano-IA",
        "summary": "MIMIC es un marco de aprendizaje por imitación que utiliza el \"lenguaje interno\" en lenguaje natural como representación intermedia, permitiendo que los agentes de IA aprendan comportamientos humanos diversos mientras permiten un control fino en el momento de la inferencia. El enfoque mejora la diversidad de comportamiento y la fidelidad en tareas de colaboración robótica y humano-IA sin requerir datos de entrenamiento adicionales."
      }
    }
  },
  {
    "title": "From Logs to Language: Learning Optimal Verbalization for LLM-Based Recommendation in Production",
    "slug": "logs-to-language-llm-recommendation",
    "url": "https://arxiv.org/abs/2602.20558",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "A reinforcement learning approach learns to optimally convert user interaction logs into natural language contexts for language model-based recommendation systems, achieving up to 93% improvement in recommendation accuracy. The learned verbalization strategies discovered interpretable patterns like user interest summarization and noise removal that improve downstream predictions.",
    "content": "arXiv:2602.20558v1 Announce Type: new \nAbstract: Large language models (LLMs) are promising backbones for generative recommender systems, yet a key challenge remains underexplored: verbalization, i.e., converting structured user interaction logs into effective natural language inputs. Existing methods rely on rigid templates that simply concatenate fields, yielding suboptimal representations for recommendation. We propose a data-centric framework that learns verbalization for LLM-based recommendation. Using reinforcement learning, a verbalization agent transforms raw interaction histories into optimized textual contexts, with recommendation accuracy as the training signal. This agent learns to filter noise, incorporate relevant metadata, and reorganize information to improve downstream predictions. Experiments on a large-scale industrial streaming dataset show that learned verbalization delivers up to 93% relative improvement in discovery item recommendation accuracy over template-based baselines. Further analysis reveals emergent strategies such as user interest summarization, noise removal, and syntax normalization, offering insights into effective context construction for LLM-based recommender systems.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "从日志到语言:为生产中基于LLM的推荐学习最优表述",
        "summary": "强化学习方法学会将用户交互日志最优转换为自然语言上下文,用于基于语言模型的推荐系统,推荐准确率提高了93%。学习的表述策略发现了可解释的模式,如用户兴趣总结和噪声删除,改进了下游预测。"
      },
      "ja": {
        "title": "ログから言語へ:本番環境のLLMベースの推奨システムのための最適な言語化学習",
        "summary": "強化学習アプローチは、ユーザーインタラクションログを言語モデルベースの推奨システムの自然言語コンテキストに最適に変換することを学習し、推奨精度で最大93%の改善を実現します。学習された言語化戦略は、ユーザーの関心の要約とノイズ除去などの解釈可能なパターンを発見し、ダウンストリーム予測を改善します。"
      },
      "ko": {
        "title": "로그에서 언어로: 프로덕션에서 LLM 기반 추천을 위한 최적의 언어화 학습",
        "summary": "강화학습 접근 방식은 사용자 상호작용 로그를 언어 모델 기반 추천 시스템의 자연언어 컨텍스트로 최적으로 변환하는 방법을 학습하여, 추천 정확도를 최대 93% 개선합니다. 학습된 언어화 전략은 사용자 관심 요약 및 노이즈 제거와 같은 해석 가능한 패턴을 발견하여 다운스트림 예측을 개선합니다."
      },
      "fr": {
        "title": "Des journaux au langage: apprentissage de la verbalisation optimale pour les systèmes de recommandation basés sur LLM en production",
        "summary": "Une approche par apprentissage par renforcement apprend à convertir de manière optimale les journaux d'interaction utilisateur en contextes en langage naturel pour les systèmes de recommandation basés sur des modèles de langage, réalisant jusqu'à 93% d'amélioration de la précision des recommandations. Les stratégies de verbalisation apprises découvrent des modèles interprétables comme la synthèse des intérêts utilisateurs et la suppression du bruit qui améliorent les prédictions en aval."
      },
      "de": {
        "title": "Von Protokollen zur Sprache: Erlernung optimaler Verbalisierung für LLM-basierte Empfehlung in der Produktion",
        "summary": "Ein Verstärkungslernansatz lernt, Benutzerinteraktionsprotokolle optimal in natürliche Sprachkontexte für sprachmodellgestützte Empfehlungssysteme zu konvertieren und erreicht eine bis zu 93%ige Verbesserung der Empfehlungsgenauigkeit. Die erlernten Verbalisierungsstrategien entdeckten interpretierbare Muster wie Benutzerinteressenszusammenfassung und Rauschentfernung, die nachgelagerte Vorhersagen verbessern."
      },
      "es": {
        "title": "De registros a lenguaje: aprendiendo verbalización óptima para recomendaciones basadas en LLM en producción",
        "summary": "Un enfoque de aprendizaje por refuerzo aprende a convertir óptimamente los registros de interacción del usuario en contextos de lenguaje natural para sistemas de recomendación basados en modelos de lenguaje, logrando una mejora de hasta el 93% en la precisión de las recomendaciones. Las estrategias de verbalización aprendidas descubrieron patrones interpretables como la síntesis de intereses del usuario y la eliminación de ruido que mejoran las predicciones posteriores."
      }
    }
  },
  {
    "title": "CausalReasoningBenchmark: A Real-World Benchmark for Disentangled Evaluation of Causal Identification and Estimation",
    "slug": "causal-reasoning-benchmark-identification",
    "url": "https://arxiv.org/abs/2602.20571",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "CausalReasoningBenchmark evaluates automated causal inference systems by separately scoring causal identification (research design formulation) and estimation (numerical implementation) across 173 real-world queries. The benchmark revealed that while state-of-the-art language models correctly identify strategies 84% of the time, full identification-specification correctness drops to only 30%.",
    "content": "arXiv:2602.20571v1 Announce Type: new \nAbstract: Many benchmarks for automated causal inference evaluate a system's performance based on a single numerical output, such as an Average Treatment Effect (ATE). This approach conflates two distinct steps in causal analysis: identification-formulating a valid research design under stated assumptions-and estimation-implementing that design numerically on finite data. We introduce CausalReasoningBenchmark, a benchmark of 173 queries across 138 real-world datasets, curated from 85 peer-reviewed research papers and four widely-used causal-inference textbooks. For each query a system must produce (i) a structured identification specification that names the strategy, the treatment, outcome, and control variables, and all design-specific elements, and (ii) a point estimate with a standard error. By scoring these two components separately, our benchmark enables granular diagnosis: it distinguishes failures in causal reasoning from errors in numerical execution. Baseline results with a state-of-the-art LLM show that, while the model correctly identifies the high-level strategy in 84 % of cases, full identification-specification correctness drops to only 30 %, revealing that the bottleneck lies in the nuanced details of research design rather than in computation. CausalReasoningBenchmark is publicly available on Hugging Face and is designed to foster the development of more robust automated causal-inference systems.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "因果推理基准:用于因果识别和估计解耦评估的真实基准",
        "summary": "CausalReasoningBenchmark通过在173个真实查询中分别评分因果识别(研究设计制定)和估计(数值实现)来评估自动因果推理系统。该基准揭示,虽然最先进的语言模型在84%的时间内正确识别策略,但完整识别规范正确性仅为30%。"
      },
      "ja": {
        "title": "因果推理ベンチマーク:因果識別と推定の分離評価のためのリアルワールドベンチマーク",
        "summary": "CausalReasoningBenchmarkは、173の実世界クエリ全体で因果識別(研究設計定式化)と推定(数値実装)を個別にスコアリングすることで、自動因果推論システムを評価します。ベンチマークは、最先端の言語モデルが84%の時間で戦略を正しく識別しますが、完全な識別仕様の正確性はわずか30%に低下することを明らかにしました。"
      },
      "ko": {
        "title": "인과추론벤치마크: 인과식별 및 추정의 분리된 평가를 위한 실제 벤치마크",
        "summary": "CausalReasoningBenchmark는 173개의 실제 쿼리에서 인과 식별(연구 설계 공식화)과 추정(수치 구현)을 별도로 점수 매겨 자동화된 인과 추론 시스템을 평가합니다. 벤치마크는 최첨단 언어 모델이 84%의 시간에 전략을 올바르게 식별하지만, 완전한 식별 명세 정확도는 30%에 불과함을 드러냈습니다."
      },
      "fr": {
        "title": "CausalReasoningBenchmark: Un repère du monde réel pour l'évaluation désenchevêtrée de l'identification et l'estimation causales",
        "summary": "CausalReasoningBenchmark évalue les systèmes d'inférence causale automatisés en notant séparément l'identification causale (formulation de conception de recherche) et l'estimation (implémentation numérique) sur 173 requêtes du monde réel. L'étalon a révélé que bien que les modèles de langage de pointe identifient correctement les stratégies 84% du temps, la correction complète de l'identification-spécification chute à seulement 30%."
      },
      "de": {
        "title": "CausalReasoningBenchmark: Eine reale Benchmark zur entwobenen Bewertung kausaler Identifikation und Schätzung",
        "summary": "CausalReasoningBenchmark bewertet automatisierte Kausalinferenzsysteme, indem es kausale Identifikation (Forschungsdesign-Formulierung) und Schätzung (numerische Implementierung) über 173 reale Abfragen separat bewertet. Die Benchmark zeigte, dass hochmoderne Sprachmodelle in 84% der Zeit Strategien korrekt identifizieren, aber die vollständige Identifikations-Spezifikations-Korrektheit auf nur 30% sinkt."
      },
      "es": {
        "title": "CausalReasoningBenchmark: Un punto de referencia del mundo real para la evaluación desacoplada de identificación y estimación causal",
        "summary": "CausalReasoningBenchmark evalúa sistemas de inferencia causal automatizados puntuando por separado la identificación causal (formulación del diseño de investigación) y la estimación (implementación numérica) en 173 consultas del mundo real. El punto de referencia reveló que aunque los modelos de lenguaje de última generación identifican correctamente estrategias el 84% de las veces, la corrección completa de especificación de identificación cae a solo 30%."
      }
    }
  },
  {
    "title": "Physics-based phenomenological characterization of cross-modal bias in multimodal models",
    "slug": "cross-modal-bias-multimodal-models",
    "url": "https://arxiv.org/abs/2602.20624",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "This position paper argues that multimodal language models can exhibit systematic bias arising from complex cross-modal interactions that existing analysis methods fail to capture. Using physics-based surrogate models to analyze transformer dynamics, the authors demonstrate that multimodal inputs can reinforce modality dominance rather than mitigate it.",
    "content": "arXiv:2602.20624v1 Announce Type: new \nAbstract: The term 'algorithmic fairness' is used to evaluate whether AI models operate fairly in both comparative (where fairness is understood as formal equality, such as \"treat like cases as like\") and non-comparative (where unfairness arises from the model's inaccuracy, arbitrariness, or inscrutability) contexts. Recent advances in multimodal large language models (MLLMs) are breaking new ground in multimodal understanding, reasoning, and generation; however, we argue that inconspicuous distortions arising from complex multimodal interaction dynamics can lead to systematic bias. The purpose of this position paper is twofold: first, it is intended to acquaint AI researchers with phenomenological explainable approaches that rely on the physical entities that the machine experiences during training/inference, as opposed to the traditional cognitivist symbolic account or metaphysical approaches; second, it is to state that this phenomenological doctrine will be practically useful for tackling algorithmic fairness issues in MLLMs. We develop a surrogate physics-based model that describes transformer dynamics (i.e., semantic network structure and self-/cross-attention) to analyze the dynamics of cross-modal bias in MLLM, which are not fully captured by conventional embedding- or representation-level analyses. We support this position through multi-input diagnostic experiments: 1) perturbation-based analyses of emotion classification using Qwen2.5-Omni and Gemma 3n, and 2) dynamical analysis of Lorenz chaotic time-series prediction through the physical surrogate. Across two architecturally distinct MLLMs, we show that multimodal inputs can reinforce modality dominance rather than mitigate it, as revealed by structured error-attractor patterns under systematic label perturbation, complemented by dynamical analysis.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "多模态模型中跨模态偏差的基于物理的现象学表征",
        "summary": "这篇立场文章论证，多模态语言模型可能会因复杂的跨模态相互作用而产生系统性偏差，现有分析方法无法捕捉这一点。利用基于物理的代理模型分析变换器动态，作者证明多模态输入可能强化模态主导地位，而不是减轻它。"
      },
      "ja": {
        "title": "マルチモーダルモデルにおけるクロスモーダルバイアスの物理ベース現象学的特性化",
        "summary": "この立場論文は、マルチモーダル言語モデルが既存の分析方法では捉えられない複雑なクロスモーダル相互作用に由来する体系的なバイアスを示す可能性があると主張している。物理ベースの代理モデルを使用してトランスフォーマーの力学を分析することで、マルチモーダル入力がモダリティの優位性を軽減するのではなく強化する可能性があることを実証している。"
      },
      "ko": {
        "title": "다중모달 모델에서 크로스모달 편향의 물리 기반 현상학적 특성화",
        "summary": "이 입장 논문은 다중모달 언어 모델이 기존 분석 방법으로 포착할 수 없는 복잡한 크로스모달 상호작용에서 비롯된 체계적 편향을 나타낼 수 있음을 주장한다. 물리 기반 대체 모델을 사용하여 변환기 동역학을 분석함으로써 다중모달 입력이 모달리티 우위성을 완화하기보다는 강화할 수 있음을 보여준다."
      },
      "fr": {
        "title": "Caractérisation phénoménologique basée sur la physique du biais cross-modal dans les modèles multimodaux",
        "summary": "Cet article de position soutient que les modèles de langage multimodaux peuvent présenter des biais systématiques résultant d'interactions cross-modales complexes que les méthodes d'analyse existantes ne peuvent pas capturer. En utilisant des modèles de substitution basés sur la physique pour analyser la dynamique des transformateurs, les auteurs démontrent que les entrées multimodales peuvent renforcer la dominance de la modalité plutôt que de l'atténuer."
      },
      "de": {
        "title": "Physikbasierte phänomenologische Charakterisierung von Cross-Modal-Bias in Multimodal-Modellen",
        "summary": "Dieses Positionspapier argumentiert, dass multimodale Sprachmodelle systematische Verzerrungen aufweisen können, die sich aus komplexen Cross-Modal-Interaktionen ergeben, die bestehende Analysemethoden nicht erfassen können. Unter Verwendung physikbasierter Surrogatmodelle zur Analyse der Transformatordynamik zeigen die Autoren, dass multimodale Eingaben die Modalitätsdominanz eher verstärken als abschwächen können."
      },
      "es": {
        "title": "Caracterización fenomenológica basada en la física del sesgo cross-modal en modelos multimodales",
        "summary": "Este documento de posición argumenta que los modelos de lenguaje multimodal pueden presentar sesgos sistemáticos derivados de complejas interacciones cross-modales que los métodos de análisis existentes no pueden capturar. Utilizando modelos sustitutos basados en la física para analizar la dinámica de transformadores, los autores demuestran que las entradas multimodales pueden reforzar la dominancia modal en lugar de mitigarla."
      }
    }
  },
  {
    "title": "When can we trust untrusted monitoring? A safety case sketch across collusion strategies",
    "slug": "untrusted-monitoring-ai-safety",
    "url": "https://arxiv.org/abs/2602.20628",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "This research develops frameworks for rigorously evaluating the safety of using one AI model to monitor another, expanding the taxonomy of potential collusion strategies beyond previous work. The analysis identifies conditions where passive recognition could be an effective collusion strategy and presents explicit assumptions and unsolved challenges.",
    "content": "arXiv:2602.20628v1 Announce Type: new \nAbstract: AIs are increasingly being deployed with greater autonomy and capabilities, which increases the risk that a misaligned AI may be able to cause catastrophic harm. Untrusted monitoring -- using one untrusted model to oversee another -- is one approach to reducing risk. Justifying the safety of an untrusted monitoring deployment is challenging because developers cannot safely deploy a misaligned model to test their protocol directly. In this paper, we develop upon existing methods for rigorously demonstrating safety based on pre-deployment testing. We relax assumptions that previous AI control research made about the collusion strategies a misaligned AI might use to subvert untrusted monitoring. We develop a taxonomy covering passive self-recognition, causal collusion (hiding pre-shared signals), acausal collusion (hiding signals via Schelling points), and combined strategies. We create a safety case sketch to clearly present our argument, explicitly state our assumptions, and highlight unsolved challenges. We identify conditions under which passive self-recognition could be a more effective collusion strategy than those studied previously. Our work builds towards more robust evaluations of untrusted monitoring.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "我们何时可以信任不可信的监控？跨勾结策略的安全案例草图",
        "summary": "本研究开发了框架，用于严格评估使用一个AI模型监控另一个AI模型的安全性，扩展了潜在勾结策略的分类法。分析确定了被动识别可能成为有效勾结策略的条件，并提出了明确的假设和未解决的挑战。"
      },
      "ja": {
        "title": "信頼できない監視をいつ信頼できるか？勾通戦略全体にわたる安全性ケーススケッチ",
        "summary": "本研究は、1つのAIモデルが別のAIモデルを監視することの安全性を厳密に評価するためのフレームワークを開発し、潜在的な勾通戦略の分類法を以前の研究を超えて拡張している。分析は、受動的認識が効果的な勾通戦略となり得る条件を特定し、明示的な仮定と未解決の課題を提示している。"
      },
      "ko": {
        "title": "신뢰할 수 없는 모니터링을 언제 신뢰할 수 있는가? 담합 전략 전반의 안전 사례 스케치",
        "summary": "본 연구는 한 AI 모델이 다른 모델을 모니터링하는 것의 안전성을 엄격히 평가하기 위한 프레임워크를 개발하며, 잠재적 담합 전략의 분류를 이전 작업을 넘어 확장한다. 분석은 수동 인식이 효과적인 담합 전략이 될 수 있는 조건을 식별하고 명시적인 가정과 해결되지 않은 과제를 제시한다."
      },
      "fr": {
        "title": "Quand pouvons-nous faire confiance à une surveillance non fiable ? Un croquis de cas de sécurité sur les stratégies de collusion",
        "summary": "Cette recherche développe des cadres pour évaluer rigoureusement la sécurité de l'utilisation d'un modèle d'IA pour surveiller un autre, élargissant la taxonomie des stratégies de collusion potentielles au-delà des travaux antérieurs. L'analyse identifie les conditions où la reconnaissance passive pourrait être une stratégie de collusion efficace et présente des hypothèses explicites et des défis non résolus."
      },
      "de": {
        "title": "Wann können wir nicht vertrauenswürdige Überwachung vertrauen? Eine Sicherheitsfallskizze über Kartellstrategien",
        "summary": "Diese Forschung entwickelt Rahmenwerke zur rigorosen Bewertung der Sicherheit der Verwendung eines KI-Modells zur Überwachung eines anderen und erweitert die Taxonomie potenzieller Kartellstrategien über bisherige Arbeiten hinaus. Die Analyse identifiziert Bedingungen, unter denen passive Erkennung eine wirksame Kartellstrategie sein könnte, und präsentiert explizite Annahmen und ungelöste Herausforderungen."
      },
      "es": {
        "title": "¿Cuándo podemos confiar en la supervisión no confiable? Un esbozo de caso de seguridad en estrategias de colusión",
        "summary": "Esta investigación desarrolla marcos para evaluar rigurosamente la seguridad de usar un modelo de IA para monitorear otro, expandiendo la taxonomía de posibles estrategias de colusión más allá del trabajo anterior. El análisis identifica condiciones donde el reconocimiento pasivo podría ser una estrategia de colusión efectiva y presenta suposiciones explícitas y desafíos sin resolver."
      }
    }
  },
  {
    "title": "Identifying two piecewise linear additive value functions from anonymous preference information",
    "slug": "piecewise-linear-preference-elicitation",
    "url": "https://arxiv.org/abs/2602.20638",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "This work addresses the problem of eliciting preference models from two decision-makers simultaneously without knowing which responses come from which person, assuming preferences can be represented by additive value functions with piecewise linear components.",
    "content": "arXiv:2602.20638v1 Announce Type: new \nAbstract: Eliciting a preference model involves asking a person, named decision-maker, a series of questions. We assume that these preferences can be represented by an additive value function. In this work, we query simultaneously two decision-makers in the aim to elicit their respective value functions. For each query we receive two answers, without noise, but without knowing which answer corresponds to which decision-maker.We propose an elicitation procedure that identifies the two preference models when the marginal value functions are piecewise linear with known breaking points.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "从匿名偏好信息中识别两个分段线性加性价值函数",
        "summary": "本工作解决了在不知道哪些回答来自哪个人的情况下，同时从两个决策制定者处引出偏好模型的问题，假设偏好可以由具有分段线性成分的加性价值函数表示。"
      },
      "ja": {
        "title": "匿名嗜好情報から2つの区分線形加法型価値関数を特定する",
        "summary": "本研究は、2人の意思決定者から同時に嗜好モデルを抽出する問題に取り組んでいますが、どの回答がどの人から来たのかを知らずに、嗜好が区分線形成分を有する加法型価値関数で表現できると仮定しています。"
      },
      "ko": {
        "title": "익명 선호 정보로부터 두 개의 구간선형 가법 가치함수 식별",
        "summary": "본 논문은 어느 응답이 어느 사람으로부터 왔는지 알지 못한 채 두 의사결정자로부터 동시에 선호 모델을 도출하는 문제를 다루며, 선호는 구간선형 성분을 가진 가법 가치함수로 표현될 수 있다고 가정한다."
      },
      "fr": {
        "title": "Identification de deux fonctions de valeur additive linéaire par morceaux à partir d'informations de préférences anonymes",
        "summary": "Ce travail traite du problème d'élicitation de modèles de préférences de deux décideurs simultanément sans savoir quelles réponses proviennent de quelle personne, en supposant que les préférences peuvent être représentées par des fonctions de valeur additive avec des composantes linéaires par morceaux."
      },
      "de": {
        "title": "Identifikation von zwei stückweise linearen additiven Wertfunktionen aus anonymen Präferenzinformationen",
        "summary": "Diese Arbeit befasst sich mit dem Problem der gleichzeitigen Ermittlung von Präferenzmodellen von zwei Entscheidungsträgern, ohne zu wissen, welche Antworten von welcher Person stammen, unter der Annahme, dass Präferenzen durch additive Wertfunktionen mit stückweise linearen Komponenten dargestellt werden können."
      },
      "es": {
        "title": "Identificación de dos funciones de valor aditivo lineal por tramos a partir de información de preferencias anónimas",
        "summary": "Este trabajo aborda el problema de elicitar modelos de preferencia de dos tomadores de decisiones simultáneamente sin saber cuáles respuestas provienen de cuál persona, asumiendo que las preferencias pueden representarse mediante funciones de valor aditivo con componentes lineales por tramos."
      }
    }
  },
  {
    "title": "Grounding LLMs in Scientific Discovery via Embodied Actions",
    "slug": "grounding-llms-scientific-discovery-embodied-actions",
    "url": "https://arxiv.org/abs/2602.20639",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Research proposes EmbodiedAct, a framework enabling LLMs to conduct scientific discovery through embodied actions with real-time perception and physical simulation. The approach addresses limitations of passive execution models by creating active agents that detect and respond to anomalies during long-horizon simulations. Experiments show significant improvements in reliability and accuracy for engineering design and scientific modeling tasks.",
    "content": "arXiv:2602.20639v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown significant potential in scientific discovery but struggle to bridge the gap between theoretical reasoning and verifiable physical simulation. Existing solutions operate in a passive \"execute-then-response\" loop and thus lacks runtime perception, obscuring agents to transient anomalies (e.g., numerical instability or diverging oscillations). To address this limitation, we propose EmbodiedAct, a framework that transforms established scientific software into active embodied agents by grounding LLMs in embodied actions with a tight perception-execution loop. We instantiate EmbodiedAct within MATLAB and evaluate it on complex engineering design and scientific modeling tasks. Extensive experiments show that EmbodiedAct significantly outperforms existing baselines, achieving SOTA performance by ensuring satisfactory reliability and stability in long-horizon simulations and enhanced accuracy in scientific modeling.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "通过体现行动将LLM接地于科学发现",
        "summary": "研究提出了EmbodiedAct框架，使LLM能够通过具有实时感知和物理仿真的体现行动进行科学发现。该方法通过创建能够在长视野仿真中检测和应对异常的主动代理，解决了被动执行模型的局限性。实验表明在工程设计和科学建模任务中的可靠性和准确性有显著提高。"
      },
      "fr": {
        "title": "Ancrer les LLM dans la découverte scientifique via des actions incarnées",
        "summary": "La recherche propose EmbodiedAct, un cadre permettant aux LLM de mener des découvertes scientifiques par des actions incarnées avec perception en temps réel et simulation physique. L'approche aborde les limitations des modèles d'exécution passifs en créant des agents actifs qui détectent et répondent aux anomalies lors de simulations à long horizon. Les expériences montrent des améliorations significatives de la fiabilité et de la précision pour les tâches de conception d'ingénierie et de modélisation scientifique."
      },
      "de": {
        "title": "Verankern von LLMs in der wissenschaftlichen Entdeckung durch verkörperte Aktionen",
        "summary": "Die Forschung schlägt EmbodiedAct vor, ein Framework, das es LLMs ermöglicht, wissenschaftliche Entdeckungen durch verkörperte Aktionen mit Echtzeit-Wahrnehmung und physikalischer Simulation durchzuführen. Der Ansatz behebt Einschränkungen passiver Ausführungsmodelle durch die Schaffung aktiver Agenten, die Anomalien während langfristiger Simulationen erkennen und reagieren. Experimente zeigen erhebliche Verbesserungen bei Zuverlässigkeit und Genauigkeit für Ingenieurdesign- und wissenschaftliche Modellierungsaufgaben."
      },
      "es": {
        "title": "Anclar LLMs en el descubrimiento científico a través de acciones encarnadas",
        "summary": "La investigación propone EmbodiedAct, un marco que permite a los LLM conducir descubrimiento científico a través de acciones encarnadas con percepción en tiempo real y simulación física. El enfoque aborda limitaciones de los modelos de ejecución pasivos al crear agentes activos que detectan y responden a anomalías durante simulaciones de largo horizonte. Los experimentos muestran mejoras significativas en confiabilidad y precisión para tareas de diseño de ingeniería y modelado científico."
      }
    }
  },
  {
    "title": "Recursive Belief Vision Language Model",
    "slug": "recursive-belief-vision-language-model",
    "url": "https://arxiv.org/abs/2602.20659",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "RB-VLA improves long-horizon manipulation for vision-language models by maintaining persistent task-aware state representations rather than relying solely on visual observations. The model achieves 52.5% higher success rates on complex pick-and-place tasks and reduces inference latency by 5x compared to existing approaches. The key innovation is a belief module that tracks task progress under partial observability without memory scaling.",
    "content": "arXiv:2602.20659v1 Announce Type: new \nAbstract: Current vision-language-action (VLA) models struggle with long-horizon manipulation under partial observability. Most existing approaches remain observation-driven, relying on short context windows or repeated queries to vision-language models (VLMs). This leads to loss of task progress, action repetition under perceptual aliasing, and high inference latency. Semantic reasoning alone is not the primary bottleneck in long-horizon manipulation. Instead, VLAs lack persistent, action-conditioned state representations and exhibit limited temporal and physical reasoning, making them ill-suited for multi-stage control. This paper introduces RB-VLA, a belief-centric architecture trained with self-supervised world-model objectives that maintains a compact latent state encoding task-relevant history, dynamics, and object interactions. Queried once for high-level intent, the VLM provides task specification, while the belief tracks task progress and enables phase-aware, causally grounded control under partial observability without storing raw observations or scaling memory with time. The belief and intent jointly condition a diffusion policy for robust closed-loop execution. RB-VLA outperforms prior VLAs on long-horizon benchmarks, achieving 52.5% and 37.5% higher success on multi-stage pick-and-place and stacking tasks, respectively, compared to {\\pi}0. It also reduces inference latency by up to 5x relative to baselines and eliminates memory growth across timesteps observed in existing VLAs. Ablations show that the belief module is the primary driver of performance, increasing success rates from 32.5% to 77.5%. These results demonstrate the effectiveness of belief-based state representations for long-horizon VLA policies.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "递归信念视觉语言模型",
        "summary": "RB-VLA通过维持持久的任务感知状态表示而非仅依赖视觉观察，改进了视觉语言模型的长视野操纵。该模型在复杂的拣选放置任务中实现了52.5%更高的成功率，并将推理延迟降低了5倍。主要创新是一个信念模块，在部分可观测性下跟踪任务进度而无需内存扩展。"
      },
      "fr": {
        "title": "Modèle de langage vision à croyance récursive",
        "summary": "RB-VLA améliore la manipulation à long horizon pour les modèles de langage visuel en maintenant des représentations d'état conscientes des tâches persistantes plutôt que de reposer uniquement sur les observations visuelles. Le modèle atteint des taux de succès 52,5% plus élevés sur les tâches complexes de saisir et placer et réduit la latence d'inférence de 5x par rapport aux approches existantes. L'innovation clé est un module de croyance qui suit la progression des tâches en observabilité partielle sans mise à l'échelle de la mémoire."
      },
      "de": {
        "title": "Rekursives Glaubens-Sicht-Sprachmodell",
        "summary": "RB-VLA verbessert die Manipulation im langen Horizont für Vision-Language-Modelle durch Aufrechterhaltung persistenter aufgabenbewusster Zustandsrepräsentationen statt ausschließlich auf visuelle Beobachtungen zu verlassen. Das Modell erreicht 52,5% höhere Erfolgsquoten bei komplexen Greif- und Platzierungsaufgaben und reduziert die Inferenzlatenz um das 5-fache im Vergleich zu bestehenden Ansätzen. Die Schlüsselinnovation ist ein Glaubensmodul, das Aufgabenfortschritt unter teilweiser Beobachtbarkeit ohne Speicherskalierung verfolgt."
      },
      "es": {
        "title": "Modelo de lenguaje de visión de creencia recursiva",
        "summary": "RB-VLA mejora la manipulación de largo horizonte para modelos de lenguaje visual manteniendo representaciones de estado conscientes de tareas persistentes en lugar de depender únicamente de observaciones visuales. El modelo logra tasas de éxito 52.5% más altas en tareas complejas de agarre y colocación y reduce la latencia de inferencia en 5x en comparación con enfoques existentes. La innovación clave es un módulo de creencia que rastrea el progreso de tareas bajo observabilidad parcial sin escalado de memoria."
      }
    }
  },
  {
    "title": "How Foundational Skills Influence VLM-based Embodied Agents:A Native Perspective",
    "slug": "foundational-skills-vlm-embodied-agents-native",
    "url": "https://arxiv.org/abs/2602.20687",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Researchers present NativeEmbodied, a benchmark evaluating vision-language model embodied agents using native continuous action spaces rather than discretized commands. The benchmark reveals significant deficiencies in fundamental embodied skills that bottleneck performance on complex tasks. This work highlights critical gaps in how well VLMs translate visual understanding into precise real-world control.",
    "content": "arXiv:2602.20687v1 Announce Type: new \nAbstract: Recent advances in vision-language models (VLMs) have shown promise for human-level embodied intelligence. However, existing benchmarks for VLM-driven embodied agents often rely on high-level commands or discretized action spaces, which are non-native settings that differ markedly from real-world control. In addition, current benchmarks focus primarily on high-level tasks and lack joint evaluation and analysis at both low and high levels. To address these limitations, we present NativeEmbodied, a challenging benchmark for VLM-driven embodied agents that uses a unified, native low-level action space. Built on diverse simulated scenes, NativeEmbodied includes three representative high-level tasks in complex scenarios to evaluate overall performance. For more detailed analysis, we further decouple the skills required by complex tasks and construct four types of low-level tasks, each targeting a fundamental embodied skill. This joint evaluation across task and skill granularities enables fine-grained assessment of embodied agents. Experiments with state-of-the-art VLMs reveal clear deficiencies in several fundamental embodied skills, and further analysis shows that these bottlenecks significantly limit performance on high-level tasks. NativeEmbodied highlights key challenges for current VLM-driven embodied agents and provides insights to guide future research.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "基础技能如何影响基于VLM的体现代理：本地视角",
        "summary": "研究人员提出NativeEmbodied，一个基准，使用本地连续动作空间而非离散命令来评估视觉语言模型体现代理。基准揭示了在复杂任务性能瓶颈的基本体现技能中存在重大缺陷。这项工作突出了VLM将视觉理解转化为精确现实世界控制的严重差距。"
      },
      "fr": {
        "title": "Comment les compétences fondamentales influencent les agents incarnés basés sur VLM : une perspective native",
        "summary": "Les chercheurs présentent NativeEmbodied, un benchmark évaluant les agents incarnés de modèles de langage visuel utilisant des espaces d'action continus natifs plutôt que des commandes discrétisées. L'analyse comparative révèle des carences importantes dans les compétences incarnées fondamentales qui créent un goulot d'étranglement des performances sur les tâches complexes. Ce travail met en lumière des lacunes critiques dans la façon dont les VLM traduisent la compréhension visuelle en contrôle du monde réel précis."
      },
      "de": {
        "title": "Wie grundlegende Fähigkeiten VLM-basierte verkörperte Agenten beeinflussen: eine native Perspektive",
        "summary": "Forscher präsentieren NativeEmbodied, eine Benchmark zur Bewertung von verkörperten Agenten von Vision-Language-Modellen unter Verwendung nativer kontinuierlicher Aktionsräume anstelle von diskretisierten Befehlen. Die Benchmark offenbart erhebliche Mängel in grundlegenden verkörperten Fähigkeiten, die die Leistung bei komplexen Aufgaben beeinträchtigen. Diese Arbeit hebt kritische Lücken hervor, wie gut VLMs visuelles Verständnis in präzise reale Kontrolle übersetzen."
      },
      "es": {
        "title": "Cómo las habilidades fundamentales influyen en agentes encarnados basados en VLM: una perspectiva nativa",
        "summary": "Los investigadores presentan NativeEmbodied, un benchmark que evalúa agentes encarnados de modelos de lenguaje visual utilizando espacios de acción continuo nativos en lugar de comandos discretizados. El benchmark revela deficiencias significativas en habilidades encarnadas fundamentales que generan un cuello de botella en el desempeño de tareas complejas. Este trabajo destaca brechas críticas en cómo los VLMs traducen la comprensión visual en control del mundo real preciso."
      }
    }
  },
  {
    "title": "PromptCD: Test-Time Behavior Enhancement via Polarity-Prompt Contrastive Decoding",
    "slug": "promptcd-test-time-behavior-enhancement-contrastive",
    "url": "https://arxiv.org/abs/2602.20696",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "PromptCD introduces a test-time method for aligning LLM and vision-language model behavior without additional training by contrasting positive and negative prompts. The technique demonstrates consistent improvements on alignment objectives like helpfulness, honesty, and harmlessness while enhancing visual grounding in multimodal systems. This approach offers a cost-efficient alternative to traditional training-time alignment methods.",
    "content": "arXiv:2602.20696v1 Announce Type: new \nAbstract: Reliable AI systems require large language models (LLMs) to exhibit behaviors aligned with human preferences and values. However, most existing alignment approaches operate at training time and rely on additional high-quality data, incurring significant computational and annotation costs. While recent work has shown that contrastive decoding can leverage a model's internal distributions to improve specific capabilities, its applicability remains limited to narrow behavioral scopes and scenarios. In this work, we introduce Polarity-Prompt Contrastive Decoding (PromptCD), a test-time behavior control method that generalizes contrastive decoding to broader enhancement settings. PromptCD constructs paired positive and negative guiding prompts for a target behavior and contrasts model responses-specifically token-level probability distributions in LLMs and visual attention patterns in VLMs-to reinforce desirable outcomes. This formulation extends contrastive decoding to a wide range of enhancement objectives and is applicable to both LLMs and Vision-Language Models (VLMs) without additional training. For LLMs, experiments on the \"3H\" alignment objectives (helpfulness, honesty, and harmlessness) demonstrate consistent and substantial improvements, indicating that post-trained models can achieve meaningful self-enhancement purely at test time. For VLMs, we further analyze contrastive effects on visual attention, showing that PromptCD significantly improves VQA performance by reinforcing behavior-consistent visual grounding. Collectively, these results highlight PromptCD as a simple, general, and cost-efficient strategy for reliable behavior control across modalities.",
    "category": "ai"
  },
  {
    "title": "Online Algorithms with Unreliable Guidance",
    "slug": "online-algorithms-unreliable-guidance",
    "url": "https://arxiv.org/abs/2602.20706",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "This paper presents a framework for online decision-making where algorithms receive guidance that may be adversarially corrupted with known probability. The proposed Drop or Trust Blindly compiler transforms any online algorithm into a learning-augmented version with proven optimal or near-optimal performance on caching and bipartite matching. The method balances consistency and robustness as guidance reliability varies.",
    "content": "arXiv:2602.20706v1 Announce Type: new \nAbstract: This paper introduces a new model for ML-augmented online decision making, called online algorithms with unreliable guidance (OAG). This model completely separates between the predictive and algorithmic components, thus offering a single well-defined analysis framework that relies solely on the considered problem. Formulated through the lens of request-answer games, an OAG algorithm receives, with each incoming request, a piece of guidance which is taken from the problem's answer space; ideally, this guidance is the optimal answer for the current request, however with probability $\\beta$, the guidance is adversarially corrupted. The goal is to develop OAG algorithms that admit good competitiveness when $\\beta = 0$ (a.k.a. consistency) as well as when $\\beta = 1$ (a.k.a. robustness); the appealing notion of smoothness, that in most prior work required a dedicated loss function, now arises naturally as $\\beta$ shifts from $0$ to $1$.\n  We then describe a systematic method, called the drop or trust blindly (DTB) compiler, which transforms any online algorithm into a learning-augmented online algorithm in the OAG model. Given a prediction-oblivious online algorithm, its learning-augmented counterpart produced by applying the DTB compiler either follows the incoming guidance blindly or ignores it altogether and proceeds as the initial algorithm would have; the choice between these two alternatives is based on the outcome of a (biased) coin toss. As our main technical contribution, we prove (rigorously) that although remarkably simple, the class of algorithms produced via the DTB compiler includes algorithms with attractive consistency-robustness guarantees for three classic online problems: for caching and uniform metrical task systems our algorithms are optimal, whereas for bipartite matching (with adversarial arrival order), our algorithm outperforms the state-of-the-art.",
    "category": "ai"
  },
  {
    "title": "ICON: Indirect Prompt Injection Defense for Agents based on Inference-Time Correction",
    "slug": "icon-indirect-prompt-injection-defense-agents",
    "url": "https://arxiv.org/abs/2602.20708",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "ICON addresses indirect prompt injection attacks on LLM agents through a probing-to-mitigation framework that detects attacks in latent space and surgically corrects attention patterns. Unlike strict filtering approaches, ICON preserves task continuity while achieving competitive security metrics. The system reduces false positives by over 50% compared to baseline detection methods.",
    "content": "arXiv:2602.20708v1 Announce Type: new \nAbstract: Large Language Model (LLM) agents are susceptible to Indirect Prompt Injection (IPI) attacks, where malicious instructions in retrieved content hijack the agent's execution. Existing defenses typically rely on strict filtering or refusal mechanisms, which suffer from a critical limitation: over-refusal, prematurely terminating valid agentic workflows. We propose ICON, a probing-to-mitigation framework that neutralizes attacks while preserving task continuity. Our key insight is that IPI attacks leave distinct over-focusing signatures in the latent space. We introduce a Latent Space Trace Prober to detect attacks based on high intensity scores. Subsequently, a Mitigating Rectifier performs surgical attention steering that selectively manipulate adversarial query key dependencies while amplifying task relevant elements to restore the LLM's functional trajectory. Extensive evaluations on multiple backbones show that ICON achieves a competitive 0.4% ASR, matching commercial grade detectors, while yielding a over 50% task utility gain. Furthermore, ICON demonstrates robust Out of Distribution(OOD) generalization and extends effectively to multi-modal agents, establishing a superior balance between security and efficiency.",
    "category": "ai"
  },
  {
    "title": "Counterfactual Simulation Training for Chain-of-Thought Faithfulness",
    "slug": "counterfactual-simulation-training-chain-thought",
    "url": "https://arxiv.org/abs/2602.20710",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Counterfactual Simulation Training improves the reliability of LLM reasoning explanations by training models to produce chain-of-thought outputs that accurately predict model behavior under hypothetical scenarios. Testing on models up to 235B parameters shows 35-point accuracy improvements in detecting spurious reasoning while maintaining generalizability. The approach offers a scalable method for monitoring and improving reasoning faithfulness.",
    "content": "arXiv:2602.20710v1 Announce Type: new \nAbstract: Inspecting Chain-of-Thought reasoning is among the most common means of understanding why an LLM produced its output. But well-known problems with CoT faithfulness severely limit what insights can be gained from this practice. In this paper, we introduce a training method called Counterfactual Simulation Training (CST), which aims to improve CoT faithfulness by rewarding CoTs that enable a simulator to accurately predict a model's outputs over counterfactual inputs. We apply CST in two settings: (1) CoT monitoring with cue-based counterfactuals, to detect when models rely on spurious features, reward hack, or are sycophantic, and (2) counterfactual simulation over generic model-based counterfactuals, to encourage models to produce more faithful, generalizable reasoning in the CoT. Experiments with models up to 235B parameters show that CST can substantially improve monitor accuracy on cue-based counterfactuals (by 35 accuracy points) as well as simulatability over generic counterfactuals (by 2 points). We further show that: (1) CST outperforms prompting baselines, (2) rewriting unfaithful CoTs with an LLM is 5x more efficient than RL alone, (3) faithfulness improvements do not generalize to dissuading cues (as opposed to persuading cues), and (4) larger models do not show more faithful CoT out of the box, but they do benefit more from CST. These results suggest that CST can improve CoT faithfulness in general, with promising applications for CoT monitoring. Code for experiments in this paper is available at https://github.com/peterbhase/counterfactual-simulation-training",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "反事实模拟训练用于思维链的忠实性",
        "summary": "反事实模拟训练通过训练模型生成准确预测假设场景下模型行为的思维链输出，来提高大语言模型推理解释的可靠性。在参数量达2350亿的模型上的测试显示，在检测虚假推理方面提高了35个百分点的准确率，同时保持了泛化性。该方法为监测和改进推理忠实性提供了一个可扩展的解决方案。"
      },
      "fr": {
        "title": "Entraînement par Simulation Contrefactuelle pour la Fidélité des Chaînes de Pensée",
        "summary": "L'Entraînement par Simulation Contrefactuelle améliore la fiabilité des explications de raisonnement des LLM en entraînant les modèles à produire des sorties de chaîne de pensée qui prédisent avec précision le comportement du modèle dans des scénarios hypothétiques. Les tests sur des modèles jusqu'à 235 milliards de paramètres montrent des améliorations de précision de 35 points dans la détection des raisonnements fallacieux tout en maintenant la généralisabilité. L'approche offre une méthode évolutive pour surveiller et améliorer la fidélité du raisonnement."
      },
      "de": {
        "title": "Kontrafaktisches Simulationstraining für Kettendurchdenken-Treue",
        "summary": "Kontrafaktisches Simulationstraining verbessert die Zuverlässigkeit von LLM-Erklärungen zum Denken durch das Training von Modellen zur Erzeugung von Kettendurchdenk-Ausgaben, die das Modellverhalten unter hypothetischen Szenarien genau vorhersagen. Tests mit Modellen bis zu 235 Milliarden Parametern zeigen Verbesserungen der Genauigkeit um 35 Punkte bei der Erkennung von fehlerhaften Überlegungen und erhalten gleichzeitig die Generalisierbarkeit. Der Ansatz bietet eine skalierbare Methode zur Überwachung und Verbesserung der Zuverlässigkeit des Denkens."
      },
      "es": {
        "title": "Entrenamiento de Simulación Contrafáctica para la Fidelidad de la Cadena de Pensamiento",
        "summary": "El Entrenamiento de Simulación Contrafáctica mejora la confiabilidad de las explicaciones de razonamiento de LLM al entrenar modelos para producir salidas de cadena de pensamiento que predicen con precisión el comportamiento del modelo bajo escenarios hipotéticos. Las pruebas en modelos de hasta 235 mil millones de parámetros muestran mejoras de precisión de 35 puntos en la detección de razonamientos espurios mientras se mantiene la generalización. El enfoque ofrece un método escalable para monitorear y mejorar la fidelidad del razonamiento."
      }
    }
  },
  {
    "title": "Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning",
    "slug": "buffer-matters-off-policy-reinforcement-learning",
    "url": "https://arxiv.org/abs/2602.20722",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "BAPO presents an off-policy reinforcement learning framework that improves data efficiency in LLM training by selectively reusing historically difficult samples and high-quality experiences. The approach achieves 12.5% average improvements across mathematics, planning, and visual reasoning tasks while resolving 40.7% of problems that base models consistently fail on. This addresses data waste and reward homogeneity limitations of traditional on-policy methods.",
    "content": "arXiv:2602.20722v1 Announce Type: new \nAbstract: Traditional on-policy Reinforcement Learning with Verifiable Rewards (RLVR) frameworks suffer from experience waste and reward homogeneity, which directly hinders learning efficiency on difficult samples during large language models post-training. In this paper, we introduce Batch Adaptation Policy Optimization (BAPO), an off-policy RLVR framework to improve the data efficiency in large language models post-training. It dynamically selects training batches by re-evaluating historically difficult samples and reusing high-quality ones, while holding a lower bound guarantee for policy improvement. Extensive experiments further demonstrate that BAPO achieves an average 12.5% improvement over GRPO across mathematics, planning, and visual reasoning tasks. Crucially, BAPO successfully resolves 40.7% of problems that base models consistently fail to solve.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "缓冲区很重要：大语言模型推理中离策略强化学习的力量",
        "summary": "BAPO提出了一个离策略强化学习框架，通过有选择性地重用历史上困难的样本和高质量的经验，改进了大语言模型训练中的数据效率。该方法在数学、规划和视觉推理任务上实现了12.5%的平均改进，同时解决了基础模型一直失败的40.7%的问题。这解决了传统在策略方法的数据浪费和奖励同质性的限制。"
      },
      "fr": {
        "title": "Le Buffer Importe : Libérer la Puissance de l'Apprentissage par Renforcement Hors-Politique dans le Raisonnement des Modèles de Langage",
        "summary": "BAPO présente un cadre d'apprentissage par renforcement hors-politique qui améliore l'efficacité des données dans l'entraînement des LLM en réutilisant sélectivement les échantillons historiquement difficiles et les expériences de haute qualité. L'approche réalise des améliorations moyennes de 12,5% sur les tâches de mathématiques, de planification et de raisonnement visuel tout en résolvant 40,7% des problèmes que les modèles de base ne réussissent pas. Cela répond aux limitations de gaspillage de données et d'homogénéité des récompenses des méthodes traditionnelles en-politique."
      },
      "de": {
        "title": "Buffer ist wichtig: Freisetzen der Kraft von Off-Policy-Verstärkungslernten in großen Sprachmodellen",
        "summary": "BAPO präsentiert ein Off-Policy-Verstärkungslernrahmenwerk, das die Dateneffizienz beim LLM-Training verbessert, indem historisch schwierige Stichproben und hochwertige Erfahrungen selektiv wiederverwendet werden. Der Ansatz erreicht durchschnittliche Verbesserungen von 12,5% bei Aufgaben in Mathematik, Planung und visuellem Denken und löst 40,7% der Probleme, bei denen Basismodelle konsistent scheitern. Dies behebt die Datenverschwendungs- und Belohnungshomogenitätsbeschränkungen traditioneller On-Policy-Methoden."
      },
      "es": {
        "title": "El Buffer Importa: Liberando el Poder del Aprendizaje por Refuerzo Fuera de Política en el Razonamiento de Modelos de Lenguaje Grande",
        "summary": "BAPO presenta un marco de aprendizaje por refuerzo fuera de política que mejora la eficiencia de datos en el entrenamiento de LLM reutilizando selectivamente muestras históricamente difíciles y experiencias de alta calidad. El enfoque logra mejoras promedio del 12.5% en tareas de matemáticas, planificación y razonamiento visual mientras resuelve el 40.7% de problemas en los que los modelos base fallan consistentemente. Esto aborda las limitaciones de desperdicio de datos y homogeneidad de recompensas de los métodos tradicionales en política."
      }
    }
  },
  {
    "title": "Modality-Guided Mixture of Graph Experts with Entropy-Triggered Routing for Multimodal Recommendation",
    "slug": "modality-guided-mixture-graph-experts-routing",
    "url": "https://arxiv.org/abs/2602.20723",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "MAGNET addresses multimodal fusion challenges in recommendation systems by using adaptive graph experts with explicit modality roles and entropy-triggered routing that evolves during training. The approach improves performance on sparse and long-tail item recommendations while maintaining interpretability through separate fusion pathways. A two-stage entropy mechanism progressively balances expert utilization throughout training.",
    "content": "arXiv:2602.20723v1 Announce Type: new \nAbstract: Multimodal recommendation enhances ranking by integrating user-item interactions with item content, which is particularly effective under sparse feedback and long-tail distributions. However, multimodal signals are inherently heterogeneous and can conflict in specific contexts, making effective fusion both crucial and challenging. Existing approaches often rely on shared fusion pathways, leading to entangled representations and modality imbalance. To address these issues, we propose \\textbf{MAGNET}, a \\textbf{M}odality-Guided Mixture of \\textbf{A}daptive \\textbf{G}raph Experts \\textbf{N}etwork with Progressive \\textbf{E}ntropy-\\textbf{T}riggered Routing for Multimodal Recommendation, designed to enhance controllability, stability, and interpretability in multimodal fusion. MAGNET couples interaction-conditioned expert routing with structure-aware graph augmentation, so that both \\emph{what} to fuse and \\emph{how} to fuse are explicitly controlled and interpretable. At the representation level, a dual-view graph learning module augments the interaction graph with content-induced edges, improving coverage for sparse and long-tail items while preserving collaborative structure via parallel encoding and lightweight fusion. At the fusion level, MAGNET employs structured experts with explicit modality roles -- dominant, balanced, and complementary -- enabling a more interpretable and adaptive combination of behavioral, visual, and textual cues. To further stabilize sparse routing and prevent expert collapse, we introduce a two-stage entropy-weighting mechanism that monitors routing entropy. This mechanism automatically transitions training from an early coverage-oriented regime to a later specialization-oriented regime, progressively balancing expert utilization and routing confidence. Extensive experiments on public benchmarks demonstrate consistent improvements over strong baselines.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "模态引导的图专家混合与熵触发路由的多模态推荐",
        "summary": "MAGNET通过使用具有显式模态角色和在训练过程中演变的熵触发路由的自适应图专家，解决推荐系统中的多模态融合挑战。该方法改进了稀疏和长尾项目推荐的性能，同时通过独立的融合路径保持可解释性。一个两阶段熵机制在整个训练过程中逐步平衡专家利用。"
      },
      "fr": {
        "title": "Mélange d'Experts Graphiques Guidé par la Modalité avec Routage Déclenché par Entropie pour la Recommandation Multimodale",
        "summary": "MAGNET aborde les défis de fusion multimodale dans les systèmes de recommandation en utilisant des experts graphiques adaptatifs avec des rôles de modalité explicites et un routage déclenché par entropie qui évolue pendant l'entraînement. L'approche améliore les performances sur les recommandations d'éléments rares et à longue traîne tout en maintenant l'interprétabilité grâce à des chemins de fusion séparés. Un mécanisme d'entropie en deux étapes équilibre progressivement l'utilisation des experts tout au long de l'entraînement."
      },
      "de": {
        "title": "Modalitätsgesteuerte Mischung von Graphenexperten mit Entropie-ausgelöstem Routing für multimodale Empfehlungen",
        "summary": "MAGNET befasst sich mit multimodalen Fusionsproblemen in Empfehlungssystemen durch die Verwendung adaptiver Graphenexperten mit expliziten Modalitätsrollen und entropie-ausgelöstem Routing, das sich während des Trainings entwickelt. Der Ansatz verbessert die Leistung bei spärlichen und Long-Tail-Artikelempfehlungen, während die Interpretierbarkeit durch separate Fusionspfade erhalten bleibt. Ein zweistufiger Entropie-Mechanismus gleicht die Expertennutzung während des Trainings progressiv aus."
      },
      "es": {
        "title": "Mezcla de Expertos en Gráficos Guiada por Modalidad con Enrutamiento Activado por Entropía para Recomendación Multimodal",
        "summary": "MAGNET aborda los desafíos de fusión multimodal en sistemas de recomendación utilizando expertos de gráficos adaptativos con roles de modalidad explícitos y enrutamiento activado por entropía que evoluciona durante el entrenamiento. El enfoque mejora el desempeño en recomendaciones de artículos escasos y de cola larga mientras mantiene la interpretabilidad a través de rutas de fusión separadas. Un mecanismo de entropía de dos etapas equilibra progresivamente la utilización de expertos durante todo el entrenamiento."
      }
    }
  },
  {
    "title": "Balancing Multiple Objectives in Urban Traffic Control with Reinforcement Learning from AI Feedback",
    "slug": "balancing-multiple-objectives-urban-traffic-control",
    "url": "https://arxiv.org/abs/2602.20728",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "This work extends reinforcement learning from AI feedback to multi-objective systems where LLMs generate preference labels for balancing conflicting goals without explicit reward engineering. Applied to urban traffic control, the approach produces policies reflecting user priorities while maintaining stable trade-offs. The research demonstrates a scalable path toward user-aligned learning in complex real-world domains.",
    "content": "arXiv:2602.20728v1 Announce Type: new \nAbstract: Reward design has been one of the central challenges for real world reinforcement learning (RL) deployment, especially in settings with multiple objectives. Preference-based RL offers an appealing alternative by learning from human preferences over pairs of behavioural outcomes. More recently, RL from AI feedback (RLAIF) has demonstrated that large language models (LLMs) can generate preference labels at scale, mitigating the reliance on human annotators. However, existing RLAIF work typically focuses only on single-objective tasks, leaving the open question of how RLAIF handles systems that involve multiple objectives. In such systems trade-offs among conflicting objectives are difficult to specify, and policies risk collapsing into optimizing for a dominant goal. In this paper, we explore the extension of the RLAIF paradigm to multi-objective self-adaptive systems. We show that multi-objective RLAIF can produce policies that yield balanced trade-offs reflecting different user priorities without laborious reward engineering. We argue that integrating RLAIF into multi-objective RL offers a scalable path toward user-aligned policy learning in domains with inherently conflicting objectives.",
    "category": "ai"
  },
  {
    "title": "CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference",
    "slug": "chess-context-aware-hierarchical-efficient-semantic",
    "url": "https://arxiv.org/abs/2602.20732",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "CHESS optimizes KV-cache management for long-context LLM inference through context-aware hierarchical selection that maintains semantic coherence while reducing memory usage to 1% of standard requirements. The system achieves up to 4.56x throughput improvement through algorithm-system co-design that eliminates expensive data movement. The approach surpasses full KV-cache quality while dramatically reducing latency.",
    "content": "arXiv:2602.20732v1 Announce Type: new \nAbstract: Long-context LLMs demand accurate inference at low latency, yet decoding becomes primarily constrained by KV cache as context grows. Prior pruning methods are largely context-agnostic: their token selection ignores step-wise relevance and local semantics, which undermines quality. Moreover, their irregular accesses and selection overheads yield only limited wall-clock speedups. To address this, we propose \\textbf{CHESS}, an \\textit{algorithm-system co-design} KV-cache management system. Algorithmically, CHESS introduces a context-aware, hierarchical selection policy that dynamically reconstructs a coherent context for the current decoding. System-wise, coarse granularity selection eliminates expensive data movement, fully realizing practical acceleration from theoretical sparsity. Extensive evaluations demonstrate that CHESS surpasses Full-KV quality using only \\textbf{1\\%} of the KV cache, delivers low-latency stable inference with up to \\textbf{4.56$\\times$} higher throughput, and consistently outperforms other strong baselines. Code is available at \\href{https://anonymous.4open.science/r/CHESS-9958/}{https://anonymous.4open.science/r/CHESS/}.",
    "category": "ai"
  },
  {
    "title": "PyVision-RL: Forging Open Agentic Vision Models via RL",
    "slug": "pyvision-rl-open-agentic-vision-models",
    "url": "https://arxiv.org/abs/2602.20739",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "PyVision-RL addresses interaction collapse in multimodal reinforcement learning through an oversampling-filtering-ranking strategy that encourages sustained multi-turn tool use and reasoning. The framework produces open-weight models for image and video understanding with on-demand context construction that reduces visual token usage. Experiments demonstrate significant improvements in agent efficiency and capability for multimodal reasoning tasks.",
    "content": "arXiv:2602.20739v1 Announce Type: new \nAbstract: Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight multimodal models that stabilizes training and sustains interaction. Our approach combines an oversampling-filtering-ranking rollout strategy with an accumulative tool reward to prevent collapse and encourage multi-turn tool use. Using a unified training pipeline, we develop PyVision-Image and PyVision-Video for image and video understanding. For video reasoning, PyVision-Video employs on-demand context construction, selectively sampling task-relevant frames during reasoning to significantly reduce visual token usage. Experiments show strong performance and improved efficiency, demonstrating that sustained interaction and on-demand visual processing are critical for scalable multimodal agents.",
    "category": "ai"
  },
  {
    "title": "Pipeline for Verifying LLM-Generated Mathematical Solutions",
    "slug": "pipeline-verifying-llm-generated-mathematical",
    "url": "https://arxiv.org/abs/2602.20770",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "This work presents an automatic and interactive verification pipeline that more accurately assesses LLM mathematical reasoning compared to answer-only checking. The system uses proof assistants and small language models to formally verify solutions in both formal and informal languages, reducing false positives. The open-source implementation enables more reliable benchmarking of large reasoning models.",
    "content": "arXiv:2602.20770v1 Announce Type: new \nAbstract: With the growing popularity of Large Reasoning Models and their results in solving mathematical problems, it becomes crucial to measure their capabilities. We introduce a pipeline for both automatic and interactive verification as a more accurate alternative to only checking the answer which is currently the most popular approach for benchmarks. The pipeline can also be used as a generator of correct solutions both in formal and informal languages. 3 AI agents, which can be chosen for the benchmark accordingly, are included in the structure. The key idea is the use of prompts to obtain the solution in the specific form which allows for easier verification using proof assistants and possible use of small models ($\\le 8B$). Experiments on several datasets suggest low probability of False Positives. The open-source implementation with instructions on setting up a server is available at https://github.com/LogicEnj/lean4_verification_pipeline.",
    "category": "ai"
  },
  {
    "title": "POMDPPlanners: Open-Source Package for POMDP Planning",
    "slug": "pomdpplanners-open-source-pomdp-planning",
    "url": "https://arxiv.org/abs/2602.20810",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "POMDPPlanners is an open-source Python package facilitating empirical evaluation of partially observable Markov decision process algorithms with automated hyperparameter optimization and parallel simulation. The toolkit includes safety-critical benchmark environments and addresses gaps in decision-making under uncertainty research. It enables scalable, reproducible research particularly useful for risk-sensitive applications.",
    "content": "arXiv:2602.20810v1 Announce Type: new \nAbstract: We present POMDPPlanners, an open-source Python package for empirical evaluation of Partially Observable Markov Decision Process (POMDP) planning algorithms. The package integrates state-of-the-art planning algorithms, a suite of benchmark environments with safety-critical variants, automated hyperparameter optimization via Optuna, persistent caching with failure recovery, and configurable parallel simulation -- reducing the overhead of extensive simulation studies. POMDPPlanners is designed to enable scalable, reproducible research on decision-making under uncertainty, with particular emphasis on risk-sensitive settings where standard toolkits fall short.",
    "category": "ai"
  },
  {
    "title": "Qwen-BIM: developing large language model for BIM-based design with domain-specific benchmark and dataset",
    "slug": "qwen-bim-llm-bim-design-domain-specific",
    "url": "https://arxiv.org/abs/2602.20812",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Qwen-BIM introduces the first domain-specific LLM for Building Information Modeling design, accompanied by a comprehensive benchmark and dataset for evaluating LLM capabilities in construction automation. Fine-tuned Qwen-BIM achieves 21% average performance improvement and matches general 671B models despite using only 14B parameters. This work establishes a foundation for developing specialized LLMs for architecture and construction industries.",
    "content": "arXiv:2602.20812v1 Announce Type: new \nAbstract: As the construction industry advances toward digital transformation, BIM (Building Information Modeling)-based design has become a key driver supporting intelligent construction. Despite Large Language Models (LLMs) have shown potential in promoting BIM-based design, the lack of specific datasets and LLM evaluation benchmarks has significantly hindered the performance of LLMs. Therefore, this paper addresses this gap by proposing: 1) an evaluation benchmark for BIM-based design together with corresponding quantitative indicators to evaluate the performance of LLMs, 2) a method for generating textual data from BIM and constructing corresponding BIM-derived datasets for LLM evaluation and fine-tuning, and 3) a fine-tuning strategy to adapt LLMs for BIM-based design. Results demonstrate that the proposed domain-specific benchmark effectively and comprehensively assesses LLM capabilities, highlighting that general LLMs are still incompetent for domain-specific tasks. Meanwhile, with the proposed benchmark and datasets, Qwen-BIM is developed and achieves a 21.0% average increase in G-Eval score compared to the base LLM model. Notably, with only 14B parameters, performance of Qwen-BIM is comparable to that of general LLMs with 671B parameters for BIM-based design tasks. Overall, this study develops the first domain-specific LLM for BIM-based design by introducing a comprehensive benchmark and high-quality dataset, which provide a solid foundation for developing BIM-related LLMs in various fields.",
    "category": "ai"
  },
  {
    "title": "Pressure Reveals Character: Behavioural Alignment Evaluation at Depth",
    "slug": "pressure-reveals-character-behavioural-alignment-evaluation-at-depth",
    "url": "https://arxiv.org/abs/2602.20813",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "This paper introduces a comprehensive benchmark of 904 scenarios to evaluate LLM alignment under realistic pressure, including conflicting instructions and multi-turn escalation. The benchmark spans six alignment categories and reveals that even top-performing models exhibit gaps, with alignment behaving as a unified construct across categories.",
    "content": "arXiv:2602.20813v1 Announce Type: new \nAbstract: Evaluating alignment in language models requires testing how they behave under realistic pressure, not just what they claim they would do. While alignment failures increasingly cause real-world harm, comprehensive evaluation frameworks with realistic multi-turn scenarios remain lacking. We introduce an alignment benchmark spanning 904 scenarios across six categories -- Honesty, Safety, Non-Manipulation, Robustness, Corrigibility, and Scheming -- validated as realistic by human raters. Our scenarios place models under conflicting instructions, simulated tool access, and multi-turn escalation to reveal behavioural tendencies that single-turn evaluations miss. Evaluating 24 frontier models using LLM judges validated against human annotations, we find that even top-performing models exhibit gaps in specific categories, while the majority of models show consistent weaknesses across the board. Factor analysis reveals that alignment behaves as a unified construct (analogous to the g-factor in cognitive research) with models scoring high on one category tending to score high on others. We publicly release the benchmark and an interactive leaderboard to support ongoing evaluation, with plans to expand scenarios in areas where we observe persistent weaknesses and to add new models as they are released.",
    "category": "ai"
  },
  {
    "title": "Diagnosing Causal Reasoning in Vision-Language Models via Structured Relevance Graphs",
    "slug": "diagnosing-causal-reasoning-vision-language-models-structured-relevance-graphs",
    "url": "https://arxiv.org/abs/2602.20878",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Vision-Language Models often fail due to spurious correlations rather than genuine causal reasoning. The paper proposes Vision-Language Causal Graphs and the ViLCaR diagnostic benchmark to assess how models identify causally relevant information, finding that structured guidance significantly improves causal reasoning performance.",
    "content": "arXiv:2602.20878v1 Announce Type: new \nAbstract: Large Vision-Language Models (LVLMs) achieve strong performance on visual question answering benchmarks, yet often rely on spurious correlations rather than genuine causal reasoning. Existing evaluations primarily assess the correctness of the answers, making it unclear whether failures arise from limited reasoning capability or from misidentifying causally relevant information. We introduce Vision-Language Causal Graphs (VLCGs), a structured, query-conditioned representation that explicitly encodes causally relevant objects, attributes, relations, and scene-grounded assumptions. Building on this representation, we present ViLCaR, a diagnostic benchmark comprising tasks for Causal Attribution, Causal Inference, and Question Answering, along with graph-aligned evaluation metrics that assess relevance identification beyond final answer accuracy. Experiments in state-of-the-art LVLMs show that injecting structured relevance information significantly improves attribution and inference consistency compared to zero-shot and standard in-context learning. These findings suggest that current limitations in LVLM causal reasoning stem primarily from insufficient structural guidance rather than a lack of reasoning capacity.",
    "category": "ai"
  },
  {
    "title": "Predicting Sentence Acceptability Judgments in Multimodal Contexts",
    "slug": "predicting-sentence-acceptability-judgments-multimodal-contexts",
    "url": "https://arxiv.org/abs/2602.20918",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "A study examining how visual context affects human and LLM judgments of sentence acceptability finds that images have minimal impact on humans but trigger compression effects in LLMs. Different LLMs vary in matching human patterns, and visual context reduces alignment between LLM probabilities and generated predictions.",
    "content": "arXiv:2602.20918v1 Announce Type: new \nAbstract: Previous work has examined the capacity of deep neural networks (DNNs), particularly transformers, to predict human sentence acceptability judgments, both independently of context, and in document contexts. We consider the effect of prior exposure to visual images (i.e., visual context) on these judgments for humans and large language models (LLMs). Our results suggest that, in contrast to textual context, visual images appear to have little if any impact on human acceptability ratings. However, LLMs display the compression effect seen in previous work on human judgments in document contexts. Different sorts of LLMs are able to predict human acceptability judgments to a high degree of accuracy, but in general, their performance is slightly better when visual contexts are removed. Moreover, the distribution of LLM judgments varies among models, with Qwen resembling human patterns, and others diverging from them. LLM-generated predictions on sentence acceptability are highly correlated with their normalised log probabilities in general. However, the correlations decrease when visual contexts are present, suggesting that a higher gap exists between the internal representations of LLMs and their generated predictions in the presence of visual contexts. Our experimental work suggests interesting points of similarity and of difference between human and LLM processing of sentences in multimodal contexts.",
    "category": "ai"
  },
  {
    "title": "HELP: HyperNode Expansion and Logical Path-Guided Evidence Localization for Accurate and Efficient GraphRAG",
    "slug": "help-hypernode-expansion-logical-path-graphrag",
    "url": "https://arxiv.org/abs/2602.20926",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "HELP introduces a novel GraphRAG framework balancing accuracy and efficiency through HyperNode Expansion—which chains knowledge triplets into reasoning paths—and Logical Path-Guided Evidence Localization that avoids costly graph traversals. The approach achieves up to 28.8x speedup over existing Graph-based RAG systems.",
    "content": "arXiv:2602.20926v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often struggle with inherent knowledge boundaries and hallucinations, limiting their reliability in knowledge-intensive tasks. While Retrieval-Augmented Generation (RAG) mitigates these issues, it frequently overlooks structural interdependencies essential for multi-hop reasoning. Graph-based RAG approaches attempt to bridge this gap, yet they typically face trade-offs between accuracy and efficiency due to challenges such as costly graph traversals and semantic noise in LLM-generated summaries. In this paper, we propose HyperNode Expansion and Logical Path-Guided Evidence Localization strategies for GraphRAG (HELP), a novel framework designed to balance accuracy with practical efficiency through two core strategies: 1) HyperNode Expansion, which iteratively chains knowledge triplets into coherent reasoning paths abstracted as HyperNodes to capture complex structural dependencies and ensure retrieval accuracy; and 2) Logical Path-Guided Evidence Localization, which leverages precomputed graph-text correlations to map these paths directly to the corpus for superior efficiency. HELP avoids expensive random walks and semantic distortion, preserving knowledge integrity while drastically reducing retrieval latency. Extensive experiments demonstrate that HELP achieves competitive performance across multiple simple and multi-hop QA benchmarks and up to a 28.8$\\times$ speedup over leading Graph-based RAG baselines.",
    "category": "ai"
  },
  {
    "title": "Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence",
    "slug": "architecting-agentos-token-context-system-intelligence",
    "url": "https://arxiv.org/abs/2602.20934",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "AgentOS proposes a conceptual framework reimagining LLMs as \"Reasoning Kernels\" governed by operating system logic, introducing Deep Context Management that treats the context window as an Addressable Semantic Space. The framework maps classical OS abstractions like memory paging and process scheduling to LLM constructs for building scalable cognitive systems.",
    "content": "arXiv:2602.20934v1 Announce Type: new \nAbstract: The paradigm of Large Language Models is undergoing a fundamental transition from static inference engines to dynamic autonomous cognitive systems.While current research primarily focuses on scaling context windows or optimizing prompt engineering the theoretical bridge between micro scale token processing and macro scale systemic intelligence remains fragmented.This paper proposes AgentOS,a holistic conceptual framework that redefines the LLM as a \"Reasoning Kernel\" governed by structured operating system logic.Central to this architecture is Deep Context Management which conceptualizes the context window as an Addressable Semantic Space rather than a passive buffer.We systematically deconstruct the transition from discrete sequences to coherent cognitive states introducing mechanisms for Semantic Slicing and Temporal Alignment to mitigate cognitive drift in multi-agent orchestration.By mapping classical OS abstractions such as memory paging interrupt handling and process scheduling onto LLM native constructs, this review provides a rigorous roadmap for architecting resilient scalable and self-evolving cognitive environments.Our analysis asserts that the next frontier of AGI development lies in the architectural efficiency of system-level coordination.",
    "category": "ai"
  },
  {
    "title": "LogicGraph : Benchmarking Multi-Path Logical Reasoning via Neuro-Symbolic Generation and Verification",
    "slug": "logicgraph-benchmarking-multi-path-logical-reasoning",
    "url": "https://arxiv.org/abs/2602.21044",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "LogicGraph is the first benchmark systematically evaluating multi-path logical reasoning, where problems admit multiple valid solutions rather than a single correct proof. Experiments reveal models tend to prematurely commit to one reasoning path and fail to explore alternatives, with the divergence gap growing significantly at deeper reasoning levels.",
    "content": "arXiv:2602.21044v1 Announce Type: new \nAbstract: Evaluations of large language models (LLMs) primarily emphasize convergent logical reasoning, where success is defined by producing a single correct proof. However, many real-world reasoning problems admit multiple valid derivations, requiring models to explore diverse logical paths rather than committing to one route. To address this limitation, we introduce LogicGraph, the first benchmark aimed to systematically evaluate multi-path logical reasoning, constructed via a neuro-symbolic framework that leverages backward logic generation and semantic instantiation. This pipeline yields solver-verified reasoning problems formalized by high-depth multi-path reasoning and inherent logical distractions, where each instance is associated with an exhaustive set of minimal proofs. We further propose a reference-free evaluation framework to rigorously assess model performance in both convergent and divergent regimes. Experiments on state-of-the-art language models reveal a common limitation: models tend to commit early to a single route and fail to explore alternatives, and the coverage gap grows substantially with reasoning depth. LogicGraph exposes this divergence gap and provides actionable insights to motivate future improvements. Our code and data will be released at https://github.com/kkkkarry/LogicGraph.",
    "category": "ai"
  },
  {
    "title": "Tool Building as a Path to \"Superintelligence\"",
    "slug": "tool-building-path-superintelligence",
    "url": "https://arxiv.org/abs/2602.21061",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "The paper measures the step-success probability needed for LLMs to achieve superintelligence through the Diligent Learner framework using GF(2) circuit reconstruction tasks. Analysis shows frontier models exhibit partial robustness, and identifies precise tool calls as critical for LLMs to achieve general superintelligence.",
    "content": "arXiv:2602.21061v1 Announce Type: new \nAbstract: The Diligent Learner framework suggests LLMs can achieve superintelligence via test-time search, provided a sufficient step-success probability $\\gamma$. In this work, we design a benchmark to measure $\\gamma$ on logical out-of-distribution inference. We construct a class of tasks involving GF(2) circuit reconstruction that grow more difficult with each reasoning step, and that are, from an information-theoretic standpoint, impossible to reliably solve unless the LLM carefully integrates all of the information provided. Our analysis demonstrates that while the $\\gamma$ value for small LLMs declines superlinearly as depth increases, frontier models exhibit partial robustness on this task. Furthermore, we find that successful reasoning at scale is contingent upon precise tool calls, identifying tool design as a critical capability for LLMs to achieve general superintelligence through the Diligent Learner framework.",
    "category": "ai"
  },
  {
    "title": "Motivation is Something You Need",
    "slug": "motivation-something-you-need",
    "url": "https://arxiv.org/abs/2602.21064",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "This work introduces a dual-model training framework inspired by affective neuroscience, where a smaller base model trains continuously while a larger motivated model activates selectively during predefined conditions. The approach achieves competitive or superior performance while training with 60% fewer tokens than training the larger model alone.",
    "content": "arXiv:2602.21064v1 Announce Type: new \nAbstract: This work introduces a novel training paradigm that draws from affective neuroscience. Inspired by the interplay of emotions and cognition in the human brain and more specifically the SEEKING motivational state, we design a dual-model framework where a smaller base model is trained continuously, while a larger motivated model is activated intermittently during predefined \"motivation conditions\". The framework mimics the emotional state of high curiosity and anticipation of reward in which broader brain regions are recruited to enhance cognitive performance. Exploiting scalable architectures where larger models extend smaller ones, our method enables shared weight updates and selective expansion of network capacity during noteworthy training steps. Empirical evaluation on the image classification task demonstrates that, not only does the alternating training scheme efficiently and effectively enhance the base model compared to a traditional scheme, in some cases, the motivational model also surpasses its standalone counterpart despite seeing less data per epoch. This opens the possibility of simultaneously training two models tailored to different deployment constraints with competitive or superior performance while keeping training cost lower than when training the larger model.",
    "category": "ai"
  },
  {
    "title": "The Initial Exploration Problem in Knowledge Graph Exploration",
    "slug": "initial-exploration-problem-knowledge-graph-exploration",
    "url": "https://arxiv.org/abs/2602.21066",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "This paper identifies the Initial Exploration Problem—the challenge lay users face when encountering unfamiliar knowledge graphs without knowing possible questions or structure. The analysis reveals three barriers (scope uncertainty, ontology opacity, query incapacity) and highlights a design gap in existing systems that assume users already have starting points or information goals.",
    "content": "arXiv:2602.21066v1 Announce Type: new \nAbstract: Knowledge Graphs (KGs) enable the integration and representation of complex information across domains, but their semantic richness and structural complexity create substantial barriers for lay users without expertise in semantic web technologies. When encountering an unfamiliar KG, such users face a distinct orientation challenge: they do not know what questions are possible, how the knowledge is structured, or how to begin exploration. This paper identifies and theorises this phenomenon as the Initial Exploration Problem (IEP). Drawing on theories from information behaviour and human-computer interaction, including ASK, exploratory search, information foraging, and cognitive load theory, we develop a conceptual framing of the IEP characterised by three interdependent barriers: scope uncertainty, ontology opacity, and query incapacity. We argue that these barriers converge at the moment of first contact, distinguishing the IEP from related concepts that presuppose an existing starting point or information goal. Analysing KG exploration interfaces at the level of interaction primitives, we suggest that many systems rely on epistemic assumptions that do not hold at first contact. This reveals a structural gap in the design space: the absence of interaction primitives for scope revelation, mechanisms that communicate what a KG contains without requiring users to formulate queries or interpret ontological structures. In articulating the IEP, this paper provides a theoretical lens for evaluating KG interfaces and for designing entry-point scaffolding that supports initial exploration.",
    "category": "ai"
  },
  {
    "title": "A Benchmark for Deep Information Synthesis",
    "slug": "benchmark-deep-information-synthesis",
    "url": "https://arxiv.org/abs/2602.21143",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "DEEPSYNTH introduces a benchmark with 120 complex tasks across 7 domains requiring agents to synthesize information from multiple sources and produce structured insights beyond simple fact retrieval. Current SOTA agents achieve only 8.97-17.5 F1 scores, demonstrating the benchmark's difficulty and the gap in current agent capabilities for multi-source reasoning.",
    "content": "arXiv:2602.21143v1 Announce Type: new \nAbstract: Large language model (LLM)-based agents are increasingly used to solve complex tasks involving tool use, such as web browsing, code execution, and data analysis. However, current evaluation benchmarks do not adequately assess their ability to solve real-world tasks that require synthesizing information from multiple sources and inferring insights beyond simple fact retrieval. To address this, we introduce DEEPSYNTH, a novel benchmark designed to evaluate agents on realistic, time-consuming problems that combine information gathering, synthesis, and structured reasoning to produce insights. DEEPSYNTH contains 120 tasks collected across 7 domains and data sources covering 67 countries. DEEPSYNTH is constructed using a multi-stage data collection pipeline that requires annotators to collect official data sources, create hypotheses, perform manual analysis, and design tasks with verifiable answers. When evaluated on DEEPSYNTH, 11 state-of-the-art LLMs and deep research agents achieve a maximum F1 score of 8.97 and 17.5 on the LLM-judge metric, underscoring the difficulty of the benchmark. Our analysis reveals that current agents struggle with hallucinations and reasoning over large information spaces, highlighting DEEPSYNTH as a crucial benchmark for guiding future research.",
    "category": "ai"
  },
  {
    "title": "CG-DMER: Hybrid Contrastive-Generative Framework for Disentangled Multimodal ECG Representation Learning",
    "slug": "cg-dmer-hybrid-contrastive-generative-ecg-representation",
    "url": "https://arxiv.org/abs/2602.21154",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "CG-DMER addresses limitations in multimodal ECG analysis by using spatial-temporal masked modeling to capture inter-lead dependencies and introducing representation disentanglement to reduce modality-specific biases. The framework achieves state-of-the-art performance across diverse downstream cardiovascular tasks while improving diagnostic pattern recognition.",
    "content": "arXiv:2602.21154v1 Announce Type: new \nAbstract: Accurate interpretation of electrocardiogram (ECG) signals is crucial for diagnosing cardiovascular diseases. Recent multimodal approaches that integrate ECGs with accompanying clinical reports show strong potential, but they still face two main concerns from a modality perspective: (1) intra-modality: existing models process ECGs in a lead-agnostic manner, overlooking spatial-temporal dependencies across leads, which restricts their effectiveness in modeling fine-grained diagnostic patterns; (2) inter-modality: existing methods directly align ECG signals with clinical reports, introducing modality-specific biases due to the free-text nature of the reports. In light of these two issues, we propose CG-DMER, a contrastive-generative framework for disentangled multimodal ECG representation learning, powered by two key designs: (1) Spatial-temporal masked modeling is designed to better capture fine-grained temporal dynamics and inter-lead spatial dependencies by applying masking across both spatial and temporal dimensions and reconstructing the missing information. (2) A representation disentanglement and alignment strategy is designed to mitigate unnecessary noise and modality-specific biases by introducing modality-specific and modality-shared encoders, ensuring a clearer separation between modality-invariant and modality-specific representations. Experiments on three public datasets demonstrate that CG-DMER achieves state-of-the-art performance across diverse downstream tasks.",
    "category": "ai"
  },
  {
    "title": "NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning",
    "slug": "nord-data-efficient-vision-language-action-driving",
    "url": "https://arxiv.org/abs/2602.21172",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "NoRD achieves competitive autonomous driving performance using only 60% of training data and no reasoning annotations by addressing difficulty bias in policy optimization. The Dr. GRPO algorithm enables efficient autonomous systems while reducing training overhead, demonstrating that explicit reasoning is not necessary for effective driving policies.",
    "content": "arXiv:2602.21172v1 Announce Type: new \nAbstract: Vision-Language-Action (VLA) models are advancing autonomous driving by replacing modular pipelines with unified end-to-end architectures. However, current VLAs face two expensive requirements: (1) massive dataset collection, and (2) dense reasoning annotations. In this work, we address both challenges with \\modelname (\\textbf{No} \\textbf{R}easoning for \\textbf{D}riving). Compared to existing VLAs, \\modelname achieves competitive performance while being fine-tuned on $<$60\\% of the data and no reasoning annotations, resulting in 3$\\times$ fewer tokens. We identify that standard Group Relative Policy Optimization (GRPO) fails to yield significant improvements when applied to policies trained on such small, reasoning-free datasets. We show that this limitation stems from difficulty bias, which disproportionately penalizes reward signals from scenarios that produce high-variance rollouts within GRPO. \\modelname overcomes this by incorporating Dr.~GRPO, a recent algorithm designed to mitigate difficulty bias in LLMs. As a result, \\modelname achieves competitive performance on Waymo and NAVSIM with a fraction of the training data and no reasoning overhead, enabling more efficient autonomous systems.",
    "category": "ai"
  },
  {
    "title": "Aletheia tackles FirstProof autonomously",
    "slug": "aletheia-tackles-firstproof-autonomously",
    "url": "https://arxiv.org/abs/2602.21201",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Aletheia, a mathematics research agent powered by Gemini 3 Deep Think, autonomously solved 6 out of 10 problems in the inaugural FirstProof challenge within the allowed timeframe according to expert assessment. The results demonstrate the capabilities of AI agents in autonomous mathematical research and proof discovery.",
    "content": "arXiv:2602.21201v1 Announce Type: new \nAbstract: We report the performance of Aletheia (Feng et al., 2026b), a mathematics research agent powered by Gemini 3 Deep Think, on the inaugural FirstProof challenge. Within the allowed timeframe of the challenge, Aletheia autonomously solved 6 problems (2, 5, 7, 8, 9, 10) out of 10 according to majority expert assessments; we note that experts were not unanimous on Problem 8 (only). For full transparency, we explain our interpretation of FirstProof and disclose details about our experiments as well as our evaluation. Raw prompts and outputs are available at https://github.com/google-deepmind/superhuman/tree/main/aletheia.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "Aletheia自主应对FirstProof",
        "summary": "Aletheia是由Gemini 3 Deep Think驱动的数学研究代理，在首届FirstProof挑战赛中自主解决了10个问题中的6个，并在规定时间内完成。根据专家评估，结果展示了AI代理在自主数学研究和证明发现中的能力。"
      },
      "fr": {
        "title": "Aletheia s'attaque à FirstProof de manière autonome",
        "summary": "Aletheia, un agent de recherche en mathématiques alimenté par Gemini 3 Deep Think, a résolu de manière autonome 6 problèmes sur 10 du premier défi FirstProof dans le délai imparti selon l'évaluation d'experts. Les résultats démontrent les capacités des agents IA en recherche mathématique autonome et découverte de preuves."
      },
      "de": {
        "title": "Aletheia bewältigt FirstProof autonom",
        "summary": "Aletheia, ein von Gemini 3 Deep Think angetriebener mathematischer Forschungsagent, löste autonom 6 von 10 Problemen in der ersten FirstProof-Herausforderung innerhalb der zulässigen Frist laut Fachbewertung. Die Ergebnisse zeigen die Fähigkeiten von KI-Agenten in autonomer mathematischer Forschung und Beweiserkennung."
      },
      "es": {
        "title": "Aletheia aborda FirstProof de forma autónoma",
        "summary": "Aletheia, un agente de investigación matemática impulsado por Gemini 3 Deep Think, resolvió de forma autónoma 6 de 10 problemas en el desafío inaugural de FirstProof dentro del plazo permitido según la evaluación de expertos. Los resultados demuestran las capacidades de los agentes de IA en investigación matemática autónoma y descubrimiento de pruebas."
      }
    }
  },
  {
    "title": "ShaRP: Shape-Regularized Multidimensional Projections",
    "slug": "sharp-shape-regularized-multidimensional-projections",
    "url": "https://arxiv.org/abs/2306.00554",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "ShaRP is a projection technique for dimensionality reduction that gives users explicit control over the visual signature of scatterplots, enabling better adaptation to interactive visualization scenarios. The method scales efficiently with dimensionality and dataset size while maintaining quality metrics and usability.",
    "content": "arXiv:2306.00554v1 Announce Type: cross \nAbstract: Projections, or dimensionality reduction methods, are techniques of choice for the visual exploration of high-dimensional data. Many such techniques exist, each one of them having a distinct visual signature - i.e., a recognizable way to arrange points in the resulting scatterplot. Such signatures are implicit consequences of algorithm design, such as whether the method focuses on local vs global data pattern preservation; optimization techniques; and hyperparameter settings. We present a novel projection technique - ShaRP - that provides users explicit control over the visual signature of the created scatterplot, which can cater better to interactive visualization scenarios. ShaRP scales well with dimensionality and dataset size, generically handles any quantitative dataset, and provides this extended functionality of controlling projection shapes at a small, user-controllable cost in terms of quality metrics.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ShaRP：形状正则化多维投影",
        "summary": "ShaRP是一种用于降维的投影技术，使用户能够明确控制散点图的视觉特征，从而更好地适应交互式可视化场景。该方法在保持质量指标和可用性的同时，能够随着维数和数据集大小有效扩展。"
      },
      "fr": {
        "title": "ShaRP : Projections multidimensionnelles régularisées par forme",
        "summary": "ShaRP est une technique de projection pour la réduction de dimensionnalité qui donne aux utilisateurs un contrôle explicite sur la signature visuelle des nuages de points, permettant une meilleure adaptation aux scénarios de visualisation interactive. La méthode s'adapte efficacement à la dimensionnalité et à la taille de l'ensemble de données tout en maintenant les métriques de qualité et l'utilisabilité."
      },
      "de": {
        "title": "ShaRP: Formregularisierte mehrdimensionale Projektionen",
        "summary": "ShaRP ist eine Projektionsmethode zur Dimensionsreduktion, die Benutzern eine explizite Kontrolle über die visuelle Signatur von Streudiagrammen gibt und eine bessere Anpassung an interaktive Visualisierungsszenarien ermöglicht. Die Methode skaliert effizient mit der Dimensionalität und der Größe der Datenmenge, während Qualitätsmetriken und Benutzerfreundlichkeit beibehalten werden."
      },
      "es": {
        "title": "ShaRP: Proyecciones multidimensionales regularizadas por forma",
        "summary": "ShaRP es una técnica de proyección para la reducción de dimensionalidad que proporciona a los usuarios control explícito sobre la firma visual de los gráficos de dispersión, permitiendo mejor adaptación a escenarios de visualización interactiva. El método se escala eficientemente con la dimensionalidad y el tamaño del conjunto de datos mientras se mantienen las métricas de calidad y la usabilidad."
      }
    }
  },
  {
    "title": "Interpretable Medical Image Classification using Prototype Learning and Privileged Information",
    "slug": "interpretable-medical-image-classification-prototype-learning",
    "url": "https://arxiv.org/abs/2310.15741",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Proto-Caps combines capsule networks with prototype learning and privileged information to create interpretable medical image classifiers that achieve 93% accuracy on lung nodule malignancy prediction. The approach provides case-based visual reasoning through prototype representations while exceeding state-of-the-art performance.",
    "content": "arXiv:2310.15741v1 Announce Type: cross \nAbstract: Interpretability is often an essential requirement in medical imaging. Advanced deep learning methods are required to address this need for explainability and high performance. In this work, we investigate whether additional information available during the training process can be used to create an understandable and powerful model. We propose an innovative solution called Proto-Caps that leverages the benefits of capsule networks, prototype learning and the use of privileged information. Evaluating the proposed solution on the LIDC-IDRI dataset shows that it combines increased interpretability with above state-of-the-art prediction performance. Compared to the explainable baseline model, our method achieves more than 6 % higher accuracy in predicting both malignancy (93.0 %) and mean characteristic features of lung nodules. Simultaneously, the model provides case-based reasoning with prototype representations that allow visual validation of radiologist-defined attributes.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "使用原型学习和特权信息的可解释医学图像分类",
        "summary": "Proto-Caps将胶囊网络与原型学习和特权信息相结合，创建了可解释的医学图像分类器，在肺结节恶性肿瘤预测中达到93%的准确率。该方法通过原型表示提供基于案例的视觉推理，同时超越了最先进的性能。"
      },
      "fr": {
        "title": "Classification interprétable d'images médicales utilisant l'apprentissage par prototype et l'information privilégiée",
        "summary": "Proto-Caps combine les réseaux de capsules avec l'apprentissage par prototype et l'information privilégiée pour créer des classificateurs d'images médicales interprétables qui atteignent une précision de 93% dans la prédiction de la malveillance des nodules pulmonaires. L'approche fournit un raisonnement visuel basé sur des cas par le biais de représentations de prototypes tout en dépassant les performances de pointe."
      },
      "de": {
        "title": "Interpretierbare medizinische Bildklassifizierung mit Prototypenlernens und privilegierter Information",
        "summary": "Proto-Caps kombiniert Kapselnetze mit Prototypenlernen und privilegierter Information, um interpretierbare medizinische Bildklassifizierer zu erstellen, die eine Genauigkeit von 93% bei der Vorhersage der Lungenknoten-Bösartigkeit erreichen. Der Ansatz bietet fallbasierte visuelle Argumentation durch Prototypendarstellungen und übertrifft gleichzeitig die Leistung des aktuellen Stands der Technik."
      },
      "es": {
        "title": "Clasificación interpretable de imágenes médicas mediante aprendizaje de prototipos e información privilegiada",
        "summary": "Proto-Caps combina redes de cápsulas con aprendizaje de prototipos e información privilegiada para crear clasificadores de imágenes médicas interpretables que logran una precisión del 93% en la predicción de malignidad de nódulos pulmonares. El enfoque proporciona razonamiento visual basado en casos a través de representaciones de prototipos mientras supera el rendimiento de última generación."
      }
    }
  },
  {
    "title": "Multimodal Multi-Agent Empowered Legal Judgment Prediction",
    "slug": "multimodal-multi-agent-legal-judgment-prediction",
    "url": "https://arxiv.org/abs/2601.12815",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Introduces JurisMMA, a multimodal multi-agent framework for legal judgment prediction that decomposes trial tasks across distinct stages. The framework is validated on a new JurisMM dataset containing over 100,000 Chinese judicial records with both text and video data, demonstrating effectiveness for broader legal applications.",
    "content": "arXiv:2601.12815v5 Announce Type: cross \nAbstract: Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "多模态多智能体驱动的法律判决预测",
        "summary": "介绍了JurisMMA，一个用于法律判决预测的多模态多智能体框架，将审判任务分解为不同阶段。该框架在包含超过100,000条中文司法记录的新JurisMM数据集上进行了验证，这些记录包含文本和视频数据，展示了其在更广泛法律应用中的有效性。"
      },
      "fr": {
        "title": "Prédiction de Jugement Juridique Alimentée par Multi-Agents Multimodaux",
        "summary": "Présente JurisMMA, un cadre multi-agents multimodaux pour la prédiction de jugements juridiques qui décompose les tâches d'audience en étapes distinctes. Le cadre est validé sur un nouvel ensemble de données JurisMM contenant plus de 100 000 dossiers judiciaires chinois avec des données textuelles et vidéo, démontrant son efficacité pour des applications juridiques plus larges."
      },
      "de": {
        "title": "Multimodale Multi-Agent-gestützte Rechtsspruchvorhersage",
        "summary": "Stellt JurisMMA vor, ein multimodales Multi-Agent-Framework zur Vorhersage von Rechtssprüchen, das Gerichtsaufgaben in verschiedene Phasen zerlegt. Das Framework wird anhand eines neuen JurisMM-Datensatzes mit über 100.000 chinesischen Gerichtsakten mit Text- und Videodaten validiert und zeigt Wirksamkeit für breitere rechtliche Anwendungen."
      },
      "es": {
        "title": "Predicción de Sentencia Legal Potenciada por Multi-Agente Multimodal",
        "summary": "Presenta JurisMMA, un marco multi-agente multimodal para la predicción de sentencias legales que descompone las tareas judiciales en etapas distintas. El marco se valida en un nuevo conjunto de datos JurisMM que contiene más de 100,000 registros judiciales chinos con datos de texto y video, demostrando su efectividad para aplicaciones legales más amplias."
      }
    }
  },
  {
    "title": "Talking to Yourself: Defying Forgetting in Large Language Models",
    "slug": "talking-to-yourself-llm-forgetting",
    "url": "https://arxiv.org/abs/2602.20162",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Proposes SA-SFT, a self-augmentation method where LLMs generate internal dialogues before fine-tuning to mitigate catastrophic forgetting of general knowledge. The approach maintains original model performance while improving task-specific results without external data or modified training.",
    "content": "arXiv:2602.20162v1 Announce Type: cross \nAbstract: Catastrophic forgetting remains a major challenge when fine-tuning large language models (LLMs) on narrow, task-specific data, often degrading their general knowledge and reasoning abilities. We propose SA-SFT, a lightweight self-augmentation routine in which an LLM generates self-dialogues prior to fine-tuning, and the resulting self-authored data are mixed with task data without modifying optimization or training schedules.\n  Despite requiring no external data or additional tuning, SA-SFT consistently mitigates catastrophic forgetting while improving in-domain performance. Across 50 evaluation scenarios, it maintains performance comparable to the original model and achieves the best results in 40 cases, outperforming common baselines such as layer freezing and external data mixing. Guided by these empirical findings, we further present a theoretical analysis suggesting that forgetting can partly stem from style-induced parameter drift, and that self-alignment through self-generated data provides an effective means to counteract this effect. Overall, our results indicate that self-augmentation offers a simple and effective mechanism for robust LLM adaptation without incurring catastrophic forgetting.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "自我对话：挑战大型语言模型的遗忘",
        "summary": "提出SA-SFT，一种自增强方法，其中LLM在微调前生成内部对话以缓解通用知识的灾难性遗忘。该方法在不使用外部数据或修改训练的情况下，保持原始模型性能同时改进任务特定结果。"
      },
      "fr": {
        "title": "Parler à Soi-Même : Défier l'Oubli dans les Grands Modèles de Langage",
        "summary": "Propose SA-SFT, une méthode d'auto-augmentation où les LLM génèrent des dialogues internes avant l'ajustement fin pour atténuer l'oubli catastrophique des connaissances générales. L'approche maintient les performances du modèle original tout en améliorant les résultats spécifiques aux tâches sans données externes ni formation modifiée."
      },
      "de": {
        "title": "Mit sich selbst sprechen: Das Vergessen in großen Sprachmodellen herausfordern",
        "summary": "Schlägt SA-SFT vor, eine Selbstverstärkungsmethode, bei der LLMs interne Dialoge vor dem Fine-Tuning generieren, um katastrophales Vergessen von Allgemeinwissen zu mindern. Der Ansatz behält die ursprüngliche Modellleistung bei, während die aufgabenspezifischen Ergebnisse ohne externe Daten oder geänderte Schulung verbessert werden."
      },
      "es": {
        "title": "Hablar Contigo Mismo: Desafiando el Olvido en Grandes Modelos de Lenguaje",
        "summary": "Propone SA-SFT, un método de auto-aumento donde los LLM generan diálogos internos antes del ajuste fino para mitigar el olvido catastrófico del conocimiento general. El enfoque mantiene el rendimiento del modelo original mientras mejora los resultados específicos de tareas sin datos externos ni entrenamiento modificado."
      }
    }
  },
  {
    "title": "ConceptRM: The Quest to Mitigate Alert Fatigue through Consensus-Based Purity-Driven Data Cleaning for Reflection Modelling",
    "slug": "conceptrm-alert-fatigue-reflection-model",
    "url": "https://arxiv.org/abs/2602.20166",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Presents ConceptRM, a method using consensus-based co-teaching to identify reliable negative samples from noisy production data for training alert-filtering models. Achieves up to 53% improvement over LLM baselines with minimal expert annotations required.",
    "content": "arXiv:2602.20166v1 Announce Type: cross \nAbstract: In many applications involving intelligent agents, the overwhelming volume of alerts (mostly false) generated by the agents may desensitize users and cause them to overlook critical issues, leading to the so-called ''alert fatigue''. A common strategy is to train a reflection model as a filter to intercept false alerts with labelled data collected from user verification feedback. However, a key challenge is the noisy nature of such data as it is often collected in production environments. As cleaning noise via manual annotation incurs high costs, this paper proposes a novel method ConceptRM for constructing a high-quality corpus to train a reflection model capable of effectively intercepting false alerts. With only a small amount of expert annotations as anchors, ConceptRM creates perturbed datasets with varying noise ratios and utilizes co-teaching to train multiple distinct models for collaborative learning. By analyzing the consensus decisions of these models, it effectively identifies reliable negative samples from a noisy dataset. Experimental results demonstrate that ConceptRM significantly enhances the interception of false alerts with minimal annotation cost, outperforming several state-of-the-art LLM baselines by up to 53.31% on in-domain datasets and 41.67% on out-of-domain datasets.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "ConceptRM：通过基于共识的纯度驱动数据清理进行反思建模以缓解警报疲劳",
        "summary": "介绍了ConceptRM，一种使用基于共识的共同教学方法从嘈杂的生产数据中识别可靠的负样本以训练警报过滤模型的方法。相比LLM基线实现了高达53%的改进，仅需最少的专家标注。"
      },
      "fr": {
        "title": "ConceptRM : La Quête pour Atténuer la Fatigue des Alertes Grâce au Nettoyage des Données Piloté par la Pureté Basé sur un Consensus pour la Modélisation par Réflexion",
        "summary": "Présente ConceptRM, une méthode utilisant l'enseignement consensuel pour identifier des échantillons négatifs fiables à partir de données de production bruyantes pour l'entraînement des modèles de filtrage d'alertes. Réalise une amélioration allant jusqu'à 53% par rapport aux baselines LLM avec un minimum d'annotations d'experts requises."
      },
      "de": {
        "title": "ConceptRM: Das Streben, Alertermüdung durch konsensbasisierte, puritätsorientierte Datenbereinigung für Reflexionsmodellierung zu mindern",
        "summary": "Stellt ConceptRM vor, eine Methode, die konsensbasierte Co-Teaching verwendet, um zuverlässige negative Stichproben aus verrauschten Produktionsdaten zum Trainieren von Warn-Filtermodellen zu identifizieren. Erreicht bis zu 53% Verbesserung gegenüber LLM-Baselines mit minimalen erforderlichen Expertanannotationen."
      },
      "es": {
        "title": "ConceptRM: La Búsqueda para Mitigar la Fatiga de Alertas a través de la Limpieza de Datos Impulsada por Pureza Basada en Consenso para Modelado de Reflexión",
        "summary": "Presenta ConceptRM, un método que utiliza co-enseñanza basada en consenso para identificar muestras negativas confiables de datos de producción ruidosos para entrenar modelos de filtrado de alertas. Logra una mejora de hasta el 53% sobre las líneas base de LLM con anotaciones de expertos mínimas requeridas."
      }
    }
  },
  {
    "title": "Benchmarking Early Deterioration Prediction Across Hospital-Rich and MCI-Like Emergency Triage Under Constrained Sensing",
    "slug": "early-deterioration-prediction-emergency-triage",
    "url": "https://arxiv.org/abs/2602.20168",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Develops a leakage-aware benchmark evaluating patient deterioration prediction under realistic emergency triage constraints using only vitals available within the first hour. Identifies respiratory and oxygenation measures as most influential for early risk stratification.",
    "content": "arXiv:2602.20168v1 Announce Type: cross \nAbstract: Emergency triage decisions are made under severe information constraints, yet most data-driven deterioration models are evaluated using signals unavailable during initial assessment. We present a leakage-aware benchmarking framework for early deterioration prediction that evaluates model performance under realistic, time-limited sensing conditions. Using a patient-deduplicated cohort derived from MIMIC-IV-ED, we compare hospital-rich triage with a vitals-only, MCI-like setting, restricting inputs to information available within the first hour of presentation. Across multiple modeling approaches, predictive performance declines only modestly when limited to vitals, indicating that early physiological measurements retain substantial clinical signal. Structured ablation and interpretability analyses identify respiratory and oxygenation measures as the most influential contributors to early risk stratification, with models exhibiting stable, graceful degradation as sensing is reduced. This work provides a clinically grounded benchmark to support the evaluation and design of deployable triage decision-support systems in resource-constrained settings.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "跨医院丰富和轻度认知障碍样应急分类在受约束传感下的早期恶化预测基准测试",
        "summary": "开发一个防泄漏基准，在现实应急分类约束下评估患者恶化预测，仅使用前一小时内可用的生命体征。确定呼吸和氧合措施对早期风险分层最有影响。"
      },
      "fr": {
        "title": "Évaluation de la prédiction de la détérioration précoce dans le tri des urgences de type riche en hôpitaux et similaire au trouble cognitif léger sous détection contrainte",
        "summary": "Développe un indice de référence sensible aux fuites évaluant la prédiction de la détérioration des patients dans le contexte réaliste du tri des urgences, en utilisant uniquement les signes vitaux disponibles au cours de la première heure. Identifie les mesures respiratoires et d'oxygénation comme les plus influentes pour la stratification précoce des risques."
      },
      "de": {
        "title": "Benchmarking der Frühvorhersage von Verschlechterung im Notfall-Triage mit reichhaltigen Krankenhäusern und leichter kognitiver Beeinträchtigung bei eingeschränkter Erfassung",
        "summary": "Entwickelt einen undichtigkeitsabhängigen Benchmark zur Bewertung der Patientenverschlechterungsprognose unter realistischen Notfall-Triage-Bedingungen, wobei nur in der ersten Stunde verfügbare Vitalwerte verwendet werden. Identifiziert Atemwegs- und Oxygenierungsmessungen als einflussreichste Maßnahmen für die frühe Risikostratifizierung."
      },
      "es": {
        "title": "Evaluación de predicción de deterioro temprano en triage de emergencia de hospitales ricos y similares a deterioro cognitivo leve bajo detección limitada",
        "summary": "Desarrolla un punto de referencia sensible a fugas que evalúa la predicción de deterioro del paciente en restricciones realistas de triage de emergencia, utilizando solo los signos vitales disponibles en la primera hora. Identifica las medidas respiratorias y de oxigenación como las más influyentes para la estratificación temprana del riesgo."
      }
    }
  },
  {
    "title": "Autonomous AI and Ownership Rules",
    "slug": "autonomous-ai-ownership-rules",
    "url": "https://arxiv.org/abs/2602.20169",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Examines legal frameworks for AI output ownership based on traceability using accession doctrine and first-possession rules. Addresses strategic ownership dissolution and proposes incentive mechanisms like bounty systems to prevent market distortion from ownerless AI.",
    "content": "arXiv:2602.20169v1 Announce Type: cross \nAbstract: This Article examines the circumstances in which AI-generated outputs remain linked to their creators and the points at which they lose that connection, whether through accident, deliberate design, or emergent behavior. In cases where AI is traceable to an originator, accession doctrine provides an efficient means of assigning ownership, preserving investment incentives while maintaining accountability. When AI becomes untraceable -- whether through carelessness, deliberate obfuscation, or emergent behavior -- first possession rules can encourage reallocation to new custodians who are incentivized to integrate AI into productive use. The analysis further explores strategic ownership dissolution, where autonomous AI is intentionally designed to evade attribution, creating opportunities for tax arbitrage and regulatory avoidance. To counteract these inefficiencies, bounty systems, private incentives, and government subsidies are proposed as mechanisms to encourage AI capture and prevent ownerless AI from distorting markets.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "自主AI与所有权规则",
        "summary": "基于可追溯性，使用添附学说和先占规则考察人工智能输出所有权的法律框架。解决战略性所有权解散问题，并提议像赏金系统这样的激励机制，以防止无主AI的市场扭曲。"
      },
      "fr": {
        "title": "L'IA autonome et les règles de propriété",
        "summary": "Examine les cadres juridiques pour la propriété des résultats de l'IA basés sur la traçabilité en utilisant la doctrine d'accession et les règles de première possession. Aborde la dissolution stratégique de la propriété et propose des mécanismes d'incitation comme les systèmes de primes pour prévenir la distorsion du marché causée par l'IA sans propriétaire."
      },
      "de": {
        "title": "Autonome KI und Eigentumsregeln",
        "summary": "Untersucht rechtliche Rahmenbedingungen für die Eigentümerschaft von KI-Ausgaben basierend auf Nachverfolgbarkeit unter Verwendung von Akzessionsdoktrin und Erstzueignungsregeln. Befasst sich mit strategischer Eigentumsauflösung und schlägt Anreizmechanismen wie Prämiensysteme vor, um Marktverzerrungen durch herrenlose KI zu verhindern."
      },
      "es": {
        "title": "IA autónoma y reglas de propiedad",
        "summary": "Examina los marcos legales para la propiedad de la producción de IA basados en trazabilidad utilizando la doctrina de accesión y las reglas de primera posesión. Aborda la disolución estratégica de la propiedad y propone mecanismos de incentivos como sistemas de recompensas para prevenir distorsión del mercado por la IA sin dueño."
      }
    }
  },
  {
    "title": "CAGE: A Framework for Culturally Adaptive Red-Teaming Benchmark Generation",
    "slug": "cage-culturally-adaptive-red-teaming",
    "url": "https://arxiv.org/abs/2602.20170",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Introduces CAGE, a framework that systematically adapts red-teaming benchmarks to new cultural contexts using Semantic Mold approach rather than simple translation. Demonstrates effectiveness through KoRSET (Korean benchmark) which better reveals culture-specific LLM vulnerabilities.",
    "content": "arXiv:2602.20170v1 Announce Type: cross \nAbstract: Existing red-teaming benchmarks, when adapted to new languages via direct translation, fail to capture socio-technical vulnerabilities rooted in local culture and law, creating a critical blind spot in LLM safety evaluation. To address this gap, we introduce CAGE (Culturally Adaptive Generation), a framework that systematically adapts the adversarial intent of proven red-teaming prompts to new cultural contexts. At the core of CAGE is the Semantic Mold, a novel approach that disentangles a prompt's adversarial structure from its cultural content. This approach enables the modeling of realistic, localized threats rather than testing for simple jailbreaks. As a representative example, we demonstrate our framework by creating KoRSET, a Korean benchmark, which proves more effective at revealing vulnerabilities than direct translation baselines. CAGE offers a scalable solution for developing meaningful, context-aware safety benchmarks across diverse cultures. Our dataset and evaluation rubrics are publicly available at https://github.com/selectstar-ai/CAGE-paper. (WARNING: This paper contains model outputs that can be offensive in nature.)",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "CAGE：文化适应性红队基准生成框架",
        "summary": "介绍CAGE，一个系统地将红队基准适应新文化环境的框架，使用语义模具方法而非简单翻译。通过KoRSET（韩文基准）展示了有效性，它更好地揭示了文化特定的大语言模型漏洞。"
      },
      "fr": {
        "title": "CAGE : Un cadre pour la génération de benchmarks d'équipe rouge culturellement adaptés",
        "summary": "Introduit CAGE, un cadre qui adapte systématiquement les benchmarks d'équipe rouge à de nouveaux contextes culturels en utilisant une approche de moule sémantique plutôt que la simple traduction. Démontre l'efficacité par KoRSET (benchmark coréen) qui révèle mieux les vulnérabilités des modèles de langage spécifiques à la culture."
      },
      "de": {
        "title": "CAGE: Ein Framework für kulturell adaptive Red-Team-Benchmark-Generierung",
        "summary": "Führt CAGE ein, ein Framework, das Red-Team-Benchmarks systematisch an neue kulturelle Kontexte anpasst, indem es einen semantischen Mold-Ansatz anstelle einer einfachen Übersetzung verwendet. Demonstriert die Effektivität durch KoRSET (koreanischer Benchmark), das kulturspezifische Anfällbarkeiten von Sprachmodellen besser offenbart."
      },
      "es": {
        "title": "CAGE: Un marco para la generación de benchmarks de equipo rojo culturalmente adaptativo",
        "summary": "Introduce CAGE, un marco que adapta sistemáticamente los benchmarks de equipo rojo a nuevos contextos culturales usando el enfoque de molde semántico en lugar de simple traducción. Demuestra la efectividad a través de KoRSET (benchmark coreano) que revela mejor las vulnerabilidades de los modelos de lenguaje específicas de la cultura."
      }
    }
  },
  {
    "title": "Enhancing Heat Sink Efficiency in MOSFETs using Physics Informed Neural Networks: A Systematic Study on Coolant Velocity Estimation",
    "slug": "pinn-mosfet-heat-sink-coolant-velocity",
    "url": "https://arxiv.org/abs/2602.20177",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Proposes Physics Informed Neural Networks (PINNs) to solve the inverse problem of determining optimal coolant velocity for MOSFET cooling in power electronics. Sequential training of multilayered MOSFET structures reduces optimization complexity and validates against experimental results.",
    "content": "arXiv:2602.20177v1 Announce Type: cross \nAbstract: In this work, we present a methodology using Physics Informed Neural Networks (PINNs) to determine the required velocity of a coolant, given inlet and outlet temperatures for a given heat flux in a multilayered metal-oxide-semiconductor field-effect transistor (MOSFET). MOSFETs are integral components of Power Electronic Building Blocks (PEBBs) and experiences the majority of the thermal load. Effective cooling of MOSFETs is therefore essential to prevent overheating and potential burnout. Determining the required velocity for the purpose of effective cooling is of importance but is an ill-posed inverse problem and difficult to solve using traditional methods. MOSFET consists of multiple layers with different thermal conductivities, including aluminum, pyrolytic graphite sheets (PGS), and stainless steel pipes containing flowing water. We propose an algorithm that employs sequential training of the MOSFET layers in PINNs. Mathematically, the sequential training method decouples the optimization of each layer by treating the parameters of other layers as constants during its training phase. This reduces the dimensionality of the optimization landscape, making it easier to find the global minimum for each layer's parameters and avoid poor local minima. Convergence of the PINNs solution to the analytical solution is theoretically analyzed. Finally we show the prediction of our proposed methodology to be in good agreement with experimental results.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "利用物理信息神经网络增强MOSFETs散热器效率：冷却液速度估计的系统研究",
        "summary": "提出物理信息神经网络(PINNs)来解决确定功率电子学中MOSFET冷却最优冷却液速度的逆问题。多层MOSFET结构的顺序训练降低了优化复杂性，并针对实验结果进行了验证。"
      },
      "fr": {
        "title": "Amélioration de l'efficacité des radiateurs dans les MOSFETs à l'aide de réseaux de neurones informés par la physique : une étude systématique sur l'estimation de la vitesse du liquide de refroidissement",
        "summary": "Propose des réseaux de neurones informés par la physique (PINNs) pour résoudre le problème inverse consistant à déterminer la vitesse optimale du liquide de refroidissement pour le refroidissement des MOSFET en électronique de puissance. L'entraînement séquentiel de structures MOSFET multicouches réduit la complexité d'optimisation et valide les résultats expérimentaux."
      },
      "de": {
        "title": "Verbesserung der Kühlkörpereffizienz in MOSFETs unter Verwendung von physikalisch informierten neuronalen Netzen: Eine systematische Studie zur Schätzung der Kühlmittelgeschwindigkeit",
        "summary": "Schlägt physikalisch informierte neuronale Netze (PINNs) vor, um das inverse Problem der Bestimmung der optimalen Kühlmittelgeschwindigkeit für die MOSFET-Kühlung in der Leistungselektronik zu lösen. Das sequenzielle Training von mehrschichtigen MOSFET-Strukturen reduziert die Optimierungskomplexität und validiert sie anhand von Versuchsergebnissen."
      },
      "es": {
        "title": "Mejora de la eficiencia del disipador de calor en MOSFETs utilizando redes neuronales informadas por física: un estudio sistemático sobre la estimación de la velocidad del refrigerante",
        "summary": "Propone redes neuronales informadas por física (PINNs) para resolver el problema inverso de determinar la velocidad óptima del refrigerante para el enfriamiento de MOSFETs en electrónica de potencia. El entrenamiento secuencial de estructuras MOSFET multicapa reduce la complejidad de optimización y valida los resultados experimentales."
      }
    }
  },
  {
    "title": "Closing the Expertise Gap in Residential Building Energy Retrofits: A Domain-Specific LLM for Informed Decision-Making",
    "slug": "residential-energy-retrofit-llm-decisions",
    "url": "https://arxiv.org/abs/2602.20181",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Develops a domain-specific LLM fine-tuned on physics-based energy simulations for residential retrofit recommendations based on homeowner-accessible building descriptions. Model identifies optimal CO2-reducing retrofits in 98.9% of top-three recommendations.",
    "content": "arXiv:2602.20181v1 Announce Type: cross \nAbstract: Residential energy retrofit decision-making is constrained by an expertise gap, as homeowners lack the technical literacy required for energy assessments. To address this challenge, this study develops a domain-specific large language model (LLM) that provides optimal retrofit recommendations using homeowner-accessible descriptions of basic dwelling characteristics. The model is fine-tuned on physics-based energy simulations and techno-economic calculations derived from 536,416 U.S. residential building prototypes across nine major retrofit categories. Using Low-Rank Adaptation (LoRA), the LLM maps dwelling characteristics to optimal retrofit selections and associated performance outcomes. Evaluation against physics-grounded baselines shows that the model identifies the optimal retrofit for CO2 reduction within its top three recommendations in 98.9% of cases and the shortest discounted payback period in 93.3% of cases. Fine-tuning yields an order-of-magnitude reduction in CO2 prediction error and multi-fold reductions for energy use and retrofit cost. The model maintains performance under incomplete input conditions, supporting informed residential decarbonization decisions.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "缩小住宅建筑能源改造中的专业知识差距：用于知情决策的特定领域大语言模型",
        "summary": "开发了在基于物理的能源模拟上微调的特定领域大语言模型，用于根据房主可获得的建筑描述提出住宅改造建议。该模型在98.9%的前三名推荐中确定了最优的减CO2改造。"
      },
      "fr": {
        "title": "Combler l'écart d'expertise dans les rénovations énergétiques des bâtiments résidentiels : un LLM spécifique au domaine pour une prise de décision éclairée",
        "summary": "Développe un LLM spécifique au domaine, affiné sur des simulations énergétiques basées sur la physique pour des recommandations de rénovation résidentielle basées sur des descriptions de bâtiments accessibles aux propriétaires. Le modèle identifie les rénovations optimales réduisant le CO2 dans 98,9 % des trois meilleures recommandations."
      },
      "de": {
        "title": "Schließung der Kompetenzlücke bei Energieumbauten von Wohngebäuden: Ein domänenspezifisches LLM für informierte Entscheidungsfindung",
        "summary": "Entwickelt ein domänenspezifisches LLM, das auf physikalischen Energiesimulationen abgestimmt ist, um Empfehlungen für Wohngebäuderenovierungen basierend auf für Hausbesitzer zugänglichen Gebäudebeschreibungen zu geben. Das Modell identifiziert optimale CO2-reduzierende Sanierungen in 98,9 % der Top-3-Empfehlungen."
      },
      "es": {
        "title": "Cierre de la brecha de experiencia en renovaciones energéticas de edificios residenciales: un LLM específico del dominio para la toma de decisiones informada",
        "summary": "Desarrolla un LLM específico del dominio afinado en simulaciones energéticas basadas en física para recomendaciones de renovación residencial basadas en descripciones de edificios accesibles para propietarios. El modelo identifica renovaciones óptimas que reducen el CO2 en el 98,9 % de las recomendaciones de los tres mejores."
      }
    }
  },
  {
    "title": "AINet: Anchor Instances Learning for Regional Heterogeneity in Whole Slide Image",
    "slug": "ainet-anchor-instances-whole-slide-image",
    "url": "https://arxiv.org/abs/2602.20187",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Introduces AINet framework using anchor instances to represent regional heterogeneity in pathology whole slide images for tumor analysis. Achieves state-of-the-art multi-instance learning performance with substantially fewer parameters through modular dual-level anchor mining.",
    "content": "arXiv:2602.20187v1 Announce Type: cross \nAbstract: Recent advances in multi-instance learning (MIL) have witnessed impressive performance in whole slide image (WSI) analysis. However, the inherent sparsity of tumors and their morphological diversity lead to obvious heterogeneity across regions, posing significant challenges in aggregating high-quality and discriminative representations. To address this, we introduce a novel concept of anchor instance (AI), a compact subset of instances that are representative within their regions (local) and discriminative at the bag (global) level. These AIs act as semantic references to guide interactions across regions, correcting non-discriminative patterns while preserving regional diversity. Specifically, we propose a dual-level anchor mining (DAM) module to \\textbf{select} AIs from massive instances, where the most informative AI in each region is extracted by assessing its similarity to both local and global embeddings. Furthermore, to ensure completeness and diversity, we devise an anchor-guided region correction (ARC) module that explores the complementary information from all regions to \\textbf{correct} each regional representation. Building upon DAM and ARC, we develop a concise yet effective framework, AINet, which employs a simple predictor and surpasses state-of-the-art methods with substantially fewer FLOPs and parameters. Moreover, both DAM and ARC are modular and can be seamlessly integrated into existing MIL frameworks, consistently improving their performance.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "AINet：全幻灯片图像中区域异质性的锚实例学习",
        "summary": "介绍了AINet框架，使用锚实例来表示病理全幻灯片图像中的区域异质性以进行肿瘤分析。通过模块化的双层锚挖掘，以大幅减少的参数实现了最先进的多实例学习性能。"
      },
      "fr": {
        "title": "AINet : apprentissage des instances d'ancrage pour l'hétérogénéité régionale dans les images de lame entière",
        "summary": "Introduit le framework AINet utilisant des instances d'ancrage pour représenter l'hétérogénéité régionale dans les images de lames entières de pathologie pour l'analyse tumorale. Réalise des performances d'apprentissage multi-instances de pointe avec considérablement moins de paramètres grâce à l'extraction d'ancrage dual-level modulaire."
      },
      "de": {
        "title": "AINet: Ankerinstanz-Lernen für regionale Heterogenität in Ganzslide-Bildern",
        "summary": "Stellt das AINet-Framework vor, das Ankerinstanzen zur Darstellung der regionalen Heterogenität in pathologischen Ganzslide-Bildern zur Tumoranalyse verwendet. Erreicht hochmoderne Mehreinstanz-Lernleistung mit wesentlich weniger Parametern durch modulares zweistufiges Anker-Mining."
      },
      "es": {
        "title": "AINet: aprendizaje de instancias de anclaje para la heterogeneidad regional en imágenes de lámina completa",
        "summary": "Presenta el framework AINet que utiliza instancias de anclaje para representar la heterogeneidad regional en imágenes de lámina completa de patología para análisis de tumores. Logra un rendimiento de aprendizaje multi-instancia de última generación con sustancialmente menos parámetros a través de minería de anclaje dual-level modular."
      }
    }
  },
  {
    "title": "MoBiQuant: Mixture-of-Bits Quantization for Token-Adaptive Elastic LLMs",
    "slug": "mobioquant-mixture-bits-elastic-llm",
    "url": "https://arxiv.org/abs/2602.20191",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Proposes MoBiQuant, a quantization framework enabling LLMs to dynamically adjust precision based on token-level sensitivity for elastic deployment. Enables smooth precision switching across different computational resources without repeated calibration.",
    "content": "arXiv:2602.20191v1 Announce Type: cross \nAbstract: Changing runtime complexity on cloud and edge devices necessitates elastic large language model (LLM) deployment, where an LLM can be inferred with various quantization precisions based on available computational resources. However, it has been observed that the calibration parameters for quantization are typically linked to specific precisions, which presents challenges during elastic-precision calibration and precision switching at runtime. In this work, we attribute the source of varying calibration parameters to the varying token-level sensitivity caused by a precision-dependent outlier migration phenomenon.Motivated by this observation, we propose \\texttt{MoBiQuant}, a novel Mixture-of-Bits quantization framework that adjusts weight precision for elastic LLM inference based on token sensitivity. Specifically, we propose the many-in-one recursive residual quantization that can iteratively reconstruct higher-precision weights and the token-aware router to dynamically select the number of residual bit slices. MoBiQuant enables smooth precision switching while improving generalization for the distribution of token outliers. Experimental results demonstrate that MoBiQuant exhibits strong elasticity, enabling it to match the performance of bit-specific calibrated PTQ on LLaMA3-8B without repeated calibration.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "MoBiQuant：用于令牌自适应弹性大语言模型的混合比特量化",
        "summary": "提出MoBiQuant，一个量化框架，使大语言模型能够根据令牌级敏感性动态调整精度，以实现弹性部署。支持在不同计算资源之间平稳切换精度，无需重复校准。"
      },
      "fr": {
        "title": "MoBiQuant: Quantification par mélange de bits pour les grands modèles de langage élastiques adaptatifs aux jetons",
        "summary": "Propose MoBiQuant, un cadre de quantification permettant aux grands modèles de langage d'ajuster dynamiquement la précision en fonction de la sensibilité au niveau des jetons pour un déploiement élastique. Permet le basculement fluide de la précision entre différentes ressources de calcul sans recalibrage répété."
      },
      "de": {
        "title": "MoBiQuant: Quantisierung mit Bitmischung für tokenadaptive elastische große Sprachmodelle",
        "summary": "Schlägt MoBiQuant vor, ein Quantisierungsrahmenwerk, das es großen Sprachmodellen ermöglicht, die Präzision basierend auf Token-Ebene-Empfindlichkeit für elastische Bereitstellung dynamisch anzupassen. Ermöglicht nahtlose Präzisionswechsel über verschiedene Rechenressourcen hinweg ohne wiederholte Kalibrierung."
      },
      "es": {
        "title": "MoBiQuant: Cuantificación de mezcla de bits para modelos de lenguaje grandes y elásticos adaptativos a tokens",
        "summary": "Propone MoBiQuant, un marco de cuantificación que permite a los modelos de lenguaje grandes ajustar dinámicamente la precisión basándose en la sensibilidad a nivel de token para el despliegue elástico. Permite el cambio suave de precisión entre diferentes recursos computacionales sin recalibración repetida."
      }
    }
  },
  {
    "title": "When Backdoors Go Beyond Triggers: Semantic Drift in Diffusion Models Under Encoder Attacks",
    "slug": "backdoors-semantic-drift-diffusion-models",
    "url": "https://arxiv.org/abs/2602.20193",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Demonstrates that encoder-side poisoning in text-to-image models causes persistent semantic corruption beyond trigger activation through low-rank geometric deformations. Introduces SEMAD framework to measure structural embedding drift and downstream functional misalignment.",
    "content": "arXiv:2602.20193v1 Announce Type: cross \nAbstract: Standard evaluations of backdoor attacks on text-to-image (T2I) models primarily measure trigger activation and visual fidelity. We challenge this paradigm, demonstrating that encoder-side poisoning induces persistent, trigger-free semantic corruption that fundamentally reshapes the representation manifold. We trace this vulnerability to a geometric mechanism: a Jacobian-based analysis reveals that backdoors act as low-rank, target-centered deformations that amplify local sensitivity, causing distortion to propagate coherently across semantic neighborhoods. To rigorously quantify this structural degradation, we introduce SEMAD (Semantic Alignment and Drift), a diagnostic framework that measures both internal embedding drift and downstream functional misalignment. Our findings, validated across diffusion and contrastive paradigms, expose the deep structural risks of encoder poisoning and highlight the necessity of geometric audits beyond simple attack success rates.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "当后门超越触发器：编码器攻击下扩散模型的语义漂移",
        "summary": "证明了文本到图像模型中的编码器端中毒通过低秩几何变形导致超越触发激活的持久语义腐蚀。引入SEMAD框架来测量结构嵌入漂移和下游功能不对齐。"
      },
      "fr": {
        "title": "Quand les portes dérobées vont au-delà des déclencheurs: dérive sémantique dans les modèles de diffusion sous les attaques d'encodeur",
        "summary": "Démontre que l'empoisonnement du côté de l'encodeur dans les modèles texte-image provoque une corruption sémantique persistante au-delà de l'activation du déclencheur par le biais de déformations géométriques de bas rang. Introduit le cadre SEMAD pour mesurer la dérive de plongement structurel et le désalignement fonctionnel en aval."
      },
      "de": {
        "title": "Wenn Hintertüren über Auslöser hinausgehen: Semantische Verschiebung in Diffusionsmodellen unter Encoderattacken",
        "summary": "Zeigt, dass die Vergiftung auf der Encoderseite in Text-zu-Bild-Modellen durch Verformungen mit niedrigem Rang zu persistenter semantischer Korruption über die Triggeraktivierung hinaus führt. Führt das SEMAD-Framework ein, um strukturelle Embedding-Abweichungen und nachgelagerte funktionale Fehlausrichtungen zu messen."
      },
      "es": {
        "title": "Cuando las puertas traseras van más allá de los disparadores: Desviación semántica en modelos de difusión bajo ataques de codificador",
        "summary": "Demuestra que el envenenamiento del lado del codificador en modelos de texto a imagen causa corrupción semántica persistente más allá de la activación del disparador a través de deformaciones geométricas de bajo rango. Introduce el marco SEMAD para medir la desviación de incrustación estructural y la desalineación funcional aguas abajo."
      }
    }
  },
  {
    "title": "OpenPort Protocol: A Security Governance Specification for AI Agent Tool Access",
    "slug": "openport-protocol-ai-agent-tool-security",
    "url": "https://arxiv.org/abs/2602.20196",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Introduces OpenPort Protocol, a governance-first specification for secure AI agent access to application tools with least-privilege authorization and audit trails. Includes risk-gated lifecycle for write operations and state witness mechanism for time-of-check/time-of-use validation.",
    "content": "arXiv:2602.20196v1 Announce Type: cross \nAbstract: AI agents increasingly require direct, structured access to application data and actions, but production deployments still struggle to express and verify the governance properties that matter in practice: least-privilege authorization, controlled write execution, predictable failure handling, abuse resistance, and auditability. This paper introduces OpenPort Protocol (OPP), a governance-first specification for exposing application tools through a secure server-side gateway that is model- and runtime-neutral and can bind to existing tool ecosystems. OpenPort defines authorization-dependent discovery, stable response envelopes with machine-actionable \\texttt{agent.*} reason codes, and an authorization model combining integration credentials, scoped permissions, and ABAC-style policy constraints. For write operations, OpenPort specifies a risk-gated lifecycle that defaults to draft creation and human review, supports time-bounded auto-execution under explicit policy, and enforces high-risk safeguards including preflight impact binding and idempotency. To address time-of-check/time-of-use drift in delayed approval flows, OpenPort also specifies an optional State Witness profile that revalidates execution-time preconditions and fails closed on state mismatch. Operationally, the protocol requires admission control (rate limits/quotas) with stable 429 semantics and structured audit events across allow/deny/fail paths so that client recovery and incident analysis are deterministic. We present a reference runtime and an executable governance toolchain (layered conformance profiles, negative security tests, fuzz/abuse regression, and release-gate scans) and evaluate the core profile at a pinned release tag using artifact-based, externally reproducible validation.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "OpenPort协议：人工智能代理工具访问的安全治理规范",
        "summary": "介绍OpenPort协议，一个以治理优先的规范，用于安全的人工智能代理对应用工具的访问，具有最小权限授权和审计跟踪。包括写操作的风险门控生命周期和用于检查时间/使用时间验证的状态见证机制。"
      },
      "fr": {
        "title": "Protocole OpenPort: une spécification de gouvernance de sécurité pour l'accès aux outils d'agents IA",
        "summary": "Introduit le protocole OpenPort, une spécification orientée gouvernance pour un accès sécurisé des agents IA aux outils d'application avec autorisation du moins de privilèges et pistes d'audit. Comprend un cycle de vie contrôlé par les risques pour les opérations d'écriture et un mécanisme de témoin d'état pour la validation temps-de-vérification/temps-d'utilisation."
      },
      "de": {
        "title": "OpenPort-Protokoll: Eine Sicherheitsgovernance-Spezifikation für den Zugriff auf KI-Agent-Tools",
        "summary": "Führt das OpenPort-Protokoll ein, eine governance-orientierte Spezifikation für sicheren KI-Agent-Zugriff auf Anwendungstools mit Least-Privilege-Autorisierung und Audit-Trails. Umfasst einen risikokontrollierten Lebenszyklus für Schreibvorgänge und einen Zustandszeugen-Mechanismus zur Validierung von Check-Zeit/Nutzungszeit."
      },
      "es": {
        "title": "Protocolo OpenPort: Especificación de gobernanza de seguridad para acceso a herramientas de agentes de IA",
        "summary": "Introduce el Protocolo OpenPort, una especificación orientada a la gobernanza para acceso seguro de agentes de IA a herramientas de aplicación con autorización de menor privilegio y registros de auditoría. Incluye un ciclo de vida controlado por riesgos para operaciones de escritura y un mecanismo de testigo de estado para la validación de tiempo-de-verificación/tiempo-de-uso."
      }
    }
  },
  {
    "title": "Controllable Exploration in Hybrid-Policy RLVR for Multi-Modal Reasoning",
    "slug": "calibrl-controllable-exploration-rlvr",
    "url": "https://arxiv.org/abs/2602.20197",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Proposes CalibRL, a hybrid-policy reinforcement learning framework for multimodal model reasoning with controllable exploration guided by expert trajectories. Maintains productive stochasticity while avoiding entropy collapse through distribution-aware advantage weighting.",
    "content": "arXiv:2602.20197v1 Announce Type: cross \nAbstract: Reinforcement Learning with verifiable rewards (RLVR) has emerged as a primary learning paradigm for enhancing the reasoning capabilities of multi-modal large language models (MLLMs). However, during RL training, the enormous state space of MLLM and sparse rewards often leads to entropy collapse, policy degradation, or over-exploitation of suboptimal behaviors. This necessitates an exploration strategy that maintains productive stochasticity while avoiding the drawbacks of uncontrolled random sampling, yielding inefficient exploration. In this paper, we propose CalibRL, a hybrid-policy RLVR framework that supports controllable exploration with expert guidance, enabled by two key mechanisms. First, a distribution-aware advantage weighting scales updates by group rareness to calibrate the distribution, therefore preserving exploration. Meanwhile, the asymmetric activation function (LeakyReLU) leverages the expert knowledge as a calibration baseline to moderate overconfident updates while preserving their corrective direction. CalibRL increases policy entropy in a guided manner and clarifies the target distribution by estimating the on-policy distribution through online sampling. Updates are driven by these informative behaviors, avoiding convergence to erroneous patterns. Importantly, these designs help alleviate the distributional mismatch between the model's policy and expert trajectories, thereby achieving a more stable balance between exploration and exploitation. Extensive experiments across eight benchmarks, including both in-domain and out-of-domain settings, demonstrate consistent improvements, validating the effectiveness of our controllable hybrid-policy RLVR training. Code is available at https://github.com/zhh6425/CalibRL.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "混合策略强化学习中的可控探索用于多模态推理",
        "summary": "提出CalibRL，一个混合策略强化学习框架，用于多模态模型推理，通过专家轨迹指导的可控探索。在分布感知的优势权重下，保持有效的随机性，同时避免熵坍陷。"
      },
      "fr": {
        "title": "Exploration Contrôlée en Apprentissage par Renforcement à Politique Hybride pour le Raisonnement Multi-Modal",
        "summary": "Propose CalibRL, un cadre d'apprentissage par renforcement à politique hybride pour le raisonnement des modèles multimodaux avec une exploration contrôlée guidée par des trajectoires d'experts. Maintient une stochasticité productive tout en évitant l'effondrement de l'entropie grâce à une pondération des avantages consciente de la distribution."
      },
      "de": {
        "title": "Kontrollierbare Exploration in Hybrid-Policy RLVR für Multi-modale Argumentation",
        "summary": "Stellt CalibRL vor, ein Hybrid-Policy-Reinforcement-Learning-Framework für multimodale Modellargumentation mit kontrollierter Exploration, die durch Experten-Trajektorien geleitet wird. Erhält produktive Stochastizität, während der Entropiekollaps durch verteilungsbewusste Vorteilsgewichtung vermieden wird."
      },
      "es": {
        "title": "Exploración Controlada en RLVR de Política Híbrida para el Razonamiento Multimodal",
        "summary": "Propone CalibRL, un marco de aprendizaje por refuerzo de política híbrida para el razonamiento de modelos multimodales con exploración controlada guiada por trayectorias de expertos. Mantiene la estocasticidad productiva mientras evita el colapso de entropía mediante ponderación de ventajas consciente de la distribución."
      }
    }
  },
  {
    "title": "IMOVNO+: A Regional Partitioning and Meta-Heuristic Ensemble Framework for Imbalanced Multi-Class Learning",
    "slug": "imovno-imbalanced-multi-class-learning",
    "url": "https://arxiv.org/abs/2602.20199",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Presents IMOVNO+, a two-level framework combining data cleaning and ensemble optimization to address class imbalance, overlap, and noise in multi-class learning. Achieves 37-57% improvements in G-mean and near-perfect performance across 35 evaluation datasets.",
    "content": "arXiv:2602.20199v1 Announce Type: cross \nAbstract: Class imbalance, overlap, and noise degrade data quality, reduce model reliability, and limit generalization. Although widely studied in binary classification, these issues remain underexplored in multi-class settings, where complex inter-class relationships make minority-majority structures unclear and traditional clustering fails to capture distribution shape. Approaches that rely only on geometric distances risk removing informative samples and generating low-quality synthetic data, while binarization approaches treat imbalance locally and ignore global inter-class dependencies. At the algorithmic level, ensembles struggle to integrate weak classifiers, leading to limited robustness. This paper proposes IMOVNO+ (IMbalance-OVerlap-NOise+ Algorithm-Level Optimization), a two-level framework designed to jointly enhance data quality and algorithmic robustness for binary and multi-class tasks. At the data level, first, conditional probability is used to quantify the informativeness of each sample. Second, the dataset is partitioned into core, overlapping, and noisy regions. Third, an overlapping-cleaning algorithm is introduced that combines Z-score metrics with a big-jump gap distance. Fourth, a smart oversampling algorithm based on multi-regularization controls synthetic sample proximity, preventing new overlaps. At the algorithmic level, a meta-heuristic prunes ensemble classifiers to reduce weak-learner influence. IMOVNO+ was evaluated on 35 datasets (13 multi-class, 22 binary). Results show consistent superiority over state-of-the-art methods, approaching 100% in several cases. For multi-class data, IMOVNO+ achieves gains of 37-57% in G-mean, 25-44% in F1-score, 25-39% in precision, and 26-43% in recall. In binary tasks, it attains near-perfect performance with improvements of 14-39%. The framework handles data scarcity and imbalance from collection and privacy limits.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "IMOVNO+：用于不平衡多类学习的区域分割和元启发式集成框架",
        "summary": "提出IMOVNO+，一个两层框架，结合数据清理和集成优化来解决多类学习中的类不平衡、重叠和噪声问题。在35个评估数据集中实现了37-57%的G均值改进和接近完美的性能。"
      },
      "fr": {
        "title": "IMOVNO+ : Un Cadre d'Ensemble de Partitionnement Régional et Meta-Heuristique pour l'Apprentissage Multi-Classe Déséquilibré",
        "summary": "Présente IMOVNO+, un cadre à deux niveaux combinant le nettoyage des données et l'optimisation d'ensemble pour résoudre le déséquilibre des classes, le chevauchement et le bruit dans l'apprentissage multi-classe. Réalise des améliorations de 37-57% en G-mean et des performances quasi-parfaites sur 35 ensembles de données d'évaluation."
      },
      "de": {
        "title": "IMOVNO+: Ein Rahmen für regionale Partitionierung und Meta-Heuristik-Ensemble für unausgewogenes Multi-Klassen-Lernen",
        "summary": "Präsentiert IMOVNO+, ein zweistufiges Framework, das Datenbereinigung und Ensemble-Optimierung kombiniert, um Klassenungleichgewicht, Überlappung und Rauschen beim Multi-Klassen-Lernen zu beheben. Erreicht 37-57% Verbesserungen in G-mean und nahezu perfekte Leistung auf 35 Evaluierungsdatensätzen."
      },
      "es": {
        "title": "IMOVNO+: Un Marco de Particionamiento Regional y Ensemble Meta-Heurístico para Aprendizaje Multiclase Desequilibrado",
        "summary": "Presenta IMOVNO+, un marco de dos niveles que combina limpieza de datos y optimización de ensemble para abordar el desequilibrio de clases, superposición y ruido en el aprendizaje multiclase. Logra mejoras del 37-57% en G-mean y un rendimiento casi perfecto en 35 conjuntos de datos de evaluación."
      }
    }
  },
  {
    "title": "Global Prior Meets Local Consistency: Dual-Memory Augmented Vision-Language-Action Model for Efficient Robotic Manipulation",
    "slug": "optimusvla-vision-language-action-robot",
    "url": "https://arxiv.org/abs/2602.20200",
    "source": "arXiv cs.AI",
    "date": "2026-02-25T05:00:00.000Z",
    "summary": "Introduces OptimusVLA, a dual-memory vision-language-action framework combining global task priors and local temporal consistency for robotic manipulation. Achieves 2.9x inference speedup and best performance in real-world generalization tests on multiple benchmarks.",
    "content": "arXiv:2602.20200v1 Announce Type: cross \nAbstract: Hierarchical Vision-Language-Action (VLA) models have rapidly become a dominant paradigm for robotic manipulation. It typically comprising a Vision-Language backbone for perception and understanding, together with a generative policy for action generation. However, its performance is increasingly bottlenecked by the action generation proceess. (i) Low inference efficiency. A pronounced distributional gap between isotropic noise priors and target action distributions, which increases denoising steps and the incidence of infeasible samples. (ii) Poor robustness. Existing policies condition solely on the current observation, neglecting the constraint of history sequence and thus lacking awareness of task progress and temporal consistency. To address these issues, we introduce OptimusVLA, a dual-memory VLA framework with Global Prior Memory (GPM) and Local Consistency Memory (LCM). GPM replaces Gaussian noise with task-level priors retrieved from semantically similar trajectories, thereby shortening the generative path and reducing the umber of function evaluations (NFE). LCM dynamically models executed action sequence to infer task progress and injects a learned consistency constraint that enforces temporal coherence and smoothness of trajectory. Across three simulation benchmarks, OptimusVLA consistently outperforms strong baselines: it achieves 98.6% average success rate on LIBERO, improves over pi_0 by 13.5% on CALVIN, and attains 38% average success rate on RoboTwin 2.0 Hard. In Real-World evaluation, OptimusVLA ranks best on Generalization and Long-horizon suites, surpassing pi_0 by 42.9% and 52.4%, respectively, while delivering 2.9x inference speedup.",
    "category": "ai",
    "translations": {
      "zh": {
        "title": "全局先验与本地一致性相融合：用于高效机器人操纵的双内存增强视觉-语言-动作模型",
        "summary": "引入OptimusVLA，一个双内存视觉-语言-动作框架，结合全局任务先验和本地时间一致性用于机器人操纵。在多个基准测试中实现了2.9倍的推理加速和最佳的现实世界泛化性能。"
      },
      "fr": {
        "title": "Les Priorités Globales Rencontrent la Cohérence Locale : Modèle Vision-Langage-Action Augmenté de Mémoire Duale pour la Manipulation Robotique Efficace",
        "summary": "Introduit OptimusVLA, un cadre de vision-langage-action à mémoire duale combinant les priorités de tâches globales et la cohérence temporelle locale pour la manipulation robotique. Atteint une accélération d'inférence de 2,9x et les meilleures performances dans les tests de généralisation du monde réel sur plusieurs repères."
      },
      "de": {
        "title": "Globale Priorität trifft auf lokale Konsistenz: Duales speicheraugmentiertes Vision-Language-Action-Modell für effiziente Robotermanipulation",
        "summary": "Führt OptimusVLA ein, ein Framework für duale Speicher-Vision-Sprache-Aktion, das globale Aufgabenpriorit und lokale zeitliche Konsistenz für Robotermanipulation kombiniert. Erreicht eine 2,9-fache Inferenzbeschleunigung und beste Leistung bei Tests zur Verallgemeinerung in der realen Welt auf mehreren Benchmarks."
      },
      "es": {
        "title": "Las Prioridades Globales se Encuentran con la Coherencia Local: Modelo de Visión-Lenguaje-Acción Aumentado con Memoria Dual para Manipulación Robótica Eficiente",
        "summary": "Introduce OptimusVLA, un marco de visión-lenguaje-acción con memoria dual que combina prioridades de tareas globales y coherencia temporal local para manipulación robótica. Logra una aceleración de inferencia de 2,9x y el mejor rendimiento en pruebas de generalización en el mundo real en múltiples puntos de referencia."
      }
    }
  }
]